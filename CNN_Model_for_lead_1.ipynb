{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsTzc3oi726u"
      },
      "source": [
        "# **Building a Convolutional Neural Network with Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "zeXEi5dqNMSo",
        "outputId": "155ce6d2-c1a7-4901-e74e-1ef12a163d6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.9.0\n"
          ]
        }
      ],
      "source": [
        "#Tensorflow version\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Rqwnas78NMSp"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Conv2D, Dense, Flatten, BatchNormalization, Dropout, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.efficientnet import EfficientNetB0\n",
        "from keras.preprocessing import image\n",
        "#from keras.preprocessing.image import load_img\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS17ZHmLNMSq"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255) #Normalize the pixel values\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ESKWSaKsNMSq"
      },
      "outputs": [],
      "source": [
        "#File path to the folder containin images\n",
        "train_dir = os.path.join('directory/training/')\n",
        "validation_dir = os.path.join('directory/validation/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "DD759cSRNMSr",
        "outputId": "d59ecaba-74fe-48f0-9de9-8594a01fbcff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 16472 images belonging to 2 classes.\n",
            "Found 3270 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(96, 96),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    )\n",
        "\n",
        "val_data = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(96,96),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeBpCIQpNMSr",
        "outputId": "3ed9a08f-557a-40fc-8787-e7b4fe8cf818"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-21 10:24:38.367821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-03-21 10:24:39.026389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-03-21 10:24:39.026642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-03-21 10:24:39.028975: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-21 10:24:39.030888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-03-21 10:24:39.031078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-03-21 10:24:39.031244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-03-21 10:24:40.972347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-03-21 10:24:40.972561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-03-21 10:24:40.972731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-03-21 10:24:40.972882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6661 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "    # First convolution layer\n",
        "    tf.keras.layers.Conv1D(32, 3, activation='relu', input_shape=(96, 96, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Second convolution layer\n",
        "    tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # Third convolution layer\n",
        "    tf.keras.layers.Conv1D(128, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv1D(128, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "    # Flatten the pooled feature maps\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    # Fully connected hidden layer\n",
        "    tf.keras.layers.Dense(96, activation='relu'),\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "MvbIWlf_NMSr",
        "outputId": "865415a2-55b7-4cbd-923d-b6335918dae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 96, 94, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 48, 47, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 48, 45, 64)        6208      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 24, 22, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 24, 20, 128)       24704     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 12, 10, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 12, 8, 128)        49280     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 6, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 96)                295008    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 97        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 375,617\n",
            "Trainable params: 375,617\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#print model summary\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "FaEjg-SLNMSs"
      },
      "outputs": [],
      "source": [
        "#Performance evaluation Metrics delcaration\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import SensitivityAtSpecificity,SpecificityAtSensitivity,Recall,Precision, AUC\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.0001),\n",
        "              metrics=['accuracy',SensitivityAtSpecificity(0.5),SpecificityAtSensitivity(0.5),Recall(0.5),Precision(0.5), AUC(num_thresholds=200,curve='ROC')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "fDal51UXNMSs"
      },
      "outputs": [],
      "source": [
        "class mycallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('val_accuracy')>0.99):\n",
        "            print(\"\\n Reached 99% accuracy so cancelling training!\")\n",
        "            self.model.stop_training=True\n",
        "\n",
        "mycallback=mycallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "uoL6GauPNMSs",
        "outputId": "6318b4bd-caeb-4d8f-e69f-75dc2145aeb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device Spec:  /job:localhost/replica:0/device:GPU:*\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-21 10:25:30.563056: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - ETA: 0s - loss: 0.6733 - accuracy: 0.6031 - sensitivity_at_specificity: 0.3826 - specificity_at_sensitivity: 0.3951 - recall: 0.0870 - precision: 0.3125 - auc: 0.4644\n",
            "Epoch 1: val_accuracy improved from -inf to 0.58750, saving model to ECG_Model_Lead_1.h5\n",
            "10/10 [==============================] - 12s 114ms/step - loss: 0.6733 - accuracy: 0.6031 - sensitivity_at_specificity: 0.3826 - specificity_at_sensitivity: 0.3951 - recall: 0.0870 - precision: 0.3125 - auc: 0.4644 - val_loss: 0.6892 - val_accuracy: 0.5875 - val_sensitivity_at_specificity: 0.2727 - val_specificity_at_sensitivity: 0.1170 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5102\n",
            "Epoch 2/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6780 - accuracy: 0.6007 - sensitivity_at_specificity: 0.4957 - specificity_at_sensitivity: 0.4740 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5110\n",
            "Epoch 2: val_accuracy did not improve from 0.58750\n",
            "10/10 [==============================] - 1s 49ms/step - loss: 0.6770 - accuracy: 0.6031 - sensitivity_at_specificity: 0.5039 - specificity_at_sensitivity: 0.5026 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5053 - val_loss: 0.7001 - val_accuracy: 0.5437 - val_sensitivity_at_specificity: 0.1096 - val_specificity_at_sensitivity: 0.3448 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5272\n",
            "Epoch 3/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6657 - accuracy: 0.6458 - sensitivity_at_specificity: 0.3922 - specificity_at_sensitivity: 0.3871 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.4162\n",
            "Epoch 3: val_accuracy improved from 0.58750 to 0.65000, saving model to ECG_Model_Lead_1.h5\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.6702 - accuracy: 0.6344 - sensitivity_at_specificity: 0.3932 - specificity_at_sensitivity: 0.3941 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.4222 - val_loss: 0.6496 - val_accuracy: 0.6500 - val_sensitivity_at_specificity: 0.4643 - val_specificity_at_sensitivity: 0.1250 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5419\n",
            "Epoch 4/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6513 - accuracy: 0.6493 - sensitivity_at_specificity: 0.3663 - specificity_at_sensitivity: 0.4171 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.4970\n",
            "Epoch 4: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6523 - accuracy: 0.6469 - sensitivity_at_specificity: 0.3717 - specificity_at_sensitivity: 0.4396 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.4984 - val_loss: 0.6790 - val_accuracy: 0.5938 - val_sensitivity_at_specificity: 0.3692 - val_specificity_at_sensitivity: 0.1579 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5938\n",
            "Epoch 5/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6848 - accuracy: 0.5868 - sensitivity_at_specificity: 0.4790 - specificity_at_sensitivity: 0.4379 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.4893\n",
            "Epoch 5: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6825 - accuracy: 0.5938 - sensitivity_at_specificity: 0.4462 - specificity_at_sensitivity: 0.4211 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.4801 - val_loss: 0.6819 - val_accuracy: 0.5813 - val_sensitivity_at_specificity: 0.6269 - val_specificity_at_sensitivity: 0.5914 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6046\n",
            "Epoch 6/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6771 - accuracy: 0.5694 - sensitivity_at_specificity: 0.6371 - specificity_at_sensitivity: 0.5793 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5939\n",
            "Epoch 6: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.6728 - accuracy: 0.5875 - sensitivity_at_specificity: 0.5530 - specificity_at_sensitivity: 0.5266 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5643 - val_loss: 0.6562 - val_accuracy: 0.6500 - val_sensitivity_at_specificity: 0.2679 - val_specificity_at_sensitivity: 0.2788 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6051\n",
            "Epoch 7/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6593 - accuracy: 0.6458 - sensitivity_at_specificity: 0.4078 - specificity_at_sensitivity: 0.4108 - recall: 0.0097 - precision: 1.0000 - auc: 0.4826     \n",
            "Epoch 7: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 0.6650 - accuracy: 0.6344 - sensitivity_at_specificity: 0.3898 - specificity_at_sensitivity: 0.4208 - recall: 0.0085 - precision: 1.0000 - auc: 0.4706 - val_loss: 0.6611 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.4833 - val_specificity_at_sensitivity: 0.1200 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5453\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6445 - accuracy: 0.6594 - sensitivity_at_specificity: 0.4495 - specificity_at_sensitivity: 0.4834 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5029\n",
            "Epoch 8: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.6445 - accuracy: 0.6594 - sensitivity_at_specificity: 0.4495 - specificity_at_sensitivity: 0.4834 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5029 - val_loss: 0.6642 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.6230 - val_specificity_at_sensitivity: 0.5657 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6196\n",
            "Epoch 9/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.7070 - accuracy: 0.5590 - sensitivity_at_specificity: 0.4173 - specificity_at_sensitivity: 0.4224 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.4732\n",
            "Epoch 9: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.7060 - accuracy: 0.5625 - sensitivity_at_specificity: 0.4286 - specificity_at_sensitivity: 0.4000 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.4582 - val_loss: 0.6739 - val_accuracy: 0.5938 - val_sensitivity_at_specificity: 0.4615 - val_specificity_at_sensitivity: 0.2947 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6175\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6551 - accuracy: 0.6442 - sensitivity_at_specificity: 0.5045 - specificity_at_sensitivity: 0.5174 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5201\n",
            "Epoch 10: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 0.6551 - accuracy: 0.6442 - sensitivity_at_specificity: 0.5045 - specificity_at_sensitivity: 0.5174 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5201 - val_loss: 0.6592 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.5862 - val_specificity_at_sensitivity: 0.5000 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5448\n",
            "Epoch 11/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6790 - accuracy: 0.5729 - sensitivity_at_specificity: 0.5203 - specificity_at_sensitivity: 0.5455 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5658\n",
            "Epoch 11: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.6753 - accuracy: 0.5875 - sensitivity_at_specificity: 0.5000 - specificity_at_sensitivity: 0.5372 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5469 - val_loss: 0.6757 - val_accuracy: 0.5875 - val_sensitivity_at_specificity: 0.4545 - val_specificity_at_sensitivity: 0.3191 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6177\n",
            "Epoch 12/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6767 - accuracy: 0.5833 - sensitivity_at_specificity: 0.5250 - specificity_at_sensitivity: 0.5655 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5469\n",
            "Epoch 12: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.6782 - accuracy: 0.5781 - sensitivity_at_specificity: 0.5333 - specificity_at_sensitivity: 0.5676 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5513 - val_loss: 0.6660 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.4516 - val_specificity_at_sensitivity: 0.4388 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6456\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6548 - accuracy: 0.6406 - sensitivity_at_specificity: 0.4957 - specificity_at_sensitivity: 0.4732 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5316\n",
            "Epoch 13: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.6548 - accuracy: 0.6406 - sensitivity_at_specificity: 0.4957 - specificity_at_sensitivity: 0.4732 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5316 - val_loss: 0.6882 - val_accuracy: 0.5625 - val_sensitivity_at_specificity: 0.5286 - val_specificity_at_sensitivity: 0.6222 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5843\n",
            "Epoch 14/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6562 - accuracy: 0.6354 - sensitivity_at_specificity: 0.4857 - specificity_at_sensitivity: 0.4973 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5140\n",
            "Epoch 14: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.6470 - accuracy: 0.6469 - sensitivity_at_specificity: 0.5133 - specificity_at_sensitivity: 0.5459 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5526 - val_loss: 0.6690 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.4921 - val_specificity_at_sensitivity: 0.4536 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6487\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6613 - accuracy: 0.6219 - sensitivity_at_specificity: 0.5124 - specificity_at_sensitivity: 0.5276 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5371\n",
            "Epoch 15: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.6613 - accuracy: 0.6219 - sensitivity_at_specificity: 0.5124 - specificity_at_sensitivity: 0.5276 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5371 - val_loss: 0.6701 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.7812 - val_specificity_at_sensitivity: 0.5833 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.7235\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6613 - accuracy: 0.6187 - sensitivity_at_specificity: 0.5574 - specificity_at_sensitivity: 0.5960 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5730\n",
            "Epoch 16: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.6613 - accuracy: 0.6187 - sensitivity_at_specificity: 0.5574 - specificity_at_sensitivity: 0.5960 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5730 - val_loss: 0.6876 - val_accuracy: 0.5688 - val_sensitivity_at_specificity: 0.7101 - val_specificity_at_sensitivity: 0.5275 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6615\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.5750 - sensitivity_at_specificity: 0.5294 - specificity_at_sensitivity: 0.5435 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5215\n",
            "Epoch 17: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6852 - accuracy: 0.5750 - sensitivity_at_specificity: 0.5294 - specificity_at_sensitivity: 0.5435 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5215 - val_loss: 0.6607 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.6721 - val_specificity_at_sensitivity: 0.7677 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6909\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6675 - accuracy: 0.6000 - sensitivity_at_specificity: 0.5938 - specificity_at_sensitivity: 0.5938 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5851\n",
            "Epoch 18: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6675 - accuracy: 0.6000 - sensitivity_at_specificity: 0.5938 - specificity_at_sensitivity: 0.5938 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5851 - val_loss: 0.6688 - val_accuracy: 0.5938 - val_sensitivity_at_specificity: 0.7231 - val_specificity_at_sensitivity: 0.8105 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.7244\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6528 - accuracy: 0.6406 - sensitivity_at_specificity: 0.6261 - specificity_at_sensitivity: 0.6244 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5792\n",
            "Epoch 19: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.6528 - accuracy: 0.6406 - sensitivity_at_specificity: 0.6261 - specificity_at_sensitivity: 0.6244 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5792 - val_loss: 0.6784 - val_accuracy: 0.5688 - val_sensitivity_at_specificity: 0.8841 - val_specificity_at_sensitivity: 0.7143 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.7465\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6580 - accuracy: 0.6156 - sensitivity_at_specificity: 0.5772 - specificity_at_sensitivity: 0.6193 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5991\n",
            "Epoch 20: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.6580 - accuracy: 0.6156 - sensitivity_at_specificity: 0.5772 - specificity_at_sensitivity: 0.6193 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5991 - val_loss: 0.7168 - val_accuracy: 0.5250 - val_sensitivity_at_specificity: 0.6579 - val_specificity_at_sensitivity: 0.6905 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6482\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6242 - accuracy: 0.6844 - sensitivity_at_specificity: 0.4653 - specificity_at_sensitivity: 0.4658 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5086\n",
            "Epoch 21: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.6242 - accuracy: 0.6844 - sensitivity_at_specificity: 0.4653 - specificity_at_sensitivity: 0.4658 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5086 - val_loss: 0.7076 - val_accuracy: 0.5688 - val_sensitivity_at_specificity: 0.7101 - val_specificity_at_sensitivity: 0.7912 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6842\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6806 - accuracy: 0.5813 - sensitivity_at_specificity: 0.5821 - specificity_at_sensitivity: 0.6022 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5843\n",
            "Epoch 22: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.6806 - accuracy: 0.5813 - sensitivity_at_specificity: 0.5821 - specificity_at_sensitivity: 0.6022 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5843 - val_loss: 0.6760 - val_accuracy: 0.5688 - val_sensitivity_at_specificity: 0.7101 - val_specificity_at_sensitivity: 0.6703 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6742\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6561 - accuracy: 0.6375 - sensitivity_at_specificity: 0.6261 - specificity_at_sensitivity: 0.5854 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5742\n",
            "Epoch 23: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.6561 - accuracy: 0.6375 - sensitivity_at_specificity: 0.6261 - specificity_at_sensitivity: 0.5854 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5742 - val_loss: 0.6799 - val_accuracy: 0.5500 - val_sensitivity_at_specificity: 0.7361 - val_specificity_at_sensitivity: 0.8409 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.7161\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6591 - accuracy: 0.6219 - sensitivity_at_specificity: 0.5207 - specificity_at_sensitivity: 0.5025 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5525\n",
            "Epoch 24: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.6591 - accuracy: 0.6219 - sensitivity_at_specificity: 0.5207 - specificity_at_sensitivity: 0.5025 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5525 - val_loss: 0.7051 - val_accuracy: 0.5188 - val_sensitivity_at_specificity: 0.6753 - val_specificity_at_sensitivity: 0.7470 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6854\n",
            "Epoch 25/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6714 - accuracy: 0.5833 - sensitivity_at_specificity: 0.6833 - specificity_at_sensitivity: 0.7024 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6221\n",
            "Epoch 25: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.6751 - accuracy: 0.5750 - sensitivity_at_specificity: 0.6838 - specificity_at_sensitivity: 0.6902 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6202 - val_loss: 0.6951 - val_accuracy: 0.5125 - val_sensitivity_at_specificity: 0.8077 - val_specificity_at_sensitivity: 0.6585 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.7031\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6490 - accuracy: 0.6281 - sensitivity_at_specificity: 0.7227 - specificity_at_sensitivity: 0.6617 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6427\n",
            "Epoch 26: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.6490 - accuracy: 0.6281 - sensitivity_at_specificity: 0.7227 - specificity_at_sensitivity: 0.6617 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6427 - val_loss: 0.6608 - val_accuracy: 0.5875 - val_sensitivity_at_specificity: 0.7879 - val_specificity_at_sensitivity: 0.7979 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.7103\n",
            "Epoch 27/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6514 - accuracy: 0.6042 - sensitivity_at_specificity: 0.7193 - specificity_at_sensitivity: 0.7644 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6742\n",
            "Epoch 27: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.6545 - accuracy: 0.6000 - sensitivity_at_specificity: 0.7031 - specificity_at_sensitivity: 0.7708 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6646 - val_loss: 0.6660 - val_accuracy: 0.5813 - val_sensitivity_at_specificity: 0.7761 - val_specificity_at_sensitivity: 0.7097 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6650\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6393 - accuracy: 0.6406 - sensitivity_at_specificity: 0.7304 - specificity_at_sensitivity: 0.6829 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6424\n",
            "Epoch 28: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.6393 - accuracy: 0.6406 - sensitivity_at_specificity: 0.7304 - specificity_at_sensitivity: 0.6829 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6424 - val_loss: 0.6992 - val_accuracy: 0.5188 - val_sensitivity_at_specificity: 0.6623 - val_specificity_at_sensitivity: 0.7590 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6692\n",
            "Epoch 29/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6280 - accuracy: 0.6493 - sensitivity_at_specificity: 0.6931 - specificity_at_sensitivity: 0.6952 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6668\n",
            "Epoch 29: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.6279 - accuracy: 0.6531 - sensitivity_at_specificity: 0.6757 - specificity_at_sensitivity: 0.7033 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6540 - val_loss: 0.7231 - val_accuracy: 0.5250 - val_sensitivity_at_specificity: 0.6579 - val_specificity_at_sensitivity: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6343\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6400 - accuracy: 0.6375 - sensitivity_at_specificity: 0.6379 - specificity_at_sensitivity: 0.6912 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6365\n",
            "Epoch 30: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.6400 - accuracy: 0.6375 - sensitivity_at_specificity: 0.6379 - specificity_at_sensitivity: 0.6912 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6365 - val_loss: 0.6511 - val_accuracy: 0.5625 - val_sensitivity_at_specificity: 0.9429 - val_specificity_at_sensitivity: 0.9111 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.8552\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6495 - accuracy: 0.6313 - sensitivity_at_specificity: 0.6446 - specificity_at_sensitivity: 0.6482 - recall: 0.0496 - precision: 0.6667 - auc: 0.6118       \n",
            "Epoch 31: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.6495 - accuracy: 0.6313 - sensitivity_at_specificity: 0.6446 - specificity_at_sensitivity: 0.6482 - recall: 0.0496 - precision: 0.6667 - auc: 0.6118 - val_loss: 0.6213 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.9138 - val_specificity_at_sensitivity: 0.9314 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.8403\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6497 - accuracy: 0.6250 - sensitivity_at_specificity: 0.6532 - specificity_at_sensitivity: 0.6633 - recall: 0.0403 - precision: 0.8333 - auc: 0.6367      \n",
            "Epoch 32: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.6497 - accuracy: 0.6250 - sensitivity_at_specificity: 0.6532 - specificity_at_sensitivity: 0.6633 - recall: 0.0403 - precision: 0.8333 - auc: 0.6367 - val_loss: 0.6788 - val_accuracy: 0.5375 - val_sensitivity_at_specificity: 0.6757 - val_specificity_at_sensitivity: 0.7093 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6644\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6410 - accuracy: 0.6375 - sensitivity_at_specificity: 0.6293 - specificity_at_sensitivity: 0.6765 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6115\n",
            "Epoch 33: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.6410 - accuracy: 0.6375 - sensitivity_at_specificity: 0.6293 - specificity_at_sensitivity: 0.6765 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6115 - val_loss: 0.6347 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.8710 - val_specificity_at_sensitivity: 0.7755 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.7577\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6373 - accuracy: 0.5969 - sensitivity_at_specificity: 0.7969 - specificity_at_sensitivity: 0.7969 - recall: 0.0156 - precision: 0.4000 - auc: 0.7161      \n",
            "Epoch 34: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.6373 - accuracy: 0.5969 - sensitivity_at_specificity: 0.7969 - specificity_at_sensitivity: 0.7969 - recall: 0.0156 - precision: 0.4000 - auc: 0.7161 - val_loss: 0.6532 - val_accuracy: 0.5875 - val_sensitivity_at_specificity: 0.7941 - val_specificity_at_sensitivity: 0.7283 - val_recall: 0.0441 - val_precision: 0.7500 - val_auc: 0.6613\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6345 - accuracy: 0.6469 - sensitivity_at_specificity: 0.7105 - specificity_at_sensitivity: 0.6311 - recall: 0.0789 - precision: 0.5294 - auc: 0.6424      \n",
            "Epoch 35: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.6345 - accuracy: 0.6469 - sensitivity_at_specificity: 0.7105 - specificity_at_sensitivity: 0.6311 - recall: 0.0789 - precision: 0.5294 - auc: 0.6424 - val_loss: 0.6477 - val_accuracy: 0.5562 - val_sensitivity_at_specificity: 0.8451 - val_specificity_at_sensitivity: 0.8202 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.7540\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6469 - accuracy: 0.5844 - sensitivity_at_specificity: 0.8116 - specificity_at_sensitivity: 0.8022 - recall: 0.0652 - precision: 0.6923 - auc: 0.7202      \n",
            "Epoch 36: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6469 - accuracy: 0.5844 - sensitivity_at_specificity: 0.8116 - specificity_at_sensitivity: 0.8022 - recall: 0.0652 - precision: 0.6923 - auc: 0.7202 - val_loss: 0.6337 - val_accuracy: 0.6438 - val_sensitivity_at_specificity: 0.7377 - val_specificity_at_sensitivity: 0.7576 - val_recall: 0.0656 - val_precision: 1.0000 - val_auc: 0.6930\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6540 - accuracy: 0.6000 - sensitivity_at_specificity: 0.7518 - specificity_at_sensitivity: 0.7322 - recall: 0.1825 - precision: 0.6098 - auc: 0.6585\n",
            "Epoch 37: val_accuracy improved from 0.65000 to 0.71250, saving model to ECG_Model_Lead_1.h5\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.6540 - accuracy: 0.6000 - sensitivity_at_specificity: 0.7518 - specificity_at_sensitivity: 0.7322 - recall: 0.1825 - precision: 0.6098 - auc: 0.6585 - val_loss: 0.6151 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8462 - val_specificity_at_sensitivity: 0.8526 - val_recall: 0.5077 - val_precision: 0.7021 - val_auc: 0.7825\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6175 - accuracy: 0.6625 - sensitivity_at_specificity: 0.7807 - specificity_at_sensitivity: 0.7718 - recall: 0.1404 - precision: 0.6154 - auc: 0.6890\n",
            "Epoch 38: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6175 - accuracy: 0.6625 - sensitivity_at_specificity: 0.7807 - specificity_at_sensitivity: 0.7718 - recall: 0.1404 - precision: 0.6154 - auc: 0.6890 - val_loss: 0.6129 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.8730 - val_specificity_at_sensitivity: 0.8351 - val_recall: 0.0317 - val_precision: 1.0000 - val_auc: 0.7800\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.6594 - sensitivity_at_specificity: 0.7477 - specificity_at_sensitivity: 0.7464 - recall: 0.0180 - precision: 1.0000 - auc: 0.6821\n",
            "Epoch 39: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6076 - accuracy: 0.6594 - sensitivity_at_specificity: 0.7477 - specificity_at_sensitivity: 0.7464 - recall: 0.0180 - precision: 1.0000 - auc: 0.6821 - val_loss: 0.6436 - val_accuracy: 0.5688 - val_sensitivity_at_specificity: 0.8261 - val_specificity_at_sensitivity: 0.8462 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.7516\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6401 - accuracy: 0.6250 - sensitivity_at_specificity: 0.6529 - specificity_at_sensitivity: 0.7236 - recall: 0.1488 - precision: 0.5143 - auc: 0.6290\n",
            "Epoch 40: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6401 - accuracy: 0.6250 - sensitivity_at_specificity: 0.6529 - specificity_at_sensitivity: 0.7236 - recall: 0.1488 - precision: 0.5143 - auc: 0.6290 - val_loss: 0.6172 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.8000 - val_specificity_at_sensitivity: 0.8316 - val_recall: 0.4923 - val_precision: 0.6667 - val_auc: 0.7497\n",
            "Epoch 41/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5896 - accuracy: 0.6840 - sensitivity_at_specificity: 0.7857 - specificity_at_sensitivity: 0.8684 - recall: 0.1531 - precision: 0.6522 - auc: 0.7503\n",
            "Epoch 41: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.6035 - accuracy: 0.6687 - sensitivity_at_specificity: 0.7565 - specificity_at_sensitivity: 0.8439 - recall: 0.1478 - precision: 0.6800 - auc: 0.7238 - val_loss: 0.6862 - val_accuracy: 0.5188 - val_sensitivity_at_specificity: 0.8077 - val_specificity_at_sensitivity: 0.8293 - val_recall: 0.0128 - val_precision: 1.0000 - val_auc: 0.7412\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6120 - accuracy: 0.6625 - sensitivity_at_specificity: 0.7155 - specificity_at_sensitivity: 0.7745 - recall: 0.0776 - precision: 0.9000 - auc: 0.6863\n",
            "Epoch 42: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6120 - accuracy: 0.6625 - sensitivity_at_specificity: 0.7155 - specificity_at_sensitivity: 0.7745 - recall: 0.0776 - precision: 0.9000 - auc: 0.6863 - val_loss: 0.6383 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.8028 - val_specificity_at_sensitivity: 0.7978 - val_recall: 0.1690 - val_precision: 0.7059 - val_auc: 0.7151\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5925 - accuracy: 0.6906 - sensitivity_at_specificity: 0.8053 - specificity_at_sensitivity: 0.7923 - recall: 0.2212 - precision: 0.6944 - auc: 0.7283\n",
            "Epoch 43: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5925 - accuracy: 0.6906 - sensitivity_at_specificity: 0.8053 - specificity_at_sensitivity: 0.7923 - recall: 0.2212 - precision: 0.6944 - auc: 0.7283 - val_loss: 0.6425 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.7429 - val_specificity_at_sensitivity: 0.8556 - val_recall: 0.1714 - val_precision: 0.7500 - val_auc: 0.7245\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8350 - specificity_at_sensitivity: 0.7972 - recall: 0.0971 - precision: 0.7692 - auc: 0.7198\n",
            "Epoch 44: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5676 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8350 - specificity_at_sensitivity: 0.7972 - recall: 0.0971 - precision: 0.7692 - auc: 0.7198 - val_loss: 0.6662 - val_accuracy: 0.5437 - val_sensitivity_at_specificity: 0.9041 - val_specificity_at_sensitivity: 0.8391 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.7832\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6441 - accuracy: 0.6344 - sensitivity_at_specificity: 0.7407 - specificity_at_sensitivity: 0.7568 - recall: 0.2370 - precision: 0.6957 - auc: 0.6839      \n",
            "Epoch 45: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.6441 - accuracy: 0.6344 - sensitivity_at_specificity: 0.7407 - specificity_at_sensitivity: 0.7568 - recall: 0.2370 - precision: 0.6957 - auc: 0.6839 - val_loss: 0.6241 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.8378 - val_specificity_at_sensitivity: 0.8140 - val_recall: 0.6216 - val_precision: 0.6667 - val_auc: 0.7222\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5912 - accuracy: 0.6603 - sensitivity_at_specificity: 0.8252 - specificity_at_sensitivity: 0.7751 - recall: 0.5922 - precision: 0.4880 - auc: 0.7409\n",
            "Epoch 46: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5912 - accuracy: 0.6603 - sensitivity_at_specificity: 0.8252 - specificity_at_sensitivity: 0.7751 - recall: 0.5922 - precision: 0.4880 - auc: 0.7409 - val_loss: 0.6118 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.8169 - val_specificity_at_sensitivity: 0.8202 - val_recall: 0.5070 - val_precision: 0.6923 - val_auc: 0.7511\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6207 - accuracy: 0.6594 - sensitivity_at_specificity: 0.7417 - specificity_at_sensitivity: 0.7750 - recall: 0.1250 - precision: 0.7895 - auc: 0.6808\n",
            "Epoch 47: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6207 - accuracy: 0.6594 - sensitivity_at_specificity: 0.7417 - specificity_at_sensitivity: 0.7750 - recall: 0.1250 - precision: 0.7895 - auc: 0.6808 - val_loss: 0.6134 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.7538 - val_specificity_at_sensitivity: 0.8316 - val_recall: 0.1385 - val_precision: 0.7500 - val_auc: 0.7334\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6307 - accuracy: 0.6406 - sensitivity_at_specificity: 0.6667 - specificity_at_sensitivity: 0.6897 - recall: 0.2393 - precision: 0.5185 - auc: 0.6384\n",
            "Epoch 48: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6307 - accuracy: 0.6406 - sensitivity_at_specificity: 0.6667 - specificity_at_sensitivity: 0.6897 - recall: 0.2393 - precision: 0.5185 - auc: 0.6384 - val_loss: 0.5816 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.8830 - val_recall: 0.4091 - val_precision: 0.7500 - val_auc: 0.7829\n",
            "Epoch 49/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5778 - accuracy: 0.6964 - sensitivity_at_specificity: 0.8243 - specificity_at_sensitivity: 0.7867 - recall: 0.2568 - precision: 0.5938 - auc: 0.7145\n",
            "Epoch 49: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5707 - accuracy: 0.7156 - sensitivity_at_specificity: 0.7963 - specificity_at_sensitivity: 0.8019 - recall: 0.3148 - precision: 0.6667 - auc: 0.7418 - val_loss: 0.6204 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.7460 - val_specificity_at_sensitivity: 0.8351 - val_recall: 0.2698 - val_precision: 0.7391 - val_auc: 0.7025\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5944 - accuracy: 0.6875 - sensitivity_at_specificity: 0.7345 - specificity_at_sensitivity: 0.7681 - recall: 0.1681 - precision: 0.7600 - auc: 0.7051\n",
            "Epoch 50: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5944 - accuracy: 0.6875 - sensitivity_at_specificity: 0.7345 - specificity_at_sensitivity: 0.7681 - recall: 0.1681 - precision: 0.7600 - auc: 0.7051 - val_loss: 0.6058 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.7903 - val_specificity_at_sensitivity: 0.7959 - val_recall: 0.2742 - val_precision: 0.7083 - val_auc: 0.7182\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6135 - accuracy: 0.6406 - sensitivity_at_specificity: 0.7200 - specificity_at_sensitivity: 0.7436 - recall: 0.4400 - precision: 0.5500 - auc: 0.6876\n",
            "Epoch 51: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6135 - accuracy: 0.6406 - sensitivity_at_specificity: 0.7200 - specificity_at_sensitivity: 0.7436 - recall: 0.4400 - precision: 0.5500 - auc: 0.6876 - val_loss: 0.6286 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.7013 - val_specificity_at_sensitivity: 0.8193 - val_recall: 0.5974 - val_precision: 0.6133 - val_auc: 0.7086\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6038 - accuracy: 0.6906 - sensitivity_at_specificity: 0.7833 - specificity_at_sensitivity: 0.7950 - recall: 0.4500 - precision: 0.6207 - auc: 0.7106\n",
            "Epoch 52: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.6038 - accuracy: 0.6906 - sensitivity_at_specificity: 0.7833 - specificity_at_sensitivity: 0.7950 - recall: 0.4500 - precision: 0.6207 - auc: 0.7106 - val_loss: 0.6645 - val_accuracy: 0.5750 - val_sensitivity_at_specificity: 0.7222 - val_specificity_at_sensitivity: 0.7159 - val_recall: 0.0972 - val_precision: 0.7000 - val_auc: 0.7036\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5886 - accuracy: 0.6812 - sensitivity_at_specificity: 0.7895 - specificity_at_sensitivity: 0.8544 - recall: 0.2105 - precision: 0.6667 - auc: 0.7248\n",
            "Epoch 53: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5886 - accuracy: 0.6812 - sensitivity_at_specificity: 0.7895 - specificity_at_sensitivity: 0.8544 - recall: 0.2105 - precision: 0.6667 - auc: 0.7248 - val_loss: 0.5919 - val_accuracy: 0.6687 - val_sensitivity_at_specificity: 0.8919 - val_specificity_at_sensitivity: 0.9070 - val_recall: 0.3649 - val_precision: 0.8182 - val_auc: 0.8051\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5939 - accuracy: 0.6781 - sensitivity_at_specificity: 0.7679 - specificity_at_sensitivity: 0.7500 - recall: 0.3929 - precision: 0.5570 - auc: 0.6993\n",
            "Epoch 54: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.5939 - accuracy: 0.6781 - sensitivity_at_specificity: 0.7679 - specificity_at_sensitivity: 0.7500 - recall: 0.3929 - precision: 0.5570 - auc: 0.6993 - val_loss: 0.6072 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8116 - val_specificity_at_sensitivity: 0.8462 - val_recall: 0.3623 - val_precision: 0.8929 - val_auc: 0.7614\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5904 - accuracy: 0.6812 - sensitivity_at_specificity: 0.7982 - specificity_at_sensitivity: 0.7816 - recall: 0.1316 - precision: 0.8333 - auc: 0.7230\n",
            "Epoch 55: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5904 - accuracy: 0.6812 - sensitivity_at_specificity: 0.7982 - specificity_at_sensitivity: 0.7816 - recall: 0.1316 - precision: 0.8333 - auc: 0.7230 - val_loss: 0.6224 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.8507 - val_specificity_at_sensitivity: 0.8280 - val_recall: 0.4478 - val_precision: 0.6667 - val_auc: 0.7117\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5655 - accuracy: 0.7375 - sensitivity_at_specificity: 0.8056 - specificity_at_sensitivity: 0.8491 - recall: 0.5000 - precision: 0.6429 - auc: 0.7441\n",
            "Epoch 56: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5655 - accuracy: 0.7375 - sensitivity_at_specificity: 0.8056 - specificity_at_sensitivity: 0.8491 - recall: 0.5000 - precision: 0.6429 - auc: 0.7441 - val_loss: 0.6107 - val_accuracy: 0.6625 - val_sensitivity_at_specificity: 0.7937 - val_specificity_at_sensitivity: 0.8144 - val_recall: 0.3016 - val_precision: 0.6552 - val_auc: 0.7106\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.6781 - sensitivity_at_specificity: 0.7984 - specificity_at_sensitivity: 0.8316 - recall: 0.3065 - precision: 0.6909 - auc: 0.7474\n",
            "Epoch 57: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5866 - accuracy: 0.6781 - sensitivity_at_specificity: 0.7984 - specificity_at_sensitivity: 0.8316 - recall: 0.3065 - precision: 0.6909 - auc: 0.7474 - val_loss: 0.6394 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.7059 - val_specificity_at_sensitivity: 0.7391 - val_recall: 0.4853 - val_precision: 0.5893 - val_auc: 0.6789\n",
            "Epoch 58/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5775 - accuracy: 0.7070 - sensitivity_at_specificity: 0.8295 - specificity_at_sensitivity: 0.8155 - recall: 0.5227 - precision: 0.5823 - auc: 0.7323\n",
            "Epoch 58: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5992 - accuracy: 0.6938 - sensitivity_at_specificity: 0.7863 - specificity_at_sensitivity: 0.7931 - recall: 0.4957 - precision: 0.5979 - auc: 0.7110 - val_loss: 0.5866 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.9041 - val_specificity_at_sensitivity: 0.8621 - val_recall: 0.4110 - val_precision: 0.7895 - val_auc: 0.7916\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5922 - accuracy: 0.6781 - sensitivity_at_specificity: 0.8293 - specificity_at_sensitivity: 0.7970 - recall: 0.5366 - precision: 0.5893 - auc: 0.7251\n",
            "Epoch 59: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.5922 - accuracy: 0.6781 - sensitivity_at_specificity: 0.8293 - specificity_at_sensitivity: 0.7970 - recall: 0.5366 - precision: 0.5893 - auc: 0.7251 - val_loss: 0.6196 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.7794 - val_specificity_at_sensitivity: 0.7391 - val_recall: 0.6176 - val_precision: 0.5915 - val_auc: 0.7084\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5756 - accuracy: 0.6938 - sensitivity_at_specificity: 0.7965 - specificity_at_sensitivity: 0.7681 - recall: 0.2566 - precision: 0.6744 - auc: 0.7304\n",
            "Epoch 60: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5756 - accuracy: 0.6938 - sensitivity_at_specificity: 0.7965 - specificity_at_sensitivity: 0.7681 - recall: 0.2566 - precision: 0.6744 - auc: 0.7304 - val_loss: 0.6355 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.8429 - val_specificity_at_sensitivity: 0.8778 - val_recall: 0.1714 - val_precision: 1.0000 - val_auc: 0.7590\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6233 - accuracy: 0.6500 - sensitivity_at_specificity: 0.7829 - specificity_at_sensitivity: 0.7487 - recall: 0.5504 - precision: 0.5680 - auc: 0.6913\n",
            "Epoch 61: val_accuracy did not improve from 0.71250\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.6233 - accuracy: 0.6500 - sensitivity_at_specificity: 0.7829 - specificity_at_sensitivity: 0.7487 - recall: 0.5504 - precision: 0.5680 - auc: 0.6913 - val_loss: 0.5753 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8077 - val_specificity_at_sensitivity: 0.8902 - val_recall: 0.7308 - val_precision: 0.6951 - val_auc: 0.7822\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5783 - accuracy: 0.6906 - sensitivity_at_specificity: 0.8077 - specificity_at_sensitivity: 0.8263 - recall: 0.5692 - precision: 0.6325 - auc: 0.7477\n",
            "Epoch 62: val_accuracy improved from 0.71250 to 0.71875, saving model to ECG_Model_Lead_1.h5\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.5783 - accuracy: 0.6906 - sensitivity_at_specificity: 0.8077 - specificity_at_sensitivity: 0.8263 - recall: 0.5692 - precision: 0.6325 - auc: 0.7477 - val_loss: 0.6114 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.7887 - val_specificity_at_sensitivity: 0.8764 - val_recall: 0.4930 - val_precision: 0.7955 - val_auc: 0.7519\n",
            "Epoch 63/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5336 - accuracy: 0.7344 - sensitivity_at_specificity: 0.8095 - specificity_at_sensitivity: 0.8953 - recall: 0.3333 - precision: 0.7000 - auc: 0.7757\n",
            "Epoch 63: val_accuracy did not improve from 0.71875\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.5340 - accuracy: 0.7312 - sensitivity_at_specificity: 0.8173 - specificity_at_sensitivity: 0.9028 - recall: 0.3173 - precision: 0.6875 - auc: 0.7769 - val_loss: 0.6415 - val_accuracy: 0.6500 - val_sensitivity_at_specificity: 0.7917 - val_specificity_at_sensitivity: 0.8523 - val_recall: 0.2917 - val_precision: 0.8077 - val_auc: 0.7422\n",
            "Epoch 64/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5575 - accuracy: 0.7305 - sensitivity_at_specificity: 0.8600 - specificity_at_sensitivity: 0.8526 - recall: 0.4600 - precision: 0.7541 - auc: 0.7755\n",
            "Epoch 64: val_accuracy did not improve from 0.71875\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.5541 - accuracy: 0.7406 - sensitivity_at_specificity: 0.8722 - specificity_at_sensitivity: 0.9091 - recall: 0.5188 - precision: 0.7841 - auc: 0.7942 - val_loss: 0.6027 - val_accuracy: 0.6625 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.7979 - val_recall: 0.6970 - val_precision: 0.5750 - val_auc: 0.7390\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.7312 - sensitivity_at_specificity: 0.8480 - specificity_at_sensitivity: 0.8308 - recall: 0.6720 - precision: 0.6512 - auc: 0.7706\n",
            "Epoch 65: val_accuracy did not improve from 0.71875\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.5658 - accuracy: 0.7312 - sensitivity_at_specificity: 0.8480 - specificity_at_sensitivity: 0.8308 - recall: 0.6720 - precision: 0.6512 - auc: 0.7706 - val_loss: 0.6435 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.7260 - val_specificity_at_sensitivity: 0.7241 - val_recall: 0.4247 - val_precision: 0.6078 - val_auc: 0.6746\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.6687 - sensitivity_at_specificity: 0.7899 - specificity_at_sensitivity: 0.7861 - recall: 0.3361 - precision: 0.5970 - auc: 0.7257\n",
            "Epoch 66: val_accuracy did not improve from 0.71875\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5890 - accuracy: 0.6687 - sensitivity_at_specificity: 0.7899 - specificity_at_sensitivity: 0.7861 - recall: 0.3361 - precision: 0.5970 - auc: 0.7257 - val_loss: 0.5688 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8657 - val_specificity_at_sensitivity: 0.8495 - val_recall: 0.5224 - val_precision: 0.7143 - val_auc: 0.7762\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5655 - accuracy: 0.7094 - sensitivity_at_specificity: 0.7931 - specificity_at_sensitivity: 0.7990 - recall: 0.4483 - precision: 0.6420 - auc: 0.7402\n",
            "Epoch 67: val_accuracy did not improve from 0.71875\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5655 - accuracy: 0.7094 - sensitivity_at_specificity: 0.7931 - specificity_at_sensitivity: 0.7990 - recall: 0.4483 - precision: 0.6420 - auc: 0.7402 - val_loss: 0.5631 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.9200 - val_specificity_at_sensitivity: 0.8706 - val_recall: 0.5067 - val_precision: 0.7755 - val_auc: 0.8118\n",
            "Epoch 68/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5840 - accuracy: 0.7227 - sensitivity_at_specificity: 0.7938 - specificity_at_sensitivity: 0.8553 - recall: 0.5155 - precision: 0.6757 - auc: 0.7325\n",
            "Epoch 68: val_accuracy did not improve from 0.71875\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5861 - accuracy: 0.7156 - sensitivity_at_specificity: 0.8000 - specificity_at_sensitivity: 0.8564 - recall: 0.5040 - precision: 0.6848 - auc: 0.7365 - val_loss: 0.5708 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.8246 - val_specificity_at_sensitivity: 0.8058 - val_recall: 0.5614 - val_precision: 0.5714 - val_auc: 0.7460\n",
            "Epoch 69/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5544 - accuracy: 0.7257 - sensitivity_at_specificity: 0.8286 - specificity_at_sensitivity: 0.8634 - recall: 0.5333 - precision: 0.6512 - auc: 0.7620\n",
            "Epoch 69: val_accuracy improved from 0.71875 to 0.74375, saving model to ECG_Model_Lead_1.h5\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.5599 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8103 - specificity_at_sensitivity: 0.8627 - recall: 0.5086 - precision: 0.6413 - auc: 0.7523 - val_loss: 0.5492 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.8939 - val_specificity_at_sensitivity: 0.8936 - val_recall: 0.5455 - val_precision: 0.7660 - val_auc: 0.8024\n",
            "Epoch 70/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5956 - accuracy: 0.6797 - sensitivity_at_specificity: 0.7363 - specificity_at_sensitivity: 0.7576 - recall: 0.3187 - precision: 0.5918 - auc: 0.6989\n",
            "Epoch 70: val_accuracy did not improve from 0.74375\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.5815 - accuracy: 0.6938 - sensitivity_at_specificity: 0.7759 - specificity_at_sensitivity: 0.8186 - recall: 0.3621 - precision: 0.6364 - auc: 0.7270 - val_loss: 0.5766 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.9205 - val_recall: 0.5417 - val_precision: 0.7800 - val_auc: 0.7780\n",
            "Epoch 71/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5586 - accuracy: 0.6979 - sensitivity_at_specificity: 0.8776 - specificity_at_sensitivity: 0.8000 - recall: 0.5306 - precision: 0.5591 - auc: 0.7494\n",
            "Epoch 71: val_accuracy did not improve from 0.74375\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.5661 - accuracy: 0.6844 - sensitivity_at_specificity: 0.8696 - specificity_at_sensitivity: 0.7805 - recall: 0.4870 - precision: 0.5714 - auc: 0.7423 - val_loss: 0.5372 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8909 - val_specificity_at_sensitivity: 0.8571 - val_recall: 0.3091 - val_precision: 0.6538 - val_auc: 0.7801\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5937 - accuracy: 0.6750 - sensitivity_at_specificity: 0.8051 - specificity_at_sensitivity: 0.7822 - recall: 0.4576 - precision: 0.5745 - auc: 0.7129\n",
            "Epoch 72: val_accuracy improved from 0.74375 to 0.76250, saving model to ECG_Model_Lead_1.h5\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.5937 - accuracy: 0.6750 - sensitivity_at_specificity: 0.8051 - specificity_at_sensitivity: 0.7822 - recall: 0.4576 - precision: 0.5745 - auc: 0.7129 - val_loss: 0.4953 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9516 - val_specificity_at_sensitivity: 0.9490 - val_recall: 0.5968 - val_precision: 0.7400 - val_auc: 0.8460\n",
            "Epoch 73/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5556 - accuracy: 0.7014 - sensitivity_at_specificity: 0.8966 - specificity_at_sensitivity: 0.8663 - recall: 0.4310 - precision: 0.7143 - auc: 0.7915\n",
            "Epoch 73: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5561 - accuracy: 0.7031 - sensitivity_at_specificity: 0.8629 - specificity_at_sensitivity: 0.8571 - recall: 0.4113 - precision: 0.6986 - auc: 0.7805 - val_loss: 0.5823 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.8857 - val_specificity_at_sensitivity: 0.8222 - val_recall: 0.5429 - val_precision: 0.6786 - val_auc: 0.7607\n",
            "Epoch 74/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5226 - accuracy: 0.7411 - sensitivity_at_specificity: 0.8902 - specificity_at_sensitivity: 0.8592 - recall: 0.5732 - precision: 0.6714 - auc: 0.8060\n",
            "Epoch 74: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.5334 - accuracy: 0.7406 - sensitivity_at_specificity: 0.8729 - specificity_at_sensitivity: 0.8614 - recall: 0.5678 - precision: 0.6768 - auc: 0.7932 - val_loss: 0.5914 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.8406 - val_specificity_at_sensitivity: 0.7912 - val_recall: 0.5507 - val_precision: 0.6667 - val_auc: 0.7451\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5690 - accuracy: 0.7094 - sensitivity_at_specificity: 0.8730 - specificity_at_sensitivity: 0.8299 - recall: 0.5714 - precision: 0.6486 - auc: 0.7558\n",
            "Epoch 75: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.5690 - accuracy: 0.7094 - sensitivity_at_specificity: 0.8730 - specificity_at_sensitivity: 0.8299 - recall: 0.5714 - precision: 0.6486 - auc: 0.7558 - val_loss: 0.6976 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.7073 - val_specificity_at_sensitivity: 0.7692 - val_recall: 0.4512 - val_precision: 0.6852 - val_auc: 0.6606\n",
            "Epoch 76/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6258 - accuracy: 0.6953 - sensitivity_at_specificity: 0.7456 - specificity_at_sensitivity: 0.8380 - recall: 0.5526 - precision: 0.7000 - auc: 0.7098\n",
            "Epoch 76: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6032 - accuracy: 0.7125 - sensitivity_at_specificity: 0.7664 - specificity_at_sensitivity: 0.8634 - recall: 0.5693 - precision: 0.7027 - auc: 0.7290 - val_loss: 0.5636 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.8615 - val_specificity_at_sensitivity: 0.8947 - val_recall: 0.7538 - val_precision: 0.6364 - val_auc: 0.7890\n",
            "Epoch 77/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5421 - accuracy: 0.7411 - sensitivity_at_specificity: 0.8846 - specificity_at_sensitivity: 0.8767 - recall: 0.5897 - precision: 0.6389 - auc: 0.7891\n",
            "Epoch 77: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5389 - accuracy: 0.7375 - sensitivity_at_specificity: 0.8992 - specificity_at_sensitivity: 0.8756 - recall: 0.5294 - precision: 0.6923 - auc: 0.7971 - val_loss: 0.6301 - val_accuracy: 0.6687 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.8636 - val_recall: 0.3750 - val_precision: 0.7714 - val_auc: 0.7365\n",
            "Epoch 78/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5681 - accuracy: 0.6979 - sensitivity_at_specificity: 0.8532 - specificity_at_sensitivity: 0.8212 - recall: 0.5046 - precision: 0.6250 - auc: 0.7463\n",
            "Epoch 78: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.5691 - accuracy: 0.7031 - sensitivity_at_specificity: 0.8595 - specificity_at_sensitivity: 0.8492 - recall: 0.5289 - precision: 0.6275 - auc: 0.7458 - val_loss: 0.5496 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.8226 - val_specificity_at_sensitivity: 0.8980 - val_recall: 0.6774 - val_precision: 0.6364 - val_auc: 0.7798\n",
            "Epoch 79/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6161 - accuracy: 0.6836 - sensitivity_at_specificity: 0.7708 - specificity_at_sensitivity: 0.7750 - recall: 0.4062 - precision: 0.6190 - auc: 0.6940\n",
            "Epoch 79: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.6105 - accuracy: 0.6750 - sensitivity_at_specificity: 0.7881 - specificity_at_sensitivity: 0.7723 - recall: 0.3898 - precision: 0.5897 - auc: 0.6955 - val_loss: 0.5668 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8873 - val_specificity_at_sensitivity: 0.8539 - val_recall: 0.5070 - val_precision: 0.7347 - val_auc: 0.7834\n",
            "Epoch 80/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5738 - accuracy: 0.7107 - sensitivity_at_specificity: 0.8142 - specificity_at_sensitivity: 0.8503 - recall: 0.5398 - precision: 0.6778 - auc: 0.7555\n",
            "Epoch 80: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5687 - accuracy: 0.7212 - sensitivity_at_specificity: 0.8226 - specificity_at_sensitivity: 0.8617 - recall: 0.5403 - precision: 0.6907 - auc: 0.7596 - val_loss: 0.5993 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8243 - val_specificity_at_sensitivity: 0.8605 - val_recall: 0.5270 - val_precision: 0.7500 - val_auc: 0.7542\n",
            "Epoch 81/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5769 - accuracy: 0.7118 - sensitivity_at_specificity: 0.7967 - specificity_at_sensitivity: 0.8667 - recall: 0.5935 - precision: 0.6887 - auc: 0.7599\n",
            "Epoch 81: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.5756 - accuracy: 0.7156 - sensitivity_at_specificity: 0.8043 - specificity_at_sensitivity: 0.8626 - recall: 0.6014 - precision: 0.6975 - auc: 0.7628 - val_loss: 0.6043 - val_accuracy: 0.6625 - val_sensitivity_at_specificity: 0.7231 - val_specificity_at_sensitivity: 0.7789 - val_recall: 0.5538 - val_precision: 0.5902 - val_auc: 0.7117\n",
            "Epoch 82/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5401 - accuracy: 0.7422 - sensitivity_at_specificity: 0.8478 - specificity_at_sensitivity: 0.8841 - recall: 0.4891 - precision: 0.7031 - auc: 0.7803\n",
            "Epoch 82: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.5421 - accuracy: 0.7406 - sensitivity_at_specificity: 0.8241 - specificity_at_sensitivity: 0.8585 - recall: 0.4630 - precision: 0.6667 - auc: 0.7646 - val_loss: 0.6405 - val_accuracy: 0.6687 - val_sensitivity_at_specificity: 0.6957 - val_specificity_at_sensitivity: 0.7802 - val_recall: 0.3478 - val_precision: 0.7500 - val_auc: 0.7036\n",
            "Epoch 83/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5807 - accuracy: 0.6836 - sensitivity_at_specificity: 0.9027 - specificity_at_sensitivity: 0.8112 - recall: 0.5398 - precision: 0.6778 - auc: 0.7632\n",
            "Epoch 83: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5819 - accuracy: 0.6781 - sensitivity_at_specificity: 0.8722 - specificity_at_sensitivity: 0.7914 - recall: 0.5639 - precision: 0.6250 - auc: 0.7479 - val_loss: 0.5912 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.7857 - val_specificity_at_sensitivity: 0.8778 - val_recall: 0.6286 - val_precision: 0.6769 - val_auc: 0.7411\n",
            "Epoch 84/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5814 - accuracy: 0.7083 - sensitivity_at_specificity: 0.8103 - specificity_at_sensitivity: 0.8488 - recall: 0.4741 - precision: 0.7051 - auc: 0.7550\n",
            "Epoch 84: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.5808 - accuracy: 0.7125 - sensitivity_at_specificity: 0.8295 - specificity_at_sensitivity: 0.8534 - recall: 0.4884 - precision: 0.7079 - auc: 0.7572 - val_loss: 0.6115 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.7727 - val_specificity_at_sensitivity: 0.7766 - val_recall: 0.5758 - val_precision: 0.5846 - val_auc: 0.7174\n",
            "Epoch 85/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5522 - accuracy: 0.7422 - sensitivity_at_specificity: 0.9200 - specificity_at_sensitivity: 0.8590 - recall: 0.7000 - precision: 0.6604 - auc: 0.7930\n",
            "Epoch 85: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5503 - accuracy: 0.7437 - sensitivity_at_specificity: 0.9225 - specificity_at_sensitivity: 0.8691 - recall: 0.7209 - precision: 0.6691 - auc: 0.7943 - val_loss: 0.5593 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.7925 - val_specificity_at_sensitivity: 0.8505 - val_recall: 0.5660 - val_precision: 0.5455 - val_auc: 0.7474\n",
            "Epoch 86/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5161 - accuracy: 0.7734 - sensitivity_at_specificity: 0.9022 - specificity_at_sensitivity: 0.9085 - recall: 0.5326 - precision: 0.7656 - auc: 0.8101\n",
            "Epoch 86: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.5340 - accuracy: 0.7563 - sensitivity_at_specificity: 0.8966 - specificity_at_sensitivity: 0.8824 - recall: 0.4914 - precision: 0.7500 - auc: 0.7898 - val_loss: 0.6530 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.7105 - val_specificity_at_sensitivity: 0.8452 - val_recall: 0.4474 - val_precision: 0.7234 - val_auc: 0.7096\n",
            "Epoch 87/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5697 - accuracy: 0.6944 - sensitivity_at_specificity: 0.8304 - specificity_at_sensitivity: 0.8125 - recall: 0.6250 - precision: 0.6034 - auc: 0.7558\n",
            "Epoch 87: val_accuracy did not improve from 0.76250\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.5666 - accuracy: 0.6906 - sensitivity_at_specificity: 0.8629 - specificity_at_sensitivity: 0.8214 - recall: 0.6452 - precision: 0.5926 - auc: 0.7595 - val_loss: 0.5801 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.7971 - val_specificity_at_sensitivity: 0.8681 - val_recall: 0.6812 - val_precision: 0.6620 - val_auc: 0.7652\n",
            "Epoch 88/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5056 - accuracy: 0.7431 - sensitivity_at_specificity: 0.8981 - specificity_at_sensitivity: 0.9056 - recall: 0.5185 - precision: 0.7179 - auc: 0.8267\n",
            "Epoch 88: val_accuracy improved from 0.76250 to 0.78125, saving model to ECG_Model_Lead_1.h5\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.5039 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9180 - specificity_at_sensitivity: 0.8990 - recall: 0.5246 - precision: 0.7356 - auc: 0.8334 - val_loss: 0.5170 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9167 - val_specificity_at_sensitivity: 0.9200 - val_recall: 0.6000 - val_precision: 0.7660 - val_auc: 0.8113\n",
            "Epoch 89/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5712 - accuracy: 0.7049 - sensitivity_at_specificity: 0.7966 - specificity_at_sensitivity: 0.8941 - recall: 0.5932 - precision: 0.6542 - auc: 0.7574\n",
            "Epoch 89: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.5692 - accuracy: 0.7031 - sensitivity_at_specificity: 0.7984 - specificity_at_sensitivity: 0.8429 - recall: 0.5814 - precision: 0.6466 - auc: 0.7564 - val_loss: 0.5185 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9375 - val_specificity_at_sensitivity: 0.8646 - val_recall: 0.7031 - val_precision: 0.7031 - val_auc: 0.8162\n",
            "Epoch 90/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5814 - accuracy: 0.7031 - sensitivity_at_specificity: 0.8485 - specificity_at_sensitivity: 0.8344 - recall: 0.5253 - precision: 0.6420 - auc: 0.7427\n",
            "Epoch 90: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.5713 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8547 - specificity_at_sensitivity: 0.8079 - recall: 0.4957 - precision: 0.6105 - auc: 0.7433 - val_loss: 0.6241 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.7432 - val_specificity_at_sensitivity: 0.8953 - val_recall: 0.3919 - val_precision: 0.8529 - val_auc: 0.7462\n",
            "Epoch 91/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5765 - accuracy: 0.7148 - sensitivity_at_specificity: 0.8491 - specificity_at_sensitivity: 0.8933 - recall: 0.4151 - precision: 0.8000 - auc: 0.7757\n",
            "Epoch 91: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5794 - accuracy: 0.7031 - sensitivity_at_specificity: 0.8333 - specificity_at_sensitivity: 0.8505 - recall: 0.4206 - precision: 0.7067 - auc: 0.7502 - val_loss: 0.5943 - val_accuracy: 0.6500 - val_sensitivity_at_specificity: 0.8434 - val_specificity_at_sensitivity: 0.7532 - val_recall: 0.6506 - val_precision: 0.6667 - val_auc: 0.7393\n",
            "Epoch 92/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5866 - accuracy: 0.6797 - sensitivity_at_specificity: 0.8532 - specificity_at_sensitivity: 0.7891 - recall: 0.6055 - precision: 0.6286 - auc: 0.7514\n",
            "Epoch 92: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.5738 - accuracy: 0.6938 - sensitivity_at_specificity: 0.8492 - specificity_at_sensitivity: 0.8454 - recall: 0.6270 - precision: 0.6077 - auc: 0.7602 - val_loss: 0.5675 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.8904 - val_specificity_at_sensitivity: 0.8506 - val_recall: 0.5068 - val_precision: 0.7400 - val_auc: 0.7973\n",
            "Epoch 93/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5599 - accuracy: 0.7083 - sensitivity_at_specificity: 0.8105 - specificity_at_sensitivity: 0.8446 - recall: 0.2632 - precision: 0.6410 - auc: 0.7415\n",
            "Epoch 93: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5669 - accuracy: 0.7063 - sensitivity_at_specificity: 0.8257 - specificity_at_sensitivity: 0.8389 - recall: 0.2752 - precision: 0.6667 - auc: 0.7449 - val_loss: 0.6016 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.8723 - val_recall: 0.3788 - val_precision: 0.7576 - val_auc: 0.7552\n",
            "Epoch 94/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5793 - accuracy: 0.7153 - sensitivity_at_specificity: 0.8190 - specificity_at_sensitivity: 0.8256 - recall: 0.6293 - precision: 0.6518 - auc: 0.7521\n",
            "Epoch 94: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5744 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8306 - specificity_at_sensitivity: 0.8265 - recall: 0.6452 - precision: 0.6349 - auc: 0.7564 - val_loss: 0.5732 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.8788 - val_specificity_at_sensitivity: 0.8617 - val_recall: 0.7424 - val_precision: 0.6447 - val_auc: 0.7801\n",
            "Epoch 95/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5360 - accuracy: 0.7500 - sensitivity_at_specificity: 0.8431 - specificity_at_sensitivity: 0.8925 - recall: 0.5294 - precision: 0.6923 - auc: 0.7885\n",
            "Epoch 95: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5463 - accuracy: 0.7375 - sensitivity_at_specificity: 0.8304 - specificity_at_sensitivity: 0.8654 - recall: 0.5000 - precision: 0.6667 - auc: 0.7687 - val_loss: 0.5756 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8833 - val_specificity_at_sensitivity: 0.8800 - val_recall: 0.3000 - val_precision: 0.7500 - val_auc: 0.7690\n",
            "Epoch 96/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5574 - accuracy: 0.7014 - sensitivity_at_specificity: 0.8667 - specificity_at_sensitivity: 0.8361 - recall: 0.3619 - precision: 0.6667 - auc: 0.7635\n",
            "Epoch 96: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5560 - accuracy: 0.7031 - sensitivity_at_specificity: 0.8707 - specificity_at_sensitivity: 0.8186 - recall: 0.3966 - precision: 0.6479 - auc: 0.7583 - val_loss: 0.5284 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.8986 - val_specificity_at_sensitivity: 0.9341 - val_recall: 0.7101 - val_precision: 0.7000 - val_auc: 0.8138\n",
            "Epoch 97/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5776 - accuracy: 0.7083 - sensitivity_at_specificity: 0.8158 - specificity_at_sensitivity: 0.8391 - recall: 0.4825 - precision: 0.6875 - auc: 0.7478\n",
            "Epoch 97: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5677 - accuracy: 0.7156 - sensitivity_at_specificity: 0.8240 - specificity_at_sensitivity: 0.8462 - recall: 0.4880 - precision: 0.6932 - auc: 0.7567 - val_loss: 0.6023 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.7778 - val_specificity_at_sensitivity: 0.7835 - val_recall: 0.5397 - val_precision: 0.6182 - val_auc: 0.7167\n",
            "Epoch 98/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5066 - accuracy: 0.7639 - sensitivity_at_specificity: 0.8660 - specificity_at_sensitivity: 0.8901 - recall: 0.5361 - precision: 0.6933 - auc: 0.8008\n",
            "Epoch 98: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5031 - accuracy: 0.7688 - sensitivity_at_specificity: 0.8571 - specificity_at_sensitivity: 0.8884 - recall: 0.5429 - precision: 0.6867 - auc: 0.8019 - val_loss: 0.5912 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.8472 - val_specificity_at_sensitivity: 0.8182 - val_recall: 0.5139 - val_precision: 0.6981 - val_auc: 0.7554\n",
            "Epoch 99/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5434 - accuracy: 0.7326 - sensitivity_at_specificity: 0.8716 - specificity_at_sensitivity: 0.8771 - recall: 0.4954 - precision: 0.7105 - auc: 0.7867\n",
            "Epoch 99: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5514 - accuracy: 0.7219 - sensitivity_at_specificity: 0.8710 - specificity_at_sensitivity: 0.8673 - recall: 0.4919 - precision: 0.7011 - auc: 0.7822 - val_loss: 0.5578 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8831 - val_specificity_at_sensitivity: 0.8554 - val_recall: 0.7143 - val_precision: 0.7333 - val_auc: 0.7873\n",
            "Epoch 100/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5224 - accuracy: 0.7431 - sensitivity_at_specificity: 0.8667 - specificity_at_sensitivity: 0.8798 - recall: 0.6095 - precision: 0.6598 - auc: 0.7965\n",
            "Epoch 100: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5150 - accuracy: 0.7563 - sensitivity_at_specificity: 0.8898 - specificity_at_sensitivity: 0.8911 - recall: 0.6186 - precision: 0.6887 - auc: 0.8050 - val_loss: 0.5282 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.8852 - val_specificity_at_sensitivity: 0.8687 - val_recall: 0.4918 - val_precision: 0.7143 - val_auc: 0.8081\n",
            "Epoch 101/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5686 - accuracy: 0.7049 - sensitivity_at_specificity: 0.8500 - specificity_at_sensitivity: 0.8191 - recall: 0.4800 - precision: 0.5926 - auc: 0.7410\n",
            "Epoch 101: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5728 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8596 - specificity_at_sensitivity: 0.8155 - recall: 0.4561 - precision: 0.6047 - auc: 0.7413 - val_loss: 0.5661 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.8358 - val_specificity_at_sensitivity: 0.8710 - val_recall: 0.4030 - val_precision: 0.7297 - val_auc: 0.7838\n",
            "Epoch 102/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5455 - accuracy: 0.7257 - sensitivity_at_specificity: 0.8173 - specificity_at_sensitivity: 0.8641 - recall: 0.5385 - precision: 0.6437 - auc: 0.7680\n",
            "Epoch 102: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5555 - accuracy: 0.7156 - sensitivity_at_specificity: 0.8000 - specificity_at_sensitivity: 0.8488 - recall: 0.5217 - precision: 0.6250 - auc: 0.7548 - val_loss: 0.5556 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.8409 - val_recall: 0.5694 - val_precision: 0.7455 - val_auc: 0.7898\n",
            "Epoch 103/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4976 - accuracy: 0.7847 - sensitivity_at_specificity: 0.8932 - specificity_at_sensitivity: 0.9243 - recall: 0.5631 - precision: 0.7733 - auc: 0.8287\n",
            "Epoch 103: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5034 - accuracy: 0.7688 - sensitivity_at_specificity: 0.8839 - specificity_at_sensitivity: 0.9087 - recall: 0.5357 - precision: 0.7317 - auc: 0.8168 - val_loss: 0.6450 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.7123 - val_specificity_at_sensitivity: 0.7931 - val_recall: 0.3425 - val_precision: 0.7143 - val_auc: 0.7067\n",
            "Epoch 104/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5432 - accuracy: 0.7292 - sensitivity_at_specificity: 0.8333 - specificity_at_sensitivity: 0.8081 - recall: 0.3333 - precision: 0.6250 - auc: 0.7461\n",
            "Epoch 104: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5419 - accuracy: 0.7250 - sensitivity_at_specificity: 0.8585 - specificity_at_sensitivity: 0.8364 - recall: 0.3396 - precision: 0.6667 - auc: 0.7660 - val_loss: 0.5381 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.8636 - val_specificity_at_sensitivity: 0.9149 - val_recall: 0.5606 - val_precision: 0.6981 - val_auc: 0.7930\n",
            "Epoch 105/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5781 - accuracy: 0.6806 - sensitivity_at_specificity: 0.8230 - specificity_at_sensitivity: 0.8229 - recall: 0.6283 - precision: 0.5868 - auc: 0.7526\n",
            "Epoch 105: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5912 - accuracy: 0.6719 - sensitivity_at_specificity: 0.8095 - specificity_at_sensitivity: 0.8144 - recall: 0.6270 - precision: 0.5766 - auc: 0.7393 - val_loss: 0.5634 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.8684 - val_specificity_at_sensitivity: 0.8452 - val_recall: 0.5921 - val_precision: 0.7031 - val_auc: 0.7787\n",
            "Epoch 106/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5770 - accuracy: 0.6992 - sensitivity_at_specificity: 0.7865 - specificity_at_sensitivity: 0.8024 - recall: 0.3933 - precision: 0.6034 - auc: 0.7256\n",
            "Epoch 106: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5671 - accuracy: 0.7031 - sensitivity_at_specificity: 0.8091 - specificity_at_sensitivity: 0.8000 - recall: 0.4091 - precision: 0.6000 - auc: 0.7360 - val_loss: 0.5876 - val_accuracy: 0.6625 - val_sensitivity_at_specificity: 0.8529 - val_specificity_at_sensitivity: 0.8370 - val_recall: 0.3529 - val_precision: 0.7059 - val_auc: 0.7759\n",
            "Epoch 107/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5434 - accuracy: 0.7361 - sensitivity_at_specificity: 0.8155 - specificity_at_sensitivity: 0.8649 - recall: 0.5534 - precision: 0.6552 - auc: 0.7708\n",
            "Epoch 107: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5410 - accuracy: 0.7406 - sensitivity_at_specificity: 0.8036 - specificity_at_sensitivity: 0.8606 - recall: 0.5357 - precision: 0.6593 - auc: 0.7688 - val_loss: 0.6035 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8125 - val_specificity_at_sensitivity: 0.8438 - val_recall: 0.4844 - val_precision: 0.6889 - val_auc: 0.7252\n",
            "Epoch 108/500\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5381 - accuracy: 0.7321 - sensitivity_at_specificity: 0.8974 - specificity_at_sensitivity: 0.8767 - recall: 0.4487 - precision: 0.6731 - auc: 0.7832\n",
            "Epoch 108: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5551 - accuracy: 0.7219 - sensitivity_at_specificity: 0.8403 - specificity_at_sensitivity: 0.8557 - recall: 0.4370 - precision: 0.7027 - auc: 0.7758 - val_loss: 0.5423 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8551 - val_specificity_at_sensitivity: 0.9560 - val_recall: 0.5942 - val_precision: 0.7455 - val_auc: 0.8031\n",
            "Epoch 109/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5191 - accuracy: 0.7578 - sensitivity_at_specificity: 0.9000 - specificity_at_sensitivity: 0.8693 - recall: 0.7000 - precision: 0.5957 - auc: 0.8062\n",
            "Epoch 109: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5434 - accuracy: 0.7344 - sensitivity_at_specificity: 0.8509 - specificity_at_sensitivity: 0.8544 - recall: 0.6140 - precision: 0.6306 - auc: 0.7783 - val_loss: 0.6190 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.7260 - val_specificity_at_sensitivity: 0.8046 - val_recall: 0.4384 - val_precision: 0.8205 - val_auc: 0.7242\n",
            "Epoch 110/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5831 - accuracy: 0.7109 - sensitivity_at_specificity: 0.8381 - specificity_at_sensitivity: 0.8675 - recall: 0.5524 - precision: 0.6824 - auc: 0.7578\n",
            "Epoch 110: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5588 - accuracy: 0.7344 - sensitivity_at_specificity: 0.8443 - specificity_at_sensitivity: 0.8737 - recall: 0.5738 - precision: 0.6796 - auc: 0.7733 - val_loss: 0.5218 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.8852 - val_specificity_at_sensitivity: 0.9091 - val_recall: 0.6885 - val_precision: 0.6885 - val_auc: 0.8108\n",
            "Epoch 111/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5241 - accuracy: 0.7569 - sensitivity_at_specificity: 0.8761 - specificity_at_sensitivity: 0.9086 - recall: 0.5929 - precision: 0.7363 - auc: 0.8072\n",
            "Epoch 111: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5199 - accuracy: 0.7594 - sensitivity_at_specificity: 0.8819 - specificity_at_sensitivity: 0.9067 - recall: 0.5984 - precision: 0.7451 - auc: 0.8137 - val_loss: 0.5099 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.8636 - val_specificity_at_sensitivity: 0.9043 - val_recall: 0.6818 - val_precision: 0.7627 - val_auc: 0.8274\n",
            "Epoch 112/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5032 - accuracy: 0.7639 - sensitivity_at_specificity: 0.8800 - specificity_at_sensitivity: 0.9096 - recall: 0.5400 - precision: 0.7105 - auc: 0.8069\n",
            "Epoch 112: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4874 - accuracy: 0.7812 - sensitivity_at_specificity: 0.8899 - specificity_at_sensitivity: 0.9194 - recall: 0.5688 - precision: 0.7294 - auc: 0.8202 - val_loss: 0.5630 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.8000 - val_specificity_at_sensitivity: 0.8700 - val_recall: 0.4833 - val_precision: 0.7073 - val_auc: 0.7586\n",
            "Epoch 113/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5208 - accuracy: 0.7639 - sensitivity_at_specificity: 0.8952 - specificity_at_sensitivity: 0.9016 - recall: 0.5333 - precision: 0.7467 - auc: 0.8050\n",
            "Epoch 113: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5267 - accuracy: 0.7656 - sensitivity_at_specificity: 0.8793 - specificity_at_sensitivity: 0.9069 - recall: 0.5259 - precision: 0.7531 - auc: 0.7966 - val_loss: 0.5098 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.8833 - val_specificity_at_sensitivity: 0.9100 - val_recall: 0.5000 - val_precision: 0.7500 - val_auc: 0.8139\n",
            "Epoch 114/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5991 - accuracy: 0.6641 - sensitivity_at_specificity: 0.8476 - specificity_at_sensitivity: 0.7616 - recall: 0.6571 - precision: 0.5798 - auc: 0.7370\n",
            "Epoch 114: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.5888 - accuracy: 0.6750 - sensitivity_at_specificity: 0.8722 - specificity_at_sensitivity: 0.7754 - recall: 0.6692 - precision: 0.5973 - auc: 0.7482 - val_loss: 0.5462 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.8857 - val_specificity_at_sensitivity: 0.9111 - val_recall: 0.6429 - val_precision: 0.7377 - val_auc: 0.7899\n",
            "Epoch 115/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5599 - accuracy: 0.7153 - sensitivity_at_specificity: 0.8750 - specificity_at_sensitivity: 0.8478 - recall: 0.4519 - precision: 0.6528 - auc: 0.7585\n",
            "Epoch 115: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5614 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8707 - specificity_at_sensitivity: 0.8480 - recall: 0.4397 - precision: 0.6711 - auc: 0.7609 - val_loss: 0.5259 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9351 - val_specificity_at_sensitivity: 0.9157 - val_recall: 0.5325 - val_precision: 0.8542 - val_auc: 0.8471\n",
            "Epoch 116/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5532 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8679 - specificity_at_sensitivity: 0.8407 - recall: 0.5283 - precision: 0.6437 - auc: 0.7707\n",
            "Epoch 116: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5472 - accuracy: 0.7250 - sensitivity_at_specificity: 0.8673 - specificity_at_sensitivity: 0.8406 - recall: 0.5310 - precision: 0.6316 - auc: 0.7720 - val_loss: 0.5394 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.9000 - val_specificity_at_sensitivity: 0.9000 - val_recall: 0.6143 - val_precision: 0.6935 - val_auc: 0.8037\n",
            "Epoch 117/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5192 - accuracy: 0.7396 - sensitivity_at_specificity: 0.8571 - specificity_at_sensitivity: 0.8474 - recall: 0.4490 - precision: 0.6769 - auc: 0.7902\n",
            "Epoch 117: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5260 - accuracy: 0.7281 - sensitivity_at_specificity: 0.8661 - specificity_at_sensitivity: 0.8365 - recall: 0.4196 - precision: 0.6812 - auc: 0.7923 - val_loss: 0.6423 - val_accuracy: 0.6687 - val_sensitivity_at_specificity: 0.6338 - val_specificity_at_sensitivity: 0.7978 - val_recall: 0.4507 - val_precision: 0.6957 - val_auc: 0.6935\n",
            "Epoch 118/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5759 - accuracy: 0.7153 - sensitivity_at_specificity: 0.8362 - specificity_at_sensitivity: 0.8314 - recall: 0.6466 - precision: 0.6466 - auc: 0.7551\n",
            "Epoch 118: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5770 - accuracy: 0.7031 - sensitivity_at_specificity: 0.8110 - specificity_at_sensitivity: 0.8394 - recall: 0.6535 - precision: 0.6194 - auc: 0.7550 - val_loss: 0.5713 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.8462 - val_specificity_at_sensitivity: 0.8737 - val_recall: 0.7692 - val_precision: 0.6410 - val_auc: 0.7776\n",
            "Epoch 119/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5362 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8889 - specificity_at_sensitivity: 0.8254 - recall: 0.5152 - precision: 0.6071 - auc: 0.7738\n",
            "Epoch 119: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5495 - accuracy: 0.7094 - sensitivity_at_specificity: 0.8739 - specificity_at_sensitivity: 0.8230 - recall: 0.4865 - precision: 0.6000 - auc: 0.7584 - val_loss: 0.6380 - val_accuracy: 0.6625 - val_sensitivity_at_specificity: 0.7857 - val_specificity_at_sensitivity: 0.9111 - val_recall: 0.3286 - val_precision: 0.7667 - val_auc: 0.7655\n",
            "Epoch 120/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5702 - accuracy: 0.7049 - sensitivity_at_specificity: 0.8491 - specificity_at_sensitivity: 0.8407 - recall: 0.3491 - precision: 0.6981 - auc: 0.7650\n",
            "Epoch 120: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5729 - accuracy: 0.7063 - sensitivity_at_specificity: 0.8417 - specificity_at_sensitivity: 0.8500 - recall: 0.3917 - precision: 0.6912 - auc: 0.7589 - val_loss: 0.5637 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.9143 - val_specificity_at_sensitivity: 0.8556 - val_recall: 0.6429 - val_precision: 0.6618 - val_auc: 0.7861\n",
            "Epoch 121/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5792 - accuracy: 0.7148 - sensitivity_at_specificity: 0.8352 - specificity_at_sensitivity: 0.8424 - recall: 0.6593 - precision: 0.5882 - auc: 0.7433\n",
            "Epoch 121: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5574 - accuracy: 0.7344 - sensitivity_at_specificity: 0.8496 - specificity_at_sensitivity: 0.8599 - recall: 0.6637 - precision: 0.6148 - auc: 0.7669 - val_loss: 0.5235 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.8833 - val_specificity_at_sensitivity: 0.8800 - val_recall: 0.6667 - val_precision: 0.6897 - val_auc: 0.8052\n",
            "Epoch 122/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5432 - accuracy: 0.7014 - sensitivity_at_specificity: 0.8785 - specificity_at_sensitivity: 0.8453 - recall: 0.4112 - precision: 0.6567 - auc: 0.7820\n",
            "Epoch 122: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5442 - accuracy: 0.7031 - sensitivity_at_specificity: 0.8833 - specificity_at_sensitivity: 0.8450 - recall: 0.4250 - precision: 0.6623 - auc: 0.7824 - val_loss: 0.5751 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8800 - val_specificity_at_sensitivity: 0.9176 - val_recall: 0.6000 - val_precision: 0.7895 - val_auc: 0.7892\n",
            "Epoch 123/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5680 - accuracy: 0.6806 - sensitivity_at_specificity: 0.8824 - specificity_at_sensitivity: 0.8107 - recall: 0.5798 - precision: 0.6216 - auc: 0.7699\n",
            "Epoch 123: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5700 - accuracy: 0.6844 - sensitivity_at_specificity: 0.8605 - specificity_at_sensitivity: 0.8168 - recall: 0.5891 - precision: 0.6129 - auc: 0.7652 - val_loss: 0.5228 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.8500 - val_specificity_at_sensitivity: 0.9000 - val_recall: 0.6833 - val_precision: 0.7069 - val_auc: 0.8072\n",
            "Epoch 124/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5321 - accuracy: 0.7500 - sensitivity_at_specificity: 0.8365 - specificity_at_sensitivity: 0.8913 - recall: 0.5096 - precision: 0.7162 - auc: 0.7843\n",
            "Epoch 124: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5349 - accuracy: 0.7375 - sensitivity_at_specificity: 0.8435 - specificity_at_sensitivity: 0.8780 - recall: 0.4870 - precision: 0.6914 - auc: 0.7802 - val_loss: 0.5203 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9062 - val_specificity_at_sensitivity: 0.9062 - val_recall: 0.6250 - val_precision: 0.7843 - val_auc: 0.8094\n",
            "Epoch 125/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5293 - accuracy: 0.7292 - sensitivity_at_specificity: 0.8909 - specificity_at_sensitivity: 0.8652 - recall: 0.5091 - precision: 0.7000 - auc: 0.7984\n",
            "Epoch 125: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5287 - accuracy: 0.7281 - sensitivity_at_specificity: 0.9000 - specificity_at_sensitivity: 0.8550 - recall: 0.5167 - precision: 0.6813 - auc: 0.7950 - val_loss: 0.6505 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.7027 - val_specificity_at_sensitivity: 0.7907 - val_recall: 0.5676 - val_precision: 0.5915 - val_auc: 0.6811\n",
            "Epoch 126/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5506 - accuracy: 0.6875 - sensitivity_at_specificity: 0.8462 - specificity_at_sensitivity: 0.8587 - recall: 0.5288 - precision: 0.5729 - auc: 0.7666\n",
            "Epoch 126: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5362 - accuracy: 0.7063 - sensitivity_at_specificity: 0.8684 - specificity_at_sensitivity: 0.8738 - recall: 0.5439 - precision: 0.5962 - auc: 0.7814 - val_loss: 0.6198 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.8235 - val_specificity_at_sensitivity: 0.8696 - val_recall: 0.3382 - val_precision: 0.8214 - val_auc: 0.7625\n",
            "Epoch 127/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5699 - accuracy: 0.6806 - sensitivity_at_specificity: 0.8739 - specificity_at_sensitivity: 0.8305 - recall: 0.4144 - precision: 0.6301 - auc: 0.7629\n",
            "Epoch 127: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5678 - accuracy: 0.6906 - sensitivity_at_specificity: 0.8678 - specificity_at_sensitivity: 0.8342 - recall: 0.4380 - precision: 0.6310 - auc: 0.7592 - val_loss: 0.5287 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9041 - val_specificity_at_sensitivity: 0.9310 - val_recall: 0.5890 - val_precision: 0.7818 - val_auc: 0.8229\n",
            "Epoch 128/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5735 - accuracy: 0.6944 - sensitivity_at_specificity: 0.8559 - specificity_at_sensitivity: 0.8079 - recall: 0.5225 - precision: 0.6237 - auc: 0.7473\n",
            "Epoch 128: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5597 - accuracy: 0.7125 - sensitivity_at_specificity: 0.8730 - specificity_at_sensitivity: 0.8247 - recall: 0.5556 - precision: 0.6604 - auc: 0.7685 - val_loss: 0.5897 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8088 - val_specificity_at_sensitivity: 0.8696 - val_recall: 0.5147 - val_precision: 0.7292 - val_auc: 0.7400\n",
            "Epoch 129/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5296 - accuracy: 0.7286 - sensitivity_at_specificity: 0.8476 - specificity_at_sensitivity: 0.8629 - recall: 0.5333 - precision: 0.6747 - auc: 0.7912\n",
            "Epoch 129: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5349 - accuracy: 0.7340 - sensitivity_at_specificity: 0.8333 - specificity_at_sensitivity: 0.8586 - recall: 0.5439 - precision: 0.6667 - auc: 0.7806 - val_loss: 0.4632 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9500 - val_specificity_at_sensitivity: 0.9400 - val_recall: 0.7500 - val_precision: 0.6923 - val_auc: 0.8696\n",
            "Epoch 130/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5621 - accuracy: 0.6944 - sensitivity_at_specificity: 0.8739 - specificity_at_sensitivity: 0.8136 - recall: 0.5586 - precision: 0.6139 - auc: 0.7650\n",
            "Epoch 130: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5531 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8898 - specificity_at_sensitivity: 0.8342 - recall: 0.5591 - precision: 0.6396 - auc: 0.7789 - val_loss: 0.5458 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.8281 - val_specificity_at_sensitivity: 0.8542 - val_recall: 0.5469 - val_precision: 0.6863 - val_auc: 0.7843\n",
            "Epoch 131/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5331 - accuracy: 0.7361 - sensitivity_at_specificity: 0.8586 - specificity_at_sensitivity: 0.8730 - recall: 0.5556 - precision: 0.6322 - auc: 0.7783\n",
            "Epoch 131: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5344 - accuracy: 0.7406 - sensitivity_at_specificity: 0.8532 - specificity_at_sensitivity: 0.8815 - recall: 0.5413 - precision: 0.6413 - auc: 0.7729 - val_loss: 0.5070 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.9683 - val_specificity_at_sensitivity: 0.9072 - val_recall: 0.3968 - val_precision: 0.8065 - val_auc: 0.8564\n",
            "Epoch 132/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5466 - accuracy: 0.7083 - sensitivity_at_specificity: 0.9018 - specificity_at_sensitivity: 0.8580 - recall: 0.4554 - precision: 0.6892 - auc: 0.7889\n",
            "Epoch 132: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5388 - accuracy: 0.7156 - sensitivity_at_specificity: 0.8952 - specificity_at_sensitivity: 0.8571 - recall: 0.4839 - precision: 0.6897 - auc: 0.7938 - val_loss: 0.5265 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.8125 - val_specificity_at_sensitivity: 0.9583 - val_recall: 0.7031 - val_precision: 0.7377 - val_auc: 0.8070\n",
            "Epoch 133/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5222 - accuracy: 0.7500 - sensitivity_at_specificity: 0.8889 - specificity_at_sensitivity: 0.8783 - recall: 0.6768 - precision: 0.6262 - auc: 0.7984\n",
            "Epoch 133: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5329 - accuracy: 0.7375 - sensitivity_at_specificity: 0.8761 - specificity_at_sensitivity: 0.8696 - recall: 0.6372 - precision: 0.6261 - auc: 0.7848 - val_loss: 0.5330 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9091 - val_specificity_at_sensitivity: 0.9468 - val_recall: 0.4697 - val_precision: 0.8857 - val_auc: 0.8256\n",
            "Epoch 134/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4728 - accuracy: 0.7708 - sensitivity_at_specificity: 0.9706 - specificity_at_sensitivity: 0.9086 - recall: 0.5588 - precision: 0.7308 - auc: 0.8512\n",
            "Epoch 134: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4806 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9561 - specificity_at_sensitivity: 0.9126 - recall: 0.5526 - precision: 0.7412 - auc: 0.8432 - val_loss: 0.6279 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8052 - val_specificity_at_sensitivity: 0.8795 - val_recall: 0.5065 - val_precision: 0.7959 - val_auc: 0.7404\n",
            "Epoch 135/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5768 - accuracy: 0.6806 - sensitivity_at_specificity: 0.8241 - specificity_at_sensitivity: 0.7944 - recall: 0.4815 - precision: 0.5909 - auc: 0.7371\n",
            "Epoch 135: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5706 - accuracy: 0.6875 - sensitivity_at_specificity: 0.8235 - specificity_at_sensitivity: 0.8010 - recall: 0.4958 - precision: 0.5960 - auc: 0.7419 - val_loss: 0.5776 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.8243 - val_specificity_at_sensitivity: 0.8372 - val_recall: 0.6757 - val_precision: 0.6579 - val_auc: 0.7693\n",
            "Epoch 136/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5661 - accuracy: 0.7153 - sensitivity_at_specificity: 0.8148 - specificity_at_sensitivity: 0.8444 - recall: 0.5093 - precision: 0.6548 - auc: 0.7525\n",
            "Epoch 136: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5555 - accuracy: 0.7219 - sensitivity_at_specificity: 0.8291 - specificity_at_sensitivity: 0.8374 - recall: 0.4957 - precision: 0.6591 - auc: 0.7601 - val_loss: 0.5943 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.7761 - val_specificity_at_sensitivity: 0.8925 - val_recall: 0.5672 - val_precision: 0.6786 - val_auc: 0.7436\n",
            "Epoch 137/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5576 - accuracy: 0.7153 - sensitivity_at_specificity: 0.8796 - specificity_at_sensitivity: 0.8444 - recall: 0.5000 - precision: 0.6585 - auc: 0.7650\n",
            "Epoch 137: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5431 - accuracy: 0.7312 - sensitivity_at_specificity: 0.8803 - specificity_at_sensitivity: 0.8571 - recall: 0.5128 - precision: 0.6742 - auc: 0.7768 - val_loss: 0.5338 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9367 - val_specificity_at_sensitivity: 0.8395 - val_recall: 0.6962 - val_precision: 0.7432 - val_auc: 0.8159\n",
            "Epoch 138/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5822 - accuracy: 0.6875 - sensitivity_at_specificity: 0.8393 - specificity_at_sensitivity: 0.7841 - recall: 0.5446 - precision: 0.6100 - auc: 0.7391\n",
            "Epoch 138: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5790 - accuracy: 0.6938 - sensitivity_at_specificity: 0.8306 - specificity_at_sensitivity: 0.7959 - recall: 0.5403 - precision: 0.6204 - auc: 0.7415 - val_loss: 0.5505 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8551 - val_specificity_at_sensitivity: 0.9231 - val_recall: 0.5217 - val_precision: 0.8000 - val_auc: 0.8017\n",
            "Epoch 139/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5776 - accuracy: 0.7118 - sensitivity_at_specificity: 0.7984 - specificity_at_sensitivity: 0.8994 - recall: 0.5736 - precision: 0.7255 - auc: 0.7644\n",
            "Epoch 139: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5639 - accuracy: 0.7250 - sensitivity_at_specificity: 0.8102 - specificity_at_sensitivity: 0.9016 - recall: 0.5839 - precision: 0.7207 - auc: 0.7717 - val_loss: 0.5489 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.8472 - val_specificity_at_sensitivity: 0.9091 - val_recall: 0.6528 - val_precision: 0.6438 - val_auc: 0.7988\n",
            "Epoch 140/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5309 - accuracy: 0.7292 - sensitivity_at_specificity: 0.8878 - specificity_at_sensitivity: 0.8526 - recall: 0.5000 - precision: 0.6282 - auc: 0.7759\n",
            "Epoch 140: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5282 - accuracy: 0.7250 - sensitivity_at_specificity: 0.8938 - specificity_at_sensitivity: 0.8551 - recall: 0.4779 - precision: 0.6506 - auc: 0.7871 - val_loss: 0.5616 - val_accuracy: 0.6687 - val_sensitivity_at_specificity: 0.8871 - val_specificity_at_sensitivity: 0.7959 - val_recall: 0.4194 - val_precision: 0.6047 - val_auc: 0.7763\n",
            "Epoch 141/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5470 - accuracy: 0.7109 - sensitivity_at_specificity: 0.9032 - specificity_at_sensitivity: 0.7975 - recall: 0.4839 - precision: 0.6338 - auc: 0.7702\n",
            "Epoch 141: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5459 - accuracy: 0.7156 - sensitivity_at_specificity: 0.9043 - specificity_at_sensitivity: 0.8390 - recall: 0.5043 - precision: 0.6304 - auc: 0.7708 - val_loss: 0.5680 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.8857 - val_specificity_at_sensitivity: 0.8111 - val_recall: 0.5857 - val_precision: 0.6508 - val_auc: 0.7698\n",
            "Epoch 142/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4994 - accuracy: 0.7812 - sensitivity_at_specificity: 0.8641 - specificity_at_sensitivity: 0.9351 - recall: 0.5631 - precision: 0.7632 - auc: 0.8230\n",
            "Epoch 142: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5054 - accuracy: 0.7656 - sensitivity_at_specificity: 0.8729 - specificity_at_sensitivity: 0.9059 - recall: 0.5424 - precision: 0.7529 - auc: 0.8222 - val_loss: 0.5713 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.8000 - val_specificity_at_sensitivity: 0.8100 - val_recall: 0.4500 - val_precision: 0.6279 - val_auc: 0.7489\n",
            "Epoch 143/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5021 - accuracy: 0.7257 - sensitivity_at_specificity: 0.9184 - specificity_at_sensitivity: 0.8421 - recall: 0.4796 - precision: 0.6267 - auc: 0.8078\n",
            "Epoch 143: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5204 - accuracy: 0.7156 - sensitivity_at_specificity: 0.9115 - specificity_at_sensitivity: 0.8309 - recall: 0.4867 - precision: 0.6250 - auc: 0.7933 - val_loss: 0.5767 - val_accuracy: 0.6687 - val_sensitivity_at_specificity: 0.8393 - val_specificity_at_sensitivity: 0.7981 - val_recall: 0.5179 - val_precision: 0.5273 - val_auc: 0.7353\n",
            "Epoch 144/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4939 - accuracy: 0.7500 - sensitivity_at_specificity: 0.9151 - specificity_at_sensitivity: 0.9066 - recall: 0.6132 - precision: 0.6771 - auc: 0.8260\n",
            "Epoch 144: val_accuracy did not improve from 0.78125\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.4981 - accuracy: 0.7500 - sensitivity_at_specificity: 0.9145 - specificity_at_sensitivity: 0.9015 - recall: 0.6154 - precision: 0.6729 - auc: 0.8230 - val_loss: 0.5127 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.8571 - val_specificity_at_sensitivity: 0.8654 - val_recall: 0.6071 - val_precision: 0.6538 - val_auc: 0.8043\n",
            "Epoch 145/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5414 - accuracy: 0.7465 - sensitivity_at_specificity: 0.8396 - specificity_at_sensitivity: 0.8956 - recall: 0.5094 - precision: 0.7200 - auc: 0.7729\n",
            "Epoch 145: val_accuracy improved from 0.78125 to 0.78750, saving model to ECG_Model_Lead_1.h5\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5340 - accuracy: 0.7500 - sensitivity_at_specificity: 0.8500 - specificity_at_sensitivity: 0.9000 - recall: 0.5167 - precision: 0.7381 - auc: 0.7856 - val_loss: 0.4722 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.8667 - val_specificity_at_sensitivity: 0.9400 - val_recall: 0.6667 - val_precision: 0.7407 - val_auc: 0.8403\n",
            "Epoch 146/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5638 - accuracy: 0.6944 - sensitivity_at_specificity: 0.8485 - specificity_at_sensitivity: 0.7778 - recall: 0.4040 - precision: 0.5797 - auc: 0.7411\n",
            "Epoch 146: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5578 - accuracy: 0.6969 - sensitivity_at_specificity: 0.8378 - specificity_at_sensitivity: 0.7895 - recall: 0.4054 - precision: 0.5921 - auc: 0.7495 - val_loss: 0.5679 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.8676 - val_specificity_at_sensitivity: 0.8804 - val_recall: 0.5294 - val_precision: 0.7500 - val_auc: 0.7743\n",
            "Epoch 147/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4953 - accuracy: 0.7569 - sensitivity_at_specificity: 0.9184 - specificity_at_sensitivity: 0.8737 - recall: 0.6224 - precision: 0.6489 - auc: 0.8194\n",
            "Epoch 147: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4956 - accuracy: 0.7563 - sensitivity_at_specificity: 0.9159 - specificity_at_sensitivity: 0.8685 - recall: 0.6262 - precision: 0.6381 - auc: 0.8175 - val_loss: 0.4969 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.8750 - val_specificity_at_sensitivity: 0.9432 - val_recall: 0.6389 - val_precision: 0.8214 - val_auc: 0.8505\n",
            "Epoch 148/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5321 - accuracy: 0.7396 - sensitivity_at_specificity: 0.8713 - specificity_at_sensitivity: 0.8770 - recall: 0.4158 - precision: 0.7241 - auc: 0.7869\n",
            "Epoch 148: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5423 - accuracy: 0.7469 - sensitivity_at_specificity: 0.8696 - specificity_at_sensitivity: 0.8829 - recall: 0.4522 - precision: 0.7429 - auc: 0.7797 - val_loss: 0.5202 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.8254 - val_specificity_at_sensitivity: 0.9381 - val_recall: 0.6349 - val_precision: 0.7018 - val_auc: 0.8023\n",
            "Epoch 149/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5343 - accuracy: 0.7153 - sensitivity_at_specificity: 0.8785 - specificity_at_sensitivity: 0.8619 - recall: 0.6449 - precision: 0.6106 - auc: 0.7865\n",
            "Epoch 149: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5228 - accuracy: 0.7250 - sensitivity_at_specificity: 0.8898 - specificity_at_sensitivity: 0.8713 - recall: 0.6441 - precision: 0.6230 - auc: 0.7959 - val_loss: 0.5874 - val_accuracy: 0.6625 - val_sensitivity_at_specificity: 0.8784 - val_specificity_at_sensitivity: 0.8488 - val_recall: 0.4324 - val_precision: 0.7273 - val_auc: 0.7928\n",
            "Epoch 150/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5189 - accuracy: 0.7326 - sensitivity_at_specificity: 0.9009 - specificity_at_sensitivity: 0.9040 - recall: 0.5495 - precision: 0.6932 - auc: 0.8080\n",
            "Epoch 150: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5260 - accuracy: 0.7250 - sensitivity_at_specificity: 0.8824 - specificity_at_sensitivity: 0.8856 - recall: 0.5378 - precision: 0.6598 - auc: 0.7942 - val_loss: 0.5957 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.7778 - val_specificity_at_sensitivity: 0.8409 - val_recall: 0.5694 - val_precision: 0.7193 - val_auc: 0.7498\n",
            "Epoch 151/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5470 - accuracy: 0.7014 - sensitivity_at_specificity: 0.8783 - specificity_at_sensitivity: 0.8208 - recall: 0.5478 - precision: 0.6495 - auc: 0.7831\n",
            "Epoch 151: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5378 - accuracy: 0.7125 - sensitivity_at_specificity: 0.8780 - specificity_at_sensitivity: 0.8325 - recall: 0.5447 - precision: 0.6505 - auc: 0.7876 - val_loss: 0.5804 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.8500 - val_recall: 0.5667 - val_precision: 0.6182 - val_auc: 0.7393\n",
            "Epoch 152/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5354 - accuracy: 0.7222 - sensitivity_at_specificity: 0.8952 - specificity_at_sensitivity: 0.8470 - recall: 0.5429 - precision: 0.6404 - auc: 0.7893\n",
            "Epoch 152: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5585 - accuracy: 0.7156 - sensitivity_at_specificity: 0.8583 - specificity_at_sensitivity: 0.8500 - recall: 0.5083 - precision: 0.6559 - auc: 0.7655 - val_loss: 0.5918 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.9459 - val_specificity_at_sensitivity: 0.8605 - val_recall: 0.4324 - val_precision: 0.7805 - val_auc: 0.7900\n",
            "Epoch 153/500\n",
            " 6/10 [=================>............] - ETA: 0s - loss: 0.5801 - accuracy: 0.7083 - sensitivity_at_specificity: 0.8158 - specificity_at_sensitivity: 0.8448 - recall: 0.5000 - precision: 0.6786 - auc: 0.7422\n",
            "Epoch 153: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5532 - accuracy: 0.7344 - sensitivity_at_specificity: 0.8000 - specificity_at_sensitivity: 0.8585 - recall: 0.5826 - precision: 0.6442 - auc: 0.7615 - val_loss: 0.5364 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8873 - val_specificity_at_sensitivity: 0.8989 - val_recall: 0.6197 - val_precision: 0.7458 - val_auc: 0.8031\n",
            "Epoch 154/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5465 - accuracy: 0.7465 - sensitivity_at_specificity: 0.8491 - specificity_at_sensitivity: 0.9176 - recall: 0.4528 - precision: 0.7619 - auc: 0.7784\n",
            "Epoch 154: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5359 - accuracy: 0.7563 - sensitivity_at_specificity: 0.8559 - specificity_at_sensitivity: 0.9257 - recall: 0.4661 - precision: 0.7857 - auc: 0.7911 - val_loss: 0.5997 - val_accuracy: 0.6687 - val_sensitivity_at_specificity: 0.8718 - val_specificity_at_sensitivity: 0.9146 - val_recall: 0.4103 - val_precision: 0.8205 - val_auc: 0.8037\n",
            "Epoch 155/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5544 - accuracy: 0.7222 - sensitivity_at_specificity: 0.8770 - specificity_at_sensitivity: 0.8434 - recall: 0.6230 - precision: 0.6909 - auc: 0.7862\n",
            "Epoch 155: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.5486 - accuracy: 0.7312 - sensitivity_at_specificity: 0.8692 - specificity_at_sensitivity: 0.8526 - recall: 0.6231 - precision: 0.6864 - auc: 0.7877 - val_loss: 0.5094 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.9194 - val_specificity_at_sensitivity: 0.8878 - val_recall: 0.7581 - val_precision: 0.6912 - val_auc: 0.8321\n",
            "Epoch 156/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5440 - accuracy: 0.7361 - sensitivity_at_specificity: 0.8687 - specificity_at_sensitivity: 0.8519 - recall: 0.5152 - precision: 0.6456 - auc: 0.7667\n",
            "Epoch 156: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5482 - accuracy: 0.7312 - sensitivity_at_specificity: 0.8761 - specificity_at_sensitivity: 0.8406 - recall: 0.4956 - precision: 0.6588 - auc: 0.7681 - val_loss: 0.5630 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8636 - val_specificity_at_sensitivity: 0.8617 - val_recall: 0.4697 - val_precision: 0.7209 - val_auc: 0.7787\n",
            "Epoch 157/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5539 - accuracy: 0.7326 - sensitivity_at_specificity: 0.8850 - specificity_at_sensitivity: 0.8400 - recall: 0.5752 - precision: 0.6915 - auc: 0.7770\n",
            "Epoch 157: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5550 - accuracy: 0.7375 - sensitivity_at_specificity: 0.8880 - specificity_at_sensitivity: 0.8462 - recall: 0.5920 - precision: 0.6916 - auc: 0.7736 - val_loss: 0.5091 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9180 - val_specificity_at_sensitivity: 0.9192 - val_recall: 0.7541 - val_precision: 0.6301 - val_auc: 0.8313\n",
            "Epoch 158/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5480 - accuracy: 0.7500 - sensitivity_at_specificity: 0.8426 - specificity_at_sensitivity: 0.9000 - recall: 0.6389 - precision: 0.6765 - auc: 0.7801\n",
            "Epoch 158: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.5517 - accuracy: 0.7344 - sensitivity_at_specificity: 0.8455 - specificity_at_sensitivity: 0.8680 - recall: 0.5935 - precision: 0.6759 - auc: 0.7766 - val_loss: 0.5367 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.9028 - val_specificity_at_sensitivity: 0.9091 - val_recall: 0.5556 - val_precision: 0.8163 - val_auc: 0.8336\n",
            "Epoch 159/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5837 - accuracy: 0.7014 - sensitivity_at_specificity: 0.8019 - specificity_at_sensitivity: 0.8242 - recall: 0.4623 - precision: 0.6282 - auc: 0.7301\n",
            "Epoch 159: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5883 - accuracy: 0.6938 - sensitivity_at_specificity: 0.7966 - specificity_at_sensitivity: 0.8119 - recall: 0.4407 - precision: 0.6190 - auc: 0.7250 - val_loss: 0.5175 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.8657 - val_specificity_at_sensitivity: 0.9355 - val_recall: 0.5821 - val_precision: 0.7800 - val_auc: 0.8334\n",
            "Epoch 160/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4840 - accuracy: 0.7917 - sensitivity_at_specificity: 0.8857 - specificity_at_sensitivity: 0.9290 - recall: 0.5810 - precision: 0.7922 - auc: 0.8449\n",
            "Epoch 160: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4899 - accuracy: 0.7844 - sensitivity_at_specificity: 0.8947 - specificity_at_sensitivity: 0.9175 - recall: 0.5789 - precision: 0.7586 - auc: 0.8367 - val_loss: 0.5564 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.7869 - val_specificity_at_sensitivity: 0.8889 - val_recall: 0.6393 - val_precision: 0.6964 - val_auc: 0.7697\n",
            "Epoch 161/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4779 - accuracy: 0.7986 - sensitivity_at_specificity: 0.8617 - specificity_at_sensitivity: 0.9433 - recall: 0.5638 - precision: 0.7571 - auc: 0.8161\n",
            "Epoch 161: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4714 - accuracy: 0.8000 - sensitivity_at_specificity: 0.8796 - specificity_at_sensitivity: 0.9481 - recall: 0.5648 - precision: 0.7821 - auc: 0.8319 - val_loss: 0.5611 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.8649 - val_specificity_at_sensitivity: 0.9419 - val_recall: 0.5541 - val_precision: 0.8039 - val_auc: 0.8214\n",
            "Epoch 162/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4722 - accuracy: 0.7917 - sensitivity_at_specificity: 0.8641 - specificity_at_sensitivity: 0.9189 - recall: 0.6505 - precision: 0.7363 - auc: 0.8378\n",
            "Epoch 162: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4614 - accuracy: 0.8000 - sensitivity_at_specificity: 0.8761 - specificity_at_sensitivity: 0.9372 - recall: 0.6726 - precision: 0.7379 - auc: 0.8467 - val_loss: 0.5544 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.8857 - val_specificity_at_sensitivity: 0.9111 - val_recall: 0.7000 - val_precision: 0.7313 - val_auc: 0.7921\n",
            "Epoch 163/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5389 - accuracy: 0.7361 - sensitivity_at_specificity: 0.8725 - specificity_at_sensitivity: 0.8656 - recall: 0.6176 - precision: 0.6300 - auc: 0.7791\n",
            "Epoch 163: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5490 - accuracy: 0.7344 - sensitivity_at_specificity: 0.8482 - specificity_at_sensitivity: 0.8702 - recall: 0.5893 - precision: 0.6286 - auc: 0.7670 - val_loss: 0.5805 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.8209 - val_specificity_at_sensitivity: 0.9247 - val_recall: 0.5075 - val_precision: 0.8095 - val_auc: 0.7758\n",
            "Epoch 164/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4962 - accuracy: 0.7778 - sensitivity_at_specificity: 0.9018 - specificity_at_sensitivity: 0.9148 - recall: 0.5982 - precision: 0.7791 - auc: 0.8263\n",
            "Epoch 164: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4986 - accuracy: 0.7719 - sensitivity_at_specificity: 0.8960 - specificity_at_sensitivity: 0.9026 - recall: 0.6000 - precision: 0.7653 - auc: 0.8246 - val_loss: 0.6065 - val_accuracy: 0.6687 - val_sensitivity_at_specificity: 0.8611 - val_specificity_at_sensitivity: 0.7955 - val_recall: 0.6528 - val_precision: 0.6267 - val_auc: 0.7368\n",
            "Epoch 165/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5152 - accuracy: 0.7639 - sensitivity_at_specificity: 0.9216 - specificity_at_sensitivity: 0.8978 - recall: 0.5882 - precision: 0.6977 - auc: 0.8018\n",
            "Epoch 165: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5240 - accuracy: 0.7500 - sensitivity_at_specificity: 0.9123 - specificity_at_sensitivity: 0.8786 - recall: 0.5614 - precision: 0.6809 - auc: 0.7920 - val_loss: 0.5405 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.8714 - val_specificity_at_sensitivity: 0.9333 - val_recall: 0.5429 - val_precision: 0.8444 - val_auc: 0.8234\n",
            "Epoch 166/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5363 - accuracy: 0.7396 - sensitivity_at_specificity: 0.8960 - specificity_at_sensitivity: 0.9141 - recall: 0.5760 - precision: 0.7660 - auc: 0.8087\n",
            "Epoch 166: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5342 - accuracy: 0.7375 - sensitivity_at_specificity: 0.8963 - specificity_at_sensitivity: 0.9135 - recall: 0.5926 - precision: 0.7339 - auc: 0.8049 - val_loss: 0.5551 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8472 - val_specificity_at_sensitivity: 0.9318 - val_recall: 0.7778 - val_precision: 0.6364 - val_auc: 0.8003\n",
            "Epoch 167/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5149 - accuracy: 0.7604 - sensitivity_at_specificity: 0.8454 - specificity_at_sensitivity: 0.8796 - recall: 0.6082 - precision: 0.6556 - auc: 0.7966\n",
            "Epoch 167: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5153 - accuracy: 0.7531 - sensitivity_at_specificity: 0.8716 - specificity_at_sensitivity: 0.8910 - recall: 0.5596 - precision: 0.6630 - auc: 0.7948 - val_loss: 0.6305 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.8295 - val_recall: 0.4167 - val_precision: 0.7692 - val_auc: 0.7652\n",
            "Epoch 168/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5275 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8868 - specificity_at_sensitivity: 0.8571 - recall: 0.4717 - precision: 0.6667 - auc: 0.7958\n",
            "Epoch 168: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5286 - accuracy: 0.7250 - sensitivity_at_specificity: 0.8898 - specificity_at_sensitivity: 0.8614 - recall: 0.4915 - precision: 0.6744 - auc: 0.7943 - val_loss: 0.5895 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.7705 - val_specificity_at_sensitivity: 0.8384 - val_recall: 0.5902 - val_precision: 0.5806 - val_auc: 0.7359\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5261 - accuracy: 0.7281 - sensitivity_at_specificity: 0.8843 - specificity_at_sensitivity: 0.8894 - recall: 0.6116 - precision: 0.6491 - auc: 0.7982\n",
            "Epoch 169: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5261 - accuracy: 0.7281 - sensitivity_at_specificity: 0.8843 - specificity_at_sensitivity: 0.8894 - recall: 0.6116 - precision: 0.6491 - auc: 0.7982 - val_loss: 0.5326 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.8197 - val_specificity_at_sensitivity: 0.9192 - val_recall: 0.6393 - val_precision: 0.7091 - val_auc: 0.7923\n",
            "Epoch 170/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5308 - accuracy: 0.7292 - sensitivity_at_specificity: 0.8926 - specificity_at_sensitivity: 0.8862 - recall: 0.6198 - precision: 0.7009 - auc: 0.8026\n",
            "Epoch 170: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5309 - accuracy: 0.7281 - sensitivity_at_specificity: 0.8939 - specificity_at_sensitivity: 0.8723 - recall: 0.5985 - precision: 0.6991 - auc: 0.8008 - val_loss: 0.5080 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.9118 - val_specificity_at_sensitivity: 0.9022 - val_recall: 0.7059 - val_precision: 0.7742 - val_auc: 0.8309\n",
            "Epoch 171/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5246 - accuracy: 0.7118 - sensitivity_at_specificity: 0.8932 - specificity_at_sensitivity: 0.8378 - recall: 0.5340 - precision: 0.6111 - auc: 0.7913\n",
            "Epoch 171: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5416 - accuracy: 0.7063 - sensitivity_at_specificity: 0.8852 - specificity_at_sensitivity: 0.8283 - recall: 0.5246 - precision: 0.6400 - auc: 0.7847 - val_loss: 0.5503 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.8361 - val_specificity_at_sensitivity: 0.9091 - val_recall: 0.5246 - val_precision: 0.7273 - val_auc: 0.7731\n",
            "Epoch 172/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5171 - accuracy: 0.7500 - sensitivity_at_specificity: 0.9167 - specificity_at_sensitivity: 0.8722 - recall: 0.6204 - precision: 0.6837 - auc: 0.8071\n",
            "Epoch 172: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5307 - accuracy: 0.7375 - sensitivity_at_specificity: 0.9174 - specificity_at_sensitivity: 0.8442 - recall: 0.6198 - precision: 0.6637 - auc: 0.7969 - val_loss: 0.5387 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.9028 - val_specificity_at_sensitivity: 0.8864 - val_recall: 0.6111 - val_precision: 0.7333 - val_auc: 0.8072\n",
            "Epoch 173/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5456 - accuracy: 0.7396 - sensitivity_at_specificity: 0.8707 - specificity_at_sensitivity: 0.9012 - recall: 0.5431 - precision: 0.7412 - auc: 0.7871\n",
            "Epoch 173: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5394 - accuracy: 0.7437 - sensitivity_at_specificity: 0.8750 - specificity_at_sensitivity: 0.9115 - recall: 0.5391 - precision: 0.7500 - auc: 0.7928 - val_loss: 0.6305 - val_accuracy: 0.6687 - val_sensitivity_at_specificity: 0.7761 - val_specificity_at_sensitivity: 0.7527 - val_recall: 0.4328 - val_precision: 0.6591 - val_auc: 0.7067\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5471 - accuracy: 0.6969 - sensitivity_at_specificity: 0.9021 - specificity_at_sensitivity: 0.8475 - recall: 0.5734 - precision: 0.6949 - auc: 0.7947\n",
            "Epoch 174: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5471 - accuracy: 0.6969 - sensitivity_at_specificity: 0.9021 - specificity_at_sensitivity: 0.8475 - recall: 0.5734 - precision: 0.6949 - auc: 0.7947 - val_loss: 0.5756 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.8553 - val_specificity_at_sensitivity: 0.8571 - val_recall: 0.6974 - val_precision: 0.6709 - val_auc: 0.7688\n",
            "Epoch 175/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5481 - accuracy: 0.7222 - sensitivity_at_specificity: 0.8909 - specificity_at_sensitivity: 0.8652 - recall: 0.6182 - precision: 0.6415 - auc: 0.7793\n",
            "Epoch 175: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5373 - accuracy: 0.7344 - sensitivity_at_specificity: 0.8926 - specificity_at_sensitivity: 0.8744 - recall: 0.6364 - precision: 0.6525 - auc: 0.7892 - val_loss: 0.5059 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.9524 - val_specificity_at_sensitivity: 0.8763 - val_recall: 0.5873 - val_precision: 0.6607 - val_auc: 0.8195\n",
            "Epoch 176/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5180 - accuracy: 0.7361 - sensitivity_at_specificity: 0.9123 - specificity_at_sensitivity: 0.8851 - recall: 0.5702 - precision: 0.7065 - auc: 0.8123\n",
            "Epoch 176: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5216 - accuracy: 0.7281 - sensitivity_at_specificity: 0.9127 - specificity_at_sensitivity: 0.8711 - recall: 0.5635 - precision: 0.6893 - auc: 0.8075 - val_loss: 0.5691 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.8267 - val_specificity_at_sensitivity: 0.8941 - val_recall: 0.6933 - val_precision: 0.7647 - val_auc: 0.7841\n",
            "Epoch 177/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4982 - accuracy: 0.7465 - sensitivity_at_specificity: 0.8942 - specificity_at_sensitivity: 0.8859 - recall: 0.6250 - precision: 0.6566 - auc: 0.8173\n",
            "Epoch 177: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5021 - accuracy: 0.7531 - sensitivity_at_specificity: 0.8673 - specificity_at_sensitivity: 0.8889 - recall: 0.6106 - precision: 0.6635 - auc: 0.8098 - val_loss: 0.5493 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.9275 - val_specificity_at_sensitivity: 0.9341 - val_recall: 0.3623 - val_precision: 0.8333 - val_auc: 0.8449\n",
            "Epoch 178/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5537 - accuracy: 0.7049 - sensitivity_at_specificity: 0.8661 - specificity_at_sensitivity: 0.8580 - recall: 0.4464 - precision: 0.6849 - auc: 0.7811\n",
            "Epoch 178: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5570 - accuracy: 0.7031 - sensitivity_at_specificity: 0.8710 - specificity_at_sensitivity: 0.8316 - recall: 0.4919 - precision: 0.6559 - auc: 0.7729 - val_loss: 0.5845 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.8116 - val_specificity_at_sensitivity: 0.8571 - val_recall: 0.7536 - val_precision: 0.6047 - val_auc: 0.7704\n",
            "Epoch 179/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4980 - accuracy: 0.7396 - sensitivity_at_specificity: 0.9266 - specificity_at_sensitivity: 0.9441 - recall: 0.7248 - precision: 0.6371 - auc: 0.8390\n",
            "Epoch 179: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5059 - accuracy: 0.7312 - sensitivity_at_specificity: 0.9167 - specificity_at_sensitivity: 0.9100 - recall: 0.6833 - precision: 0.6308 - auc: 0.8259 - val_loss: 0.5331 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.9155 - val_specificity_at_sensitivity: 0.9213 - val_recall: 0.5775 - val_precision: 0.8039 - val_auc: 0.8322\n",
            "Epoch 180/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5346 - accuracy: 0.7431 - sensitivity_at_specificity: 0.8598 - specificity_at_sensitivity: 0.8950 - recall: 0.4206 - precision: 0.7895 - auc: 0.8026\n",
            "Epoch 180: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5258 - accuracy: 0.7531 - sensitivity_at_specificity: 0.8632 - specificity_at_sensitivity: 0.8916 - recall: 0.4444 - precision: 0.7879 - auc: 0.8041 - val_loss: 0.6406 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.7429 - val_specificity_at_sensitivity: 0.8111 - val_recall: 0.4857 - val_precision: 0.6800 - val_auc: 0.6914\n",
            "Epoch 181/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5435 - accuracy: 0.7118 - sensitivity_at_specificity: 0.8611 - specificity_at_sensitivity: 0.8556 - recall: 0.5926 - precision: 0.6214 - auc: 0.7860\n",
            "Epoch 181: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5359 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8667 - specificity_at_sensitivity: 0.8600 - recall: 0.6000 - precision: 0.6316 - auc: 0.7942 - val_loss: 0.5563 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.8358 - val_specificity_at_sensitivity: 0.8710 - val_recall: 0.5522 - val_precision: 0.7400 - val_auc: 0.7807\n",
            "Epoch 182/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4906 - accuracy: 0.7604 - sensitivity_at_specificity: 0.9189 - specificity_at_sensitivity: 0.8983 - recall: 0.5766 - precision: 0.7442 - auc: 0.8388\n",
            "Epoch 182: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4959 - accuracy: 0.7563 - sensitivity_at_specificity: 0.9180 - specificity_at_sensitivity: 0.8889 - recall: 0.5820 - precision: 0.7245 - auc: 0.8311 - val_loss: 0.5738 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.8824 - val_specificity_at_sensitivity: 0.8587 - val_recall: 0.5882 - val_precision: 0.6452 - val_auc: 0.7619\n",
            "Epoch 183/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4434 - accuracy: 0.7951 - sensitivity_at_specificity: 0.9500 - specificity_at_sensitivity: 0.8798 - recall: 0.5875 - precision: 0.6438 - auc: 0.8517\n",
            "Epoch 183: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4401 - accuracy: 0.7969 - sensitivity_at_specificity: 0.9195 - specificity_at_sensitivity: 0.8927 - recall: 0.5517 - precision: 0.6486 - auc: 0.8441 - val_loss: 0.6894 - val_accuracy: 0.6500 - val_sensitivity_at_specificity: 0.8644 - val_specificity_at_sensitivity: 0.9010 - val_recall: 0.1017 - val_precision: 0.6667 - val_auc: 0.7982\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6052 - accuracy: 0.6844 - sensitivity_at_specificity: 0.7869 - specificity_at_sensitivity: 0.7626 - recall: 0.4754 - precision: 0.6105 - auc: 0.7277\n",
            "Epoch 184: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.6052 - accuracy: 0.6844 - sensitivity_at_specificity: 0.7869 - specificity_at_sensitivity: 0.7626 - recall: 0.4754 - precision: 0.6105 - auc: 0.7277 - val_loss: 0.5675 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.8462 - val_specificity_at_sensitivity: 0.8947 - val_recall: 0.7846 - val_precision: 0.6220 - val_auc: 0.7917\n",
            "Epoch 185/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5365 - accuracy: 0.7257 - sensitivity_at_specificity: 0.8807 - specificity_at_sensitivity: 0.8603 - recall: 0.6789 - precision: 0.6271 - auc: 0.8053\n",
            "Epoch 185: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5389 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8525 - specificity_at_sensitivity: 0.8687 - recall: 0.6393 - precision: 0.6290 - auc: 0.7949 - val_loss: 0.5713 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.8000 - val_specificity_at_sensitivity: 0.8632 - val_recall: 0.3846 - val_precision: 0.6944 - val_auc: 0.7653\n",
            "Epoch 186/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5664 - accuracy: 0.7049 - sensitivity_at_specificity: 0.8407 - specificity_at_sensitivity: 0.8343 - recall: 0.4071 - precision: 0.7188 - auc: 0.7713\n",
            "Epoch 186: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5686 - accuracy: 0.7063 - sensitivity_at_specificity: 0.8492 - specificity_at_sensitivity: 0.8454 - recall: 0.4365 - precision: 0.7051 - auc: 0.7694 - val_loss: 0.5582 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.8936 - val_recall: 0.5606 - val_precision: 0.7255 - val_auc: 0.7652\n",
            "Epoch 187/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5048 - accuracy: 0.7882 - sensitivity_at_specificity: 0.9159 - specificity_at_sensitivity: 0.9116 - recall: 0.7103 - precision: 0.7170 - auc: 0.8272\n",
            "Epoch 187: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5129 - accuracy: 0.7781 - sensitivity_at_specificity: 0.8833 - specificity_at_sensitivity: 0.9000 - recall: 0.6833 - precision: 0.7130 - auc: 0.8139 - val_loss: 0.5193 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.8594 - val_specificity_at_sensitivity: 0.9167 - val_recall: 0.5469 - val_precision: 0.8140 - val_auc: 0.8135\n",
            "Epoch 188/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5335 - accuracy: 0.7257 - sensitivity_at_specificity: 0.9256 - specificity_at_sensitivity: 0.8743 - recall: 0.5289 - precision: 0.7442 - auc: 0.8049\n",
            "Epoch 188: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5227 - accuracy: 0.7375 - sensitivity_at_specificity: 0.9398 - specificity_at_sensitivity: 0.8930 - recall: 0.5489 - precision: 0.7526 - auc: 0.8135 - val_loss: 0.5611 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.8621 - val_specificity_at_sensitivity: 0.8529 - val_recall: 0.7414 - val_precision: 0.5972 - val_auc: 0.7808\n",
            "Epoch 189/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4898 - accuracy: 0.7500 - sensitivity_at_specificity: 0.9300 - specificity_at_sensitivity: 0.8830 - recall: 0.6300 - precision: 0.6429 - auc: 0.8258\n",
            "Epoch 189: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5053 - accuracy: 0.7406 - sensitivity_at_specificity: 0.9211 - specificity_at_sensitivity: 0.8835 - recall: 0.5877 - precision: 0.6505 - auc: 0.8118 - val_loss: 0.5784 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.9103 - val_specificity_at_sensitivity: 0.9390 - val_recall: 0.5385 - val_precision: 0.8400 - val_auc: 0.8195\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4852 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9189 - specificity_at_sensitivity: 0.8852 - recall: 0.5676 - precision: 0.6848 - auc: 0.8259\n",
            "Epoch 190: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4852 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9189 - specificity_at_sensitivity: 0.8852 - recall: 0.5676 - precision: 0.6848 - auc: 0.8259 - val_loss: 0.6472 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.6933 - val_specificity_at_sensitivity: 0.8000 - val_recall: 0.5067 - val_precision: 0.6786 - val_auc: 0.7158\n",
            "Epoch 191/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5173 - accuracy: 0.7535 - sensitivity_at_specificity: 0.8878 - specificity_at_sensitivity: 0.8684 - recall: 0.6224 - precision: 0.6421 - auc: 0.7968\n",
            "Epoch 191: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5193 - accuracy: 0.7469 - sensitivity_at_specificity: 0.8981 - specificity_at_sensitivity: 0.8632 - recall: 0.6111 - precision: 0.6286 - auc: 0.7919 - val_loss: 0.6102 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.8472 - val_specificity_at_sensitivity: 0.9091 - val_recall: 0.4861 - val_precision: 0.8140 - val_auc: 0.7777\n",
            "Epoch 192/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4979 - accuracy: 0.7847 - sensitivity_at_specificity: 0.8909 - specificity_at_sensitivity: 0.9382 - recall: 0.5636 - precision: 0.8158 - auc: 0.8302\n",
            "Epoch 192: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4893 - accuracy: 0.7906 - sensitivity_at_specificity: 0.8783 - specificity_at_sensitivity: 0.9317 - recall: 0.5739 - precision: 0.7857 - auc: 0.8272 - val_loss: 0.5976 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8400 - val_specificity_at_sensitivity: 0.8471 - val_recall: 0.6667 - val_precision: 0.6849 - val_auc: 0.7543\n",
            "Epoch 193/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5201 - accuracy: 0.7500 - sensitivity_at_specificity: 0.9130 - specificity_at_sensitivity: 0.8728 - recall: 0.6261 - precision: 0.7129 - auc: 0.8102\n",
            "Epoch 193: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5119 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9055 - specificity_at_sensitivity: 0.8756 - recall: 0.6457 - precision: 0.7257 - auc: 0.8179 - val_loss: 0.5908 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.8148 - val_specificity_at_sensitivity: 0.8481 - val_recall: 0.6790 - val_precision: 0.7051 - val_auc: 0.7648\n",
            "Epoch 194/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5605 - accuracy: 0.7049 - sensitivity_at_specificity: 0.8641 - specificity_at_sensitivity: 0.8108 - recall: 0.4951 - precision: 0.6071 - auc: 0.7537\n",
            "Epoch 194: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5734 - accuracy: 0.6938 - sensitivity_at_specificity: 0.8621 - specificity_at_sensitivity: 0.8137 - recall: 0.4655 - precision: 0.6000 - auc: 0.7430 - val_loss: 0.6156 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.7887 - val_specificity_at_sensitivity: 0.8652 - val_recall: 0.4930 - val_precision: 0.7955 - val_auc: 0.7413\n",
            "Epoch 195/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5268 - accuracy: 0.7465 - sensitivity_at_specificity: 0.9027 - specificity_at_sensitivity: 0.8800 - recall: 0.6637 - precision: 0.6818 - auc: 0.8073\n",
            "Epoch 195: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5294 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9008 - specificity_at_sensitivity: 0.8744 - recall: 0.6364 - precision: 0.6754 - auc: 0.8023 - val_loss: 0.5562 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.8723 - val_recall: 0.5758 - val_precision: 0.6667 - val_auc: 0.7725\n",
            "Epoch 196/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5230 - accuracy: 0.7465 - sensitivity_at_specificity: 0.9211 - specificity_at_sensitivity: 0.8851 - recall: 0.5614 - precision: 0.7356 - auc: 0.8078\n",
            "Epoch 196: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5230 - accuracy: 0.7437 - sensitivity_at_specificity: 0.9120 - specificity_at_sensitivity: 0.8769 - recall: 0.5600 - precision: 0.7216 - auc: 0.8048 - val_loss: 0.5383 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8710 - val_specificity_at_sensitivity: 0.8878 - val_recall: 0.5161 - val_precision: 0.7273 - val_auc: 0.7932\n",
            "Epoch 197/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5424 - accuracy: 0.7326 - sensitivity_at_specificity: 0.8942 - specificity_at_sensitivity: 0.8424 - recall: 0.4808 - precision: 0.6849 - auc: 0.7750\n",
            "Epoch 197: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5348 - accuracy: 0.7344 - sensitivity_at_specificity: 0.8898 - specificity_at_sensitivity: 0.8762 - recall: 0.4915 - precision: 0.6988 - auc: 0.7862 - val_loss: 0.5009 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9130 - val_specificity_at_sensitivity: 0.9341 - val_recall: 0.5797 - val_precision: 0.8000 - val_auc: 0.8390\n",
            "Epoch 198/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5140 - accuracy: 0.7674 - sensitivity_at_specificity: 0.8846 - specificity_at_sensitivity: 0.8804 - recall: 0.6154 - precision: 0.7033 - auc: 0.8088\n",
            "Epoch 198: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5098 - accuracy: 0.7625 - sensitivity_at_specificity: 0.8772 - specificity_at_sensitivity: 0.8738 - recall: 0.5965 - precision: 0.6939 - auc: 0.8076 - val_loss: 0.5619 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8636 - val_specificity_at_sensitivity: 0.8830 - val_recall: 0.5606 - val_precision: 0.7400 - val_auc: 0.7834\n",
            "Epoch 199/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5218 - accuracy: 0.7465 - sensitivity_at_specificity: 0.9029 - specificity_at_sensitivity: 0.8703 - recall: 0.5437 - precision: 0.6829 - auc: 0.7912\n",
            "Epoch 199: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5198 - accuracy: 0.7469 - sensitivity_at_specificity: 0.8966 - specificity_at_sensitivity: 0.8971 - recall: 0.5603 - precision: 0.6842 - auc: 0.7960 - val_loss: 0.6075 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8481 - val_specificity_at_sensitivity: 0.8889 - val_recall: 0.5949 - val_precision: 0.7581 - val_auc: 0.7570\n",
            "Epoch 200/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5169 - accuracy: 0.7396 - sensitivity_at_specificity: 0.8991 - specificity_at_sensitivity: 0.8771 - recall: 0.5229 - precision: 0.7125 - auc: 0.8020\n",
            "Epoch 200: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5159 - accuracy: 0.7437 - sensitivity_at_specificity: 0.9091 - specificity_at_sensitivity: 0.8794 - recall: 0.5289 - precision: 0.7191 - auc: 0.8037 - val_loss: 0.5720 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.8219 - val_specificity_at_sensitivity: 0.9310 - val_recall: 0.6438 - val_precision: 0.7581 - val_auc: 0.7709\n",
            "Epoch 201/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5181 - accuracy: 0.7222 - sensitivity_at_specificity: 0.9596 - specificity_at_sensitivity: 0.8201 - recall: 0.5859 - precision: 0.5979 - auc: 0.7985\n",
            "Epoch 201: val_accuracy improved from 0.78750 to 0.79375, saving model to ECG_Model_Lead_1.h5\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5192 - accuracy: 0.7250 - sensitivity_at_specificity: 0.9369 - specificity_at_sensitivity: 0.8373 - recall: 0.5946 - precision: 0.6055 - auc: 0.7962 - val_loss: 0.4653 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 0.9589 - val_specificity_at_sensitivity: 0.9425 - val_recall: 0.6438 - val_precision: 0.8704 - val_auc: 0.8760\n",
            "Epoch 202/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5230 - accuracy: 0.7951 - sensitivity_at_specificity: 0.8021 - specificity_at_sensitivity: 0.9323 - recall: 0.5208 - precision: 0.7937 - auc: 0.7690\n",
            "Epoch 202: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5242 - accuracy: 0.7844 - sensitivity_at_specificity: 0.8131 - specificity_at_sensitivity: 0.9108 - recall: 0.4953 - precision: 0.7794 - auc: 0.7701 - val_loss: 0.6027 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.7969 - val_specificity_at_sensitivity: 0.8125 - val_recall: 0.4375 - val_precision: 0.6667 - val_auc: 0.7290\n",
            "Epoch 203/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5040 - accuracy: 0.7535 - sensitivity_at_specificity: 0.8660 - specificity_at_sensitivity: 0.8796 - recall: 0.5670 - precision: 0.6548 - auc: 0.8005\n",
            "Epoch 203: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5068 - accuracy: 0.7563 - sensitivity_at_specificity: 0.8739 - specificity_at_sensitivity: 0.8804 - recall: 0.5586 - precision: 0.6813 - auc: 0.8031 - val_loss: 0.5695 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8525 - val_specificity_at_sensitivity: 0.9091 - val_recall: 0.3770 - val_precision: 0.7419 - val_auc: 0.7801\n",
            "Epoch 204/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5292 - accuracy: 0.7257 - sensitivity_at_specificity: 0.9196 - specificity_at_sensitivity: 0.8636 - recall: 0.5179 - precision: 0.6988 - auc: 0.8015\n",
            "Epoch 204: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5281 - accuracy: 0.7281 - sensitivity_at_specificity: 0.9262 - specificity_at_sensitivity: 0.8535 - recall: 0.5410 - precision: 0.6804 - auc: 0.7969 - val_loss: 0.5727 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.7879 - val_specificity_at_sensitivity: 0.8723 - val_recall: 0.6364 - val_precision: 0.6562 - val_auc: 0.7567\n",
            "Epoch 205/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4942 - accuracy: 0.7604 - sensitivity_at_specificity: 0.9200 - specificity_at_sensitivity: 0.9096 - recall: 0.5300 - precision: 0.7067 - auc: 0.8151\n",
            "Epoch 205: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4941 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9130 - specificity_at_sensitivity: 0.9122 - recall: 0.5478 - precision: 0.7241 - auc: 0.8203 - val_loss: 0.5705 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.8406 - val_specificity_at_sensitivity: 0.8901 - val_recall: 0.4783 - val_precision: 0.7857 - val_auc: 0.7907\n",
            "Epoch 206/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5245 - accuracy: 0.7431 - sensitivity_at_specificity: 0.8983 - specificity_at_sensitivity: 0.8882 - recall: 0.6186 - precision: 0.7157 - auc: 0.8051\n",
            "Epoch 206: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5412 - accuracy: 0.7281 - sensitivity_at_specificity: 0.8692 - specificity_at_sensitivity: 0.8632 - recall: 0.6231 - precision: 0.6807 - auc: 0.7880 - val_loss: 0.5350 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8438 - val_specificity_at_sensitivity: 0.8854 - val_recall: 0.7031 - val_precision: 0.6250 - val_auc: 0.7977\n",
            "Epoch 207/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5109 - accuracy: 0.7708 - sensitivity_at_specificity: 0.8837 - specificity_at_sensitivity: 0.8663 - recall: 0.5930 - precision: 0.6220 - auc: 0.7851\n",
            "Epoch 207: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.5345 - accuracy: 0.7469 - sensitivity_at_specificity: 0.8627 - specificity_at_sensitivity: 0.8486 - recall: 0.5294 - precision: 0.6207 - auc: 0.7621 - val_loss: 0.6371 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.9067 - val_specificity_at_sensitivity: 0.9412 - val_recall: 0.3067 - val_precision: 0.8846 - val_auc: 0.8304\n",
            "Epoch 208/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5543 - accuracy: 0.7292 - sensitivity_at_specificity: 0.8288 - specificity_at_sensitivity: 0.8870 - recall: 0.4144 - precision: 0.7797 - auc: 0.7858\n",
            "Epoch 208: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5454 - accuracy: 0.7281 - sensitivity_at_specificity: 0.8607 - specificity_at_sensitivity: 0.8788 - recall: 0.4262 - precision: 0.7536 - auc: 0.7923 - val_loss: 0.5669 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.8169 - val_specificity_at_sensitivity: 0.9101 - val_recall: 0.6338 - val_precision: 0.6081 - val_auc: 0.7703\n",
            "Epoch 209/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5007 - accuracy: 0.7326 - sensitivity_at_specificity: 0.9368 - specificity_at_sensitivity: 0.8912 - recall: 0.6316 - precision: 0.5882 - auc: 0.8235\n",
            "Epoch 209: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5061 - accuracy: 0.7312 - sensitivity_at_specificity: 0.9286 - specificity_at_sensitivity: 0.8990 - recall: 0.6161 - precision: 0.6161 - auc: 0.8178 - val_loss: 0.5408 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9079 - val_specificity_at_sensitivity: 0.9286 - val_recall: 0.6184 - val_precision: 0.8545 - val_auc: 0.8240\n",
            "Epoch 210/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5401 - accuracy: 0.7222 - sensitivity_at_specificity: 0.8367 - specificity_at_sensitivity: 0.8579 - recall: 0.3776 - precision: 0.6607 - auc: 0.7644\n",
            "Epoch 210: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5281 - accuracy: 0.7312 - sensitivity_at_specificity: 0.8796 - specificity_at_sensitivity: 0.8679 - recall: 0.3889 - precision: 0.6774 - auc: 0.7795 - val_loss: 0.5647 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.8615 - val_specificity_at_sensitivity: 0.8421 - val_recall: 0.4308 - val_precision: 0.6667 - val_auc: 0.7747\n",
            "Epoch 211/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5515 - accuracy: 0.7049 - sensitivity_at_specificity: 0.8974 - specificity_at_sensitivity: 0.8421 - recall: 0.6410 - precision: 0.6356 - auc: 0.7825\n",
            "Epoch 211: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5502 - accuracy: 0.7031 - sensitivity_at_specificity: 0.8992 - specificity_at_sensitivity: 0.8482 - recall: 0.6357 - precision: 0.6308 - auc: 0.7819 - val_loss: 0.5459 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.8305 - val_specificity_at_sensitivity: 0.9109 - val_recall: 0.6949 - val_precision: 0.5694 - val_auc: 0.7927\n",
            "Epoch 212/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5302 - accuracy: 0.7361 - sensitivity_at_specificity: 0.8614 - specificity_at_sensitivity: 0.8984 - recall: 0.5743 - precision: 0.6374 - auc: 0.7834\n",
            "Epoch 212: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5336 - accuracy: 0.7375 - sensitivity_at_specificity: 0.8509 - specificity_at_sensitivity: 0.8932 - recall: 0.5526 - precision: 0.6562 - auc: 0.7812 - val_loss: 0.5460 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.8769 - val_specificity_at_sensitivity: 0.8737 - val_recall: 0.3538 - val_precision: 0.7667 - val_auc: 0.8111\n",
            "Epoch 213/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5063 - accuracy: 0.7465 - sensitivity_at_specificity: 0.9204 - specificity_at_sensitivity: 0.9086 - recall: 0.5133 - precision: 0.7632 - auc: 0.8353\n",
            "Epoch 213: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.4977 - accuracy: 0.7500 - sensitivity_at_specificity: 0.9256 - specificity_at_sensitivity: 0.8995 - recall: 0.5207 - precision: 0.7412 - auc: 0.8364 - val_loss: 0.6017 - val_accuracy: 0.6687 - val_sensitivity_at_specificity: 0.8378 - val_specificity_at_sensitivity: 0.8605 - val_recall: 0.6351 - val_precision: 0.6438 - val_auc: 0.7495\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4854 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9244 - specificity_at_sensitivity: 0.9552 - recall: 0.6975 - precision: 0.6803 - auc: 0.8395\n",
            "Epoch 214: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4854 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9244 - specificity_at_sensitivity: 0.9552 - recall: 0.6975 - precision: 0.6803 - auc: 0.8395 - val_loss: 0.5387 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.8235 - val_specificity_at_sensitivity: 0.9348 - val_recall: 0.6029 - val_precision: 0.7736 - val_auc: 0.8007\n",
            "Epoch 215/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5357 - accuracy: 0.7118 - sensitivity_at_specificity: 0.8796 - specificity_at_sensitivity: 0.8389 - recall: 0.4537 - precision: 0.6712 - auc: 0.7904\n",
            "Epoch 215: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5384 - accuracy: 0.7063 - sensitivity_at_specificity: 0.8833 - specificity_at_sensitivity: 0.8300 - recall: 0.4500 - precision: 0.6585 - auc: 0.7852 - val_loss: 0.5405 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.8571 - val_specificity_at_sensitivity: 0.8763 - val_recall: 0.6984 - val_precision: 0.6875 - val_auc: 0.7918\n",
            "Epoch 216/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4795 - accuracy: 0.7708 - sensitivity_at_specificity: 0.9167 - specificity_at_sensitivity: 0.9444 - recall: 0.7130 - precision: 0.6875 - auc: 0.8411\n",
            "Epoch 216: val_accuracy did not improve from 0.79375\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4797 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9174 - specificity_at_sensitivity: 0.9347 - recall: 0.7107 - precision: 0.6992 - auc: 0.8414 - val_loss: 0.5738 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8358 - val_specificity_at_sensitivity: 0.8495 - val_recall: 0.5522 - val_precision: 0.6981 - val_auc: 0.7526\n",
            "Epoch 217/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5230 - accuracy: 0.7500 - sensitivity_at_specificity: 0.8750 - specificity_at_sensitivity: 0.9130 - recall: 0.5288 - precision: 0.7051 - auc: 0.7975\n",
            "Epoch 217: val_accuracy improved from 0.79375 to 0.80000, saving model to ECG_Model_Lead_1.h5\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.5222 - accuracy: 0.7563 - sensitivity_at_specificity: 0.8655 - specificity_at_sensitivity: 0.9254 - recall: 0.5462 - precision: 0.7303 - auc: 0.8024 - val_loss: 0.5282 - val_accuracy: 0.8000 - val_sensitivity_at_specificity: 0.8594 - val_specificity_at_sensitivity: 0.9375 - val_recall: 0.6406 - val_precision: 0.8200 - val_auc: 0.8007\n",
            "Epoch 218/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5150 - accuracy: 0.7326 - sensitivity_at_specificity: 0.9333 - specificity_at_sensitivity: 0.8798 - recall: 0.5524 - precision: 0.6591 - auc: 0.8035\n",
            "Epoch 218: val_accuracy did not improve from 0.80000\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5039 - accuracy: 0.7437 - sensitivity_at_specificity: 0.9508 - specificity_at_sensitivity: 0.8939 - recall: 0.5902 - precision: 0.6923 - auc: 0.8200 - val_loss: 0.4588 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.9538 - val_specificity_at_sensitivity: 0.9053 - val_recall: 0.7385 - val_precision: 0.7164 - val_auc: 0.8685\n",
            "Epoch 219/500\n",
            " 6/10 [=================>............] - ETA: 0s - loss: 0.5368 - accuracy: 0.7240 - sensitivity_at_specificity: 0.8442 - specificity_at_sensitivity: 0.8609 - recall: 0.6623 - precision: 0.6538 - auc: 0.7946\n",
            "Epoch 219: val_accuracy did not improve from 0.80000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5392 - accuracy: 0.7312 - sensitivity_at_specificity: 0.8527 - specificity_at_sensitivity: 0.8586 - recall: 0.6434 - precision: 0.6748 - auc: 0.7921 - val_loss: 0.6123 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8375 - val_specificity_at_sensitivity: 0.8750 - val_recall: 0.5625 - val_precision: 0.7759 - val_auc: 0.7600\n",
            "Epoch 220/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5207 - accuracy: 0.7188 - sensitivity_at_specificity: 0.9029 - specificity_at_sensitivity: 0.8432 - recall: 0.4369 - precision: 0.6618 - auc: 0.7946\n",
            "Epoch 220: val_accuracy improved from 0.80000 to 0.80625, saving model to ECG_Model_Lead_1.h5\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5336 - accuracy: 0.7156 - sensitivity_at_specificity: 0.8850 - specificity_at_sensitivity: 0.8406 - recall: 0.4159 - precision: 0.6528 - auc: 0.7812 - val_loss: 0.4824 - val_accuracy: 0.8062 - val_sensitivity_at_specificity: 0.8421 - val_specificity_at_sensitivity: 0.9417 - val_recall: 0.6140 - val_precision: 0.7955 - val_auc: 0.8275\n",
            "Epoch 221/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5257 - accuracy: 0.7604 - sensitivity_at_specificity: 0.8598 - specificity_at_sensitivity: 0.9061 - recall: 0.6168 - precision: 0.7021 - auc: 0.7933\n",
            "Epoch 221: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5184 - accuracy: 0.7656 - sensitivity_at_specificity: 0.8678 - specificity_at_sensitivity: 0.9196 - recall: 0.6198 - precision: 0.7212 - auc: 0.8015 - val_loss: 0.5027 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9091 - val_specificity_at_sensitivity: 0.8857 - val_recall: 0.6545 - val_precision: 0.6667 - val_auc: 0.8115\n",
            "Epoch 222/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4818 - accuracy: 0.7847 - sensitivity_at_specificity: 0.8889 - specificity_at_sensitivity: 0.9556 - recall: 0.6019 - precision: 0.7738 - auc: 0.8370\n",
            "Epoch 222: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5043 - accuracy: 0.7750 - sensitivity_at_specificity: 0.8678 - specificity_at_sensitivity: 0.9397 - recall: 0.5785 - precision: 0.7692 - auc: 0.8184 - val_loss: 0.5755 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8529 - val_specificity_at_sensitivity: 0.8696 - val_recall: 0.4559 - val_precision: 0.7561 - val_auc: 0.7819\n",
            "Epoch 223/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4647 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9341 - specificity_at_sensitivity: 0.9086 - recall: 0.5604 - precision: 0.6711 - auc: 0.8317\n",
            "Epoch 223: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4581 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9412 - specificity_at_sensitivity: 0.9220 - recall: 0.5784 - precision: 0.6860 - auc: 0.8405 - val_loss: 0.5456 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9062 - val_specificity_at_sensitivity: 0.8542 - val_recall: 0.5469 - val_precision: 0.7143 - val_auc: 0.7926\n",
            "Epoch 224/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4501 - accuracy: 0.7674 - sensitivity_at_specificity: 0.9697 - specificity_at_sensitivity: 0.9048 - recall: 0.5455 - precision: 0.7105 - auc: 0.8625\n",
            "Epoch 224: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4608 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9633 - specificity_at_sensitivity: 0.8815 - recall: 0.5229 - precision: 0.6951 - auc: 0.8495 - val_loss: 0.5699 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.7797 - val_specificity_at_sensitivity: 0.8812 - val_recall: 0.5085 - val_precision: 0.6977 - val_auc: 0.7584\n",
            "Epoch 225/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5762 - accuracy: 0.6979 - sensitivity_at_specificity: 0.8148 - specificity_at_sensitivity: 0.8111 - recall: 0.5093 - precision: 0.6180 - auc: 0.7424\n",
            "Epoch 225: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5695 - accuracy: 0.7063 - sensitivity_at_specificity: 0.8264 - specificity_at_sensitivity: 0.8141 - recall: 0.5289 - precision: 0.6337 - auc: 0.7524 - val_loss: 0.5973 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8209 - val_specificity_at_sensitivity: 0.8495 - val_recall: 0.5075 - val_precision: 0.6939 - val_auc: 0.7521\n",
            "Epoch 226/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4822 - accuracy: 0.7604 - sensitivity_at_specificity: 0.9208 - specificity_at_sensitivity: 0.8930 - recall: 0.5743 - precision: 0.6905 - auc: 0.8296\n",
            "Epoch 226: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5032 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9153 - specificity_at_sensitivity: 0.8812 - recall: 0.5593 - precision: 0.6947 - auc: 0.8167 - val_loss: 0.5963 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.8028 - val_specificity_at_sensitivity: 0.8090 - val_recall: 0.5070 - val_precision: 0.6792 - val_auc: 0.7519\n",
            "Epoch 227/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4632 - accuracy: 0.7882 - sensitivity_at_specificity: 0.9300 - specificity_at_sensitivity: 0.9309 - recall: 0.6600 - precision: 0.7097 - auc: 0.8527\n",
            "Epoch 227: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4676 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9558 - specificity_at_sensitivity: 0.9372 - recall: 0.6372 - precision: 0.7200 - auc: 0.8496 - val_loss: 0.4719 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 0.9014 - val_specificity_at_sensitivity: 0.9213 - val_recall: 0.7183 - val_precision: 0.7969 - val_auc: 0.8622\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4899 - accuracy: 0.7563 - sensitivity_at_specificity: 0.8980 - specificity_at_sensitivity: 0.8739 - recall: 0.5000 - precision: 0.6282 - auc: 0.8025\n",
            "Epoch 228: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4899 - accuracy: 0.7563 - sensitivity_at_specificity: 0.8980 - specificity_at_sensitivity: 0.8739 - recall: 0.5000 - precision: 0.6282 - auc: 0.8025 - val_loss: 0.5767 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.8036 - val_specificity_at_sensitivity: 0.8269 - val_recall: 0.4107 - val_precision: 0.7419 - val_auc: 0.7417\n",
            "Epoch 229/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4931 - accuracy: 0.7465 - sensitivity_at_specificity: 0.9082 - specificity_at_sensitivity: 0.8789 - recall: 0.4694 - precision: 0.6866 - auc: 0.8156\n",
            "Epoch 229: val_accuracy improved from 0.80625 to 0.81250, saving model to ECG_Model_Lead_1.h5\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.4950 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9167 - specificity_at_sensitivity: 0.8726 - recall: 0.5000 - precision: 0.6667 - auc: 0.8092 - val_loss: 0.4657 - val_accuracy: 0.8125 - val_sensitivity_at_specificity: 0.9600 - val_specificity_at_sensitivity: 0.9294 - val_recall: 0.7200 - val_precision: 0.8571 - val_auc: 0.8755\n",
            "Epoch 230/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4967 - accuracy: 0.7778 - sensitivity_at_specificity: 0.9189 - specificity_at_sensitivity: 0.9266 - recall: 0.6036 - precision: 0.7701 - auc: 0.8297\n",
            "Epoch 230: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5024 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9180 - specificity_at_sensitivity: 0.9091 - recall: 0.6148 - precision: 0.7426 - auc: 0.8215 - val_loss: 0.5329 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.8961 - val_specificity_at_sensitivity: 0.9277 - val_recall: 0.6883 - val_precision: 0.7162 - val_auc: 0.8083\n",
            "Epoch 231/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5300 - accuracy: 0.7535 - sensitivity_at_specificity: 0.8879 - specificity_at_sensitivity: 0.8895 - recall: 0.7241 - precision: 0.6829 - auc: 0.8074\n",
            "Epoch 231: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5304 - accuracy: 0.7500 - sensitivity_at_specificity: 0.8760 - specificity_at_sensitivity: 0.8848 - recall: 0.6899 - precision: 0.6899 - auc: 0.8047 - val_loss: 0.6231 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.7714 - val_specificity_at_sensitivity: 0.8111 - val_recall: 0.5143 - val_precision: 0.6667 - val_auc: 0.7264\n",
            "Epoch 232/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5338 - accuracy: 0.7326 - sensitivity_at_specificity: 0.8661 - specificity_at_sensitivity: 0.8864 - recall: 0.5089 - precision: 0.7215 - auc: 0.7978\n",
            "Epoch 232: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5332 - accuracy: 0.7344 - sensitivity_at_specificity: 0.8702 - specificity_at_sensitivity: 0.8783 - recall: 0.5420 - precision: 0.7396 - auc: 0.8058 - val_loss: 0.5645 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.8933 - val_specificity_at_sensitivity: 0.8588 - val_recall: 0.6667 - val_precision: 0.6667 - val_auc: 0.7809\n",
            "Epoch 233/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5217 - accuracy: 0.7604 - sensitivity_at_specificity: 0.8909 - specificity_at_sensitivity: 0.9157 - recall: 0.7182 - precision: 0.6752 - auc: 0.8121\n",
            "Epoch 233: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5053 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9060 - specificity_at_sensitivity: 0.9212 - recall: 0.7179 - precision: 0.6774 - auc: 0.8225 - val_loss: 0.5395 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8846 - val_specificity_at_sensitivity: 0.8056 - val_recall: 0.5000 - val_precision: 0.5417 - val_auc: 0.7645\n",
            "Epoch 234/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5140 - accuracy: 0.7465 - sensitivity_at_specificity: 0.9057 - specificity_at_sensitivity: 0.8956 - recall: 0.4717 - precision: 0.7463 - auc: 0.8133\n",
            "Epoch 234: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5042 - accuracy: 0.7500 - sensitivity_at_specificity: 0.9043 - specificity_at_sensitivity: 0.8927 - recall: 0.4696 - precision: 0.7397 - auc: 0.8173 - val_loss: 0.5522 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.9028 - val_specificity_at_sensitivity: 0.8864 - val_recall: 0.5417 - val_precision: 0.7647 - val_auc: 0.8023\n",
            "Epoch 235/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5237 - accuracy: 0.7396 - sensitivity_at_specificity: 0.9009 - specificity_at_sensitivity: 0.8418 - recall: 0.6126 - precision: 0.6800 - auc: 0.8044\n",
            "Epoch 235: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5338 - accuracy: 0.7375 - sensitivity_at_specificity: 0.8770 - specificity_at_sensitivity: 0.8485 - recall: 0.5984 - precision: 0.6759 - auc: 0.7945 - val_loss: 0.5199 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9265 - val_specificity_at_sensitivity: 0.9022 - val_recall: 0.6765 - val_precision: 0.6970 - val_auc: 0.8145\n",
            "Epoch 236/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5205 - accuracy: 0.7361 - sensitivity_at_specificity: 0.9333 - specificity_at_sensitivity: 0.8988 - recall: 0.6583 - precision: 0.6930 - auc: 0.8090\n",
            "Epoch 236: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5149 - accuracy: 0.7375 - sensitivity_at_specificity: 0.9394 - specificity_at_sensitivity: 0.8989 - recall: 0.6439 - precision: 0.6967 - auc: 0.8130 - val_loss: 0.5121 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9189 - val_specificity_at_sensitivity: 0.9186 - val_recall: 0.6486 - val_precision: 0.7869 - val_auc: 0.8360\n",
            "Epoch 237/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5332 - accuracy: 0.7292 - sensitivity_at_specificity: 0.8713 - specificity_at_sensitivity: 0.8503 - recall: 0.4752 - precision: 0.6575 - auc: 0.7734\n",
            "Epoch 237: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5297 - accuracy: 0.7375 - sensitivity_at_specificity: 0.8739 - specificity_at_sensitivity: 0.8517 - recall: 0.4865 - precision: 0.6667 - auc: 0.7763 - val_loss: 0.5513 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8955 - val_specificity_at_sensitivity: 0.8602 - val_recall: 0.5522 - val_precision: 0.6981 - val_auc: 0.7875\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4630 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9145 - specificity_at_sensitivity: 0.9310 - recall: 0.6752 - precision: 0.7182 - auc: 0.8614\n",
            "Epoch 238: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4630 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9145 - specificity_at_sensitivity: 0.9310 - recall: 0.6752 - precision: 0.7182 - auc: 0.8614 - val_loss: 0.5298 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9079 - val_specificity_at_sensitivity: 0.9167 - val_recall: 0.6184 - val_precision: 0.7833 - val_auc: 0.8225\n",
            "Epoch 239/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4847 - accuracy: 0.7674 - sensitivity_at_specificity: 0.9541 - specificity_at_sensitivity: 0.8883 - recall: 0.5872 - precision: 0.7442 - auc: 0.8393\n",
            "Epoch 239: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4765 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9587 - specificity_at_sensitivity: 0.8995 - recall: 0.6116 - precision: 0.7475 - auc: 0.8450 - val_loss: 0.5927 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.9167 - val_specificity_at_sensitivity: 0.8409 - val_recall: 0.5972 - val_precision: 0.7288 - val_auc: 0.7625\n",
            "Epoch 240/500\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5275 - accuracy: 0.7383 - sensitivity_at_specificity: 0.8571 - specificity_at_sensitivity: 0.8909 - recall: 0.5604 - precision: 0.6538 - auc: 0.7828\n",
            "Epoch 240: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5312 - accuracy: 0.7344 - sensitivity_at_specificity: 0.8509 - specificity_at_sensitivity: 0.8932 - recall: 0.5351 - precision: 0.6559 - auc: 0.7784 - val_loss: 0.5375 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.8919 - val_specificity_at_sensitivity: 0.9419 - val_recall: 0.5541 - val_precision: 0.8367 - val_auc: 0.8244\n",
            "Epoch 241/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4854 - accuracy: 0.7882 - sensitivity_at_specificity: 0.8817 - specificity_at_sensitivity: 0.8974 - recall: 0.5591 - precision: 0.7222 - auc: 0.8127\n",
            "Epoch 241: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4785 - accuracy: 0.7906 - sensitivity_at_specificity: 0.8889 - specificity_at_sensitivity: 0.9151 - recall: 0.5648 - precision: 0.7531 - auc: 0.8265 - val_loss: 0.4947 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.8772 - val_specificity_at_sensitivity: 0.8932 - val_recall: 0.5965 - val_precision: 0.6939 - val_auc: 0.8148\n",
            "Epoch 242/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5124 - accuracy: 0.7535 - sensitivity_at_specificity: 0.9159 - specificity_at_sensitivity: 0.8840 - recall: 0.6075 - precision: 0.6915 - auc: 0.8079\n",
            "Epoch 242: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5154 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9250 - specificity_at_sensitivity: 0.8750 - recall: 0.6000 - precision: 0.6857 - auc: 0.8067 - val_loss: 0.5233 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.8769 - val_specificity_at_sensitivity: 0.9053 - val_recall: 0.7538 - val_precision: 0.7101 - val_auc: 0.8165\n",
            "Epoch 243/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5027 - accuracy: 0.7569 - sensitivity_at_specificity: 0.9316 - specificity_at_sensitivity: 0.9006 - recall: 0.6923 - precision: 0.7043 - auc: 0.8321\n",
            "Epoch 243: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5042 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9231 - specificity_at_sensitivity: 0.9000 - recall: 0.6923 - precision: 0.7087 - auc: 0.8296 - val_loss: 0.5749 - val_accuracy: 0.6625 - val_sensitivity_at_specificity: 0.9028 - val_specificity_at_sensitivity: 0.7955 - val_recall: 0.4861 - val_precision: 0.6731 - val_auc: 0.7685\n",
            "Epoch 244/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5649 - accuracy: 0.7014 - sensitivity_at_specificity: 0.8559 - specificity_at_sensitivity: 0.8529 - recall: 0.4407 - precision: 0.7222 - auc: 0.7833\n",
            "Epoch 244: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5666 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8485 - specificity_at_sensitivity: 0.8617 - recall: 0.4545 - precision: 0.7143 - auc: 0.7793 - val_loss: 0.5593 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8955 - val_specificity_at_sensitivity: 0.8602 - val_recall: 0.8060 - val_precision: 0.6136 - val_auc: 0.7877\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4591 - accuracy: 0.8094 - sensitivity_at_specificity: 0.9328 - specificity_at_sensitivity: 0.9652 - recall: 0.8739 - precision: 0.6933 - auc: 0.8859\n",
            "Epoch 245: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4591 - accuracy: 0.8094 - sensitivity_at_specificity: 0.9328 - specificity_at_sensitivity: 0.9652 - recall: 0.8739 - precision: 0.6933 - auc: 0.8859 - val_loss: 0.5272 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9649 - val_specificity_at_sensitivity: 0.8932 - val_recall: 0.5088 - val_precision: 0.7250 - val_auc: 0.7999\n",
            "Epoch 246/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5193 - accuracy: 0.7292 - sensitivity_at_specificity: 0.8679 - specificity_at_sensitivity: 0.8901 - recall: 0.3868 - precision: 0.7593 - auc: 0.8143\n",
            "Epoch 246: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5303 - accuracy: 0.7219 - sensitivity_at_specificity: 0.8595 - specificity_at_sensitivity: 0.8894 - recall: 0.3884 - precision: 0.7581 - auc: 0.8078 - val_loss: 0.5078 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9016 - val_specificity_at_sensitivity: 0.9192 - val_recall: 0.6721 - val_precision: 0.7069 - val_auc: 0.8253\n",
            "Epoch 247/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5445 - accuracy: 0.7361 - sensitivity_at_specificity: 0.8584 - specificity_at_sensitivity: 0.8971 - recall: 0.6372 - precision: 0.6729 - auc: 0.7854\n",
            "Epoch 247: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5450 - accuracy: 0.7437 - sensitivity_at_specificity: 0.8651 - specificity_at_sensitivity: 0.9021 - recall: 0.6508 - precision: 0.6833 - auc: 0.7863 - val_loss: 0.5471 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.8696 - val_specificity_at_sensitivity: 0.9011 - val_recall: 0.7101 - val_precision: 0.6712 - val_auc: 0.7946\n",
            "Epoch 248/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5330 - accuracy: 0.7326 - sensitivity_at_specificity: 0.8113 - specificity_at_sensitivity: 0.8791 - recall: 0.5472 - precision: 0.6667 - auc: 0.7849\n",
            "Epoch 248: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5337 - accuracy: 0.7281 - sensitivity_at_specificity: 0.8547 - specificity_at_sensitivity: 0.8571 - recall: 0.5299 - precision: 0.6596 - auc: 0.7832 - val_loss: 0.5342 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.9559 - val_specificity_at_sensitivity: 0.8370 - val_recall: 0.6324 - val_precision: 0.6825 - val_auc: 0.7991\n",
            "Epoch 249/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5448 - accuracy: 0.7153 - sensitivity_at_specificity: 0.8519 - specificity_at_sensitivity: 0.8667 - recall: 0.5463 - precision: 0.6413 - auc: 0.7738\n",
            "Epoch 249: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5503 - accuracy: 0.7031 - sensitivity_at_specificity: 0.8537 - specificity_at_sensitivity: 0.8579 - recall: 0.5285 - precision: 0.6373 - auc: 0.7676 - val_loss: 0.5360 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.8939 - val_specificity_at_sensitivity: 0.9255 - val_recall: 0.5455 - val_precision: 0.7200 - val_auc: 0.7917\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5798 - accuracy: 0.6938 - sensitivity_at_specificity: 0.8080 - specificity_at_sensitivity: 0.8205 - recall: 0.4240 - precision: 0.6709 - auc: 0.7490\n",
            "Epoch 250: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5798 - accuracy: 0.6938 - sensitivity_at_specificity: 0.8080 - specificity_at_sensitivity: 0.8205 - recall: 0.4240 - precision: 0.6709 - auc: 0.7490 - val_loss: 0.5365 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8871 - val_specificity_at_sensitivity: 0.8878 - val_recall: 0.5806 - val_precision: 0.6923 - val_auc: 0.7817\n",
            "Epoch 251/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4988 - accuracy: 0.7674 - sensitivity_at_specificity: 0.8900 - specificity_at_sensitivity: 0.8989 - recall: 0.6900 - precision: 0.6571 - auc: 0.8230\n",
            "Epoch 251: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5071 - accuracy: 0.7594 - sensitivity_at_specificity: 0.8919 - specificity_at_sensitivity: 0.8756 - recall: 0.6667 - precision: 0.6491 - auc: 0.8132 - val_loss: 0.5178 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.9242 - val_specificity_at_sensitivity: 0.9149 - val_recall: 0.5758 - val_precision: 0.7600 - val_auc: 0.8253\n",
            "Epoch 252/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5074 - accuracy: 0.7357 - sensitivity_at_specificity: 0.9417 - specificity_at_sensitivity: 0.8814 - recall: 0.4466 - precision: 0.7302 - auc: 0.8224\n",
            "Epoch 252: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5130 - accuracy: 0.7276 - sensitivity_at_specificity: 0.9483 - specificity_at_sensitivity: 0.8724 - recall: 0.4483 - precision: 0.7123 - auc: 0.8171 - val_loss: 0.5350 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.8548 - val_specificity_at_sensitivity: 0.9184 - val_recall: 0.5484 - val_precision: 0.7556 - val_auc: 0.7963\n",
            "Epoch 253/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5118 - accuracy: 0.7465 - sensitivity_at_specificity: 0.9048 - specificity_at_sensitivity: 0.8798 - recall: 0.6000 - precision: 0.6702 - auc: 0.8113\n",
            "Epoch 253: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5083 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9174 - specificity_at_sensitivity: 0.8744 - recall: 0.6281 - precision: 0.6786 - auc: 0.8186 - val_loss: 0.5488 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.8714 - val_specificity_at_sensitivity: 0.8889 - val_recall: 0.6000 - val_precision: 0.7119 - val_auc: 0.7844\n",
            "Epoch 254/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5432 - accuracy: 0.7812 - sensitivity_at_specificity: 0.8365 - specificity_at_sensitivity: 0.8967 - recall: 0.5962 - precision: 0.7470 - auc: 0.7718\n",
            "Epoch 254: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5206 - accuracy: 0.7937 - sensitivity_at_specificity: 0.8393 - specificity_at_sensitivity: 0.9087 - recall: 0.5982 - precision: 0.7614 - auc: 0.7903 - val_loss: 0.5041 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8939 - val_specificity_at_sensitivity: 0.8936 - val_recall: 0.5303 - val_precision: 0.7609 - val_auc: 0.8269\n",
            "Epoch 255/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4597 - accuracy: 0.7951 - sensitivity_at_specificity: 0.9429 - specificity_at_sensitivity: 0.9235 - recall: 0.6667 - precision: 0.7447 - auc: 0.8570\n",
            "Epoch 255: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4502 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9464 - specificity_at_sensitivity: 0.9327 - recall: 0.6786 - precision: 0.7308 - auc: 0.8634 - val_loss: 0.5241 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9342 - val_specificity_at_sensitivity: 0.8929 - val_recall: 0.6447 - val_precision: 0.8033 - val_auc: 0.8329\n",
            "Epoch 256/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5190 - accuracy: 0.7535 - sensitivity_at_specificity: 0.8614 - specificity_at_sensitivity: 0.9091 - recall: 0.4653 - precision: 0.7344 - auc: 0.8030\n",
            "Epoch 256: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5098 - accuracy: 0.7625 - sensitivity_at_specificity: 0.8649 - specificity_at_sensitivity: 0.9091 - recall: 0.4865 - precision: 0.7397 - auc: 0.8071 - val_loss: 0.5033 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9143 - val_specificity_at_sensitivity: 0.9556 - val_recall: 0.6429 - val_precision: 0.7627 - val_auc: 0.8301\n",
            "Epoch 257/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4560 - accuracy: 0.7882 - sensitivity_at_specificity: 0.9307 - specificity_at_sensitivity: 0.9305 - recall: 0.6337 - precision: 0.7273 - auc: 0.8554\n",
            "Epoch 257: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4518 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9375 - specificity_at_sensitivity: 0.9279 - recall: 0.6250 - precision: 0.7292 - auc: 0.8592 - val_loss: 0.5080 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.8889 - val_specificity_at_sensitivity: 0.8660 - val_recall: 0.6349 - val_precision: 0.7273 - val_auc: 0.8142\n",
            "Epoch 258/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4723 - accuracy: 0.7639 - sensitivity_at_specificity: 0.8941 - specificity_at_sensitivity: 0.8719 - recall: 0.5176 - precision: 0.6197 - auc: 0.8171\n",
            "Epoch 258: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4709 - accuracy: 0.7688 - sensitivity_at_specificity: 0.8969 - specificity_at_sensitivity: 0.8789 - recall: 0.5258 - precision: 0.6456 - auc: 0.8215 - val_loss: 0.5607 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8630 - val_specificity_at_sensitivity: 0.9310 - val_recall: 0.5068 - val_precision: 0.8605 - val_auc: 0.8074\n",
            "Epoch 259/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4959 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9074 - specificity_at_sensitivity: 0.9222 - recall: 0.6019 - precision: 0.7471 - auc: 0.8273\n",
            "Epoch 259: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4922 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9167 - specificity_at_sensitivity: 0.9150 - recall: 0.6000 - precision: 0.7423 - auc: 0.8310 - val_loss: 0.4735 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.9444 - val_specificity_at_sensitivity: 0.9205 - val_recall: 0.7361 - val_precision: 0.7794 - val_auc: 0.8517\n",
            "Epoch 260/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5155 - accuracy: 0.7465 - sensitivity_at_specificity: 0.9328 - specificity_at_sensitivity: 0.8817 - recall: 0.7143 - precision: 0.6855 - auc: 0.8191\n",
            "Epoch 260: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5140 - accuracy: 0.7406 - sensitivity_at_specificity: 0.9098 - specificity_at_sensitivity: 0.8824 - recall: 0.6917 - precision: 0.6866 - auc: 0.8201 - val_loss: 0.5068 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.8525 - val_specificity_at_sensitivity: 0.9091 - val_recall: 0.5246 - val_precision: 0.6957 - val_auc: 0.8044\n",
            "Epoch 261/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5308 - accuracy: 0.7292 - sensitivity_at_specificity: 0.9099 - specificity_at_sensitivity: 0.8531 - recall: 0.4775 - precision: 0.7260 - auc: 0.8029\n",
            "Epoch 261: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5207 - accuracy: 0.7344 - sensitivity_at_specificity: 0.9120 - specificity_at_sensitivity: 0.8821 - recall: 0.5040 - precision: 0.7326 - auc: 0.8129 - val_loss: 0.4361 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 0.9531 - val_specificity_at_sensitivity: 0.9479 - val_recall: 0.7188 - val_precision: 0.7541 - val_auc: 0.8835\n",
            "Epoch 262/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5446 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8879 - specificity_at_sensitivity: 0.8721 - recall: 0.6724 - precision: 0.6446 - auc: 0.7901\n",
            "Epoch 262: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5179 - accuracy: 0.7406 - sensitivity_at_specificity: 0.8960 - specificity_at_sensitivity: 0.8974 - recall: 0.6800 - precision: 0.6641 - auc: 0.8134 - val_loss: 0.4875 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9242 - val_specificity_at_sensitivity: 0.9362 - val_recall: 0.6061 - val_precision: 0.8163 - val_auc: 0.8482\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.7563 - sensitivity_at_specificity: 0.9123 - specificity_at_sensitivity: 0.8932 - recall: 0.5175 - precision: 0.7195 - auc: 0.8197\n",
            "Epoch 263: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4977 - accuracy: 0.7563 - sensitivity_at_specificity: 0.9123 - specificity_at_sensitivity: 0.8932 - recall: 0.5175 - precision: 0.7195 - auc: 0.8197 - val_loss: 0.5778 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.7500 - val_specificity_at_sensitivity: 0.9022 - val_recall: 0.5441 - val_precision: 0.7708 - val_auc: 0.7510\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.7437 - sensitivity_at_specificity: 0.8929 - specificity_at_sensitivity: 0.9279 - recall: 0.5625 - precision: 0.6562 - auc: 0.7977\n",
            "Epoch 264: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5126 - accuracy: 0.7437 - sensitivity_at_specificity: 0.8929 - specificity_at_sensitivity: 0.9279 - recall: 0.5625 - precision: 0.6562 - auc: 0.7977 - val_loss: 0.5092 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9545 - val_specificity_at_sensitivity: 0.9362 - val_recall: 0.5303 - val_precision: 0.8537 - val_auc: 0.8412\n",
            "Epoch 265/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5104 - accuracy: 0.7396 - sensitivity_at_specificity: 0.8713 - specificity_at_sensitivity: 0.8663 - recall: 0.4950 - precision: 0.6757 - auc: 0.7951\n",
            "Epoch 265: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5060 - accuracy: 0.7437 - sensitivity_at_specificity: 0.8818 - specificity_at_sensitivity: 0.8667 - recall: 0.5091 - precision: 0.6667 - auc: 0.7979 - val_loss: 0.4931 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9333 - val_specificity_at_sensitivity: 0.9059 - val_recall: 0.6800 - val_precision: 0.7727 - val_auc: 0.8447\n",
            "Epoch 266/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4868 - accuracy: 0.7674 - sensitivity_at_specificity: 0.9208 - specificity_at_sensitivity: 0.9091 - recall: 0.5149 - precision: 0.7429 - auc: 0.8225\n",
            "Epoch 266: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4867 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9130 - specificity_at_sensitivity: 0.9171 - recall: 0.5043 - precision: 0.7632 - auc: 0.8275 - val_loss: 0.6162 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.7917 - val_specificity_at_sensitivity: 0.9091 - val_recall: 0.6111 - val_precision: 0.6769 - val_auc: 0.7444\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5060 - accuracy: 0.7375 - sensitivity_at_specificity: 0.9348 - specificity_at_sensitivity: 0.9011 - recall: 0.7826 - precision: 0.6667 - auc: 0.8325\n",
            "Epoch 267: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5060 - accuracy: 0.7375 - sensitivity_at_specificity: 0.9348 - specificity_at_sensitivity: 0.9011 - recall: 0.7826 - precision: 0.6667 - auc: 0.8325 - val_loss: 0.5655 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.9036 - val_specificity_at_sensitivity: 0.8701 - val_recall: 0.7229 - val_precision: 0.7229 - val_auc: 0.7888\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5093 - accuracy: 0.7250 - sensitivity_at_specificity: 0.9444 - specificity_at_sensitivity: 0.8866 - recall: 0.4603 - precision: 0.7436 - auc: 0.8253\n",
            "Epoch 268: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5093 - accuracy: 0.7250 - sensitivity_at_specificity: 0.9444 - specificity_at_sensitivity: 0.8866 - recall: 0.4603 - precision: 0.7436 - auc: 0.8253 - val_loss: 0.4679 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.9571 - val_specificity_at_sensitivity: 0.9444 - val_recall: 0.6714 - val_precision: 0.8103 - val_auc: 0.8700\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5216 - accuracy: 0.7344 - sensitivity_at_specificity: 0.9138 - specificity_at_sensitivity: 0.8824 - recall: 0.6724 - precision: 0.6240 - auc: 0.8016\n",
            "Epoch 269: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5216 - accuracy: 0.7344 - sensitivity_at_specificity: 0.9138 - specificity_at_sensitivity: 0.8824 - recall: 0.6724 - precision: 0.6240 - auc: 0.8016 - val_loss: 0.5185 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8971 - val_specificity_at_sensitivity: 0.8696 - val_recall: 0.5588 - val_precision: 0.7037 - val_auc: 0.8131\n",
            "Epoch 270/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4890 - accuracy: 0.7569 - sensitivity_at_specificity: 0.9252 - specificity_at_sensitivity: 0.9006 - recall: 0.5327 - precision: 0.7403 - auc: 0.8339\n",
            "Epoch 270: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4940 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9160 - specificity_at_sensitivity: 0.9005 - recall: 0.5546 - precision: 0.7416 - auc: 0.8283 - val_loss: 0.5475 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8816 - val_specificity_at_sensitivity: 0.8690 - val_recall: 0.5395 - val_precision: 0.7736 - val_auc: 0.8003\n",
            "Epoch 271/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5337 - accuracy: 0.7465 - sensitivity_at_specificity: 0.8922 - specificity_at_sensitivity: 0.8817 - recall: 0.6078 - precision: 0.6526 - auc: 0.7820\n",
            "Epoch 271: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5323 - accuracy: 0.7469 - sensitivity_at_specificity: 0.8879 - specificity_at_sensitivity: 0.8824 - recall: 0.6034 - precision: 0.6667 - auc: 0.7856 - val_loss: 0.5263 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8507 - val_specificity_at_sensitivity: 0.9140 - val_recall: 0.5672 - val_precision: 0.7451 - val_auc: 0.8030\n",
            "Epoch 272/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4867 - accuracy: 0.7639 - sensitivity_at_specificity: 0.9052 - specificity_at_sensitivity: 0.9302 - recall: 0.5948 - precision: 0.7667 - auc: 0.8411\n",
            "Epoch 272: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4901 - accuracy: 0.7563 - sensitivity_at_specificity: 0.9070 - specificity_at_sensitivity: 0.9215 - recall: 0.5891 - precision: 0.7525 - auc: 0.8393 - val_loss: 0.5103 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9322 - val_specificity_at_sensitivity: 0.8812 - val_recall: 0.6610 - val_precision: 0.6393 - val_auc: 0.8152\n",
            "Epoch 273/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4671 - accuracy: 0.8021 - sensitivity_at_specificity: 0.9496 - specificity_at_sensitivity: 0.9290 - recall: 0.7731 - precision: 0.7541 - auc: 0.8627\n",
            "Epoch 273: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4807 - accuracy: 0.7969 - sensitivity_at_specificity: 0.9385 - specificity_at_sensitivity: 0.9211 - recall: 0.7692 - precision: 0.7407 - auc: 0.8485 - val_loss: 0.4779 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9481 - val_specificity_at_sensitivity: 0.9759 - val_recall: 0.5714 - val_precision: 0.8800 - val_auc: 0.8888\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5304 - accuracy: 0.7406 - sensitivity_at_specificity: 0.8739 - specificity_at_sensitivity: 0.8806 - recall: 0.5126 - precision: 0.7093 - auc: 0.8000\n",
            "Epoch 274: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5304 - accuracy: 0.7406 - sensitivity_at_specificity: 0.8739 - specificity_at_sensitivity: 0.8806 - recall: 0.5126 - precision: 0.7093 - auc: 0.8000 - val_loss: 0.5077 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9062 - val_specificity_at_sensitivity: 0.9375 - val_recall: 0.6250 - val_precision: 0.7843 - val_auc: 0.8254\n",
            "Epoch 275/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5281 - accuracy: 0.7500 - sensitivity_at_specificity: 0.8596 - specificity_at_sensitivity: 0.8908 - recall: 0.5789 - precision: 0.7333 - auc: 0.8007\n",
            "Epoch 275: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5302 - accuracy: 0.7500 - sensitivity_at_specificity: 0.8720 - specificity_at_sensitivity: 0.8718 - recall: 0.6000 - precision: 0.7143 - auc: 0.7978 - val_loss: 0.5032 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.8889 - val_specificity_at_sensitivity: 0.8977 - val_recall: 0.7361 - val_precision: 0.7465 - val_auc: 0.8301\n",
            "Epoch 276/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5019 - accuracy: 0.7535 - sensitivity_at_specificity: 0.9196 - specificity_at_sensitivity: 0.9034 - recall: 0.6786 - precision: 0.6847 - auc: 0.8297\n",
            "Epoch 276: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5023 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9200 - specificity_at_sensitivity: 0.9077 - recall: 0.6560 - precision: 0.6833 - auc: 0.8276 - val_loss: 0.5447 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.8933 - val_specificity_at_sensitivity: 0.8588 - val_recall: 0.6267 - val_precision: 0.7581 - val_auc: 0.8111\n",
            "Epoch 277/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4739 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9545 - specificity_at_sensitivity: 0.9551 - recall: 0.5455 - precision: 0.8000 - auc: 0.8570\n",
            "Epoch 277: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4725 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9500 - specificity_at_sensitivity: 0.9400 - recall: 0.5333 - precision: 0.8000 - auc: 0.8557 - val_loss: 0.4619 - val_accuracy: 0.8062 - val_sensitivity_at_specificity: 0.9559 - val_specificity_at_sensitivity: 0.8913 - val_recall: 0.7794 - val_precision: 0.7681 - val_auc: 0.8621\n",
            "Epoch 278/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4582 - accuracy: 0.8143 - sensitivity_at_specificity: 0.8830 - specificity_at_sensitivity: 0.9355 - recall: 0.7553 - precision: 0.7100 - auc: 0.8481\n",
            "Epoch 278: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4623 - accuracy: 0.8013 - sensitivity_at_specificity: 0.9143 - specificity_at_sensitivity: 0.9324 - recall: 0.7143 - precision: 0.7009 - auc: 0.8429 - val_loss: 0.5220 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9000 - val_specificity_at_sensitivity: 0.9222 - val_recall: 0.6143 - val_precision: 0.7963 - val_auc: 0.8315\n",
            "Epoch 279/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4535 - accuracy: 0.7778 - sensitivity_at_specificity: 0.9515 - specificity_at_sensitivity: 0.9297 - recall: 0.4854 - precision: 0.8197 - auc: 0.8692\n",
            "Epoch 279: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4576 - accuracy: 0.7781 - sensitivity_at_specificity: 0.9386 - specificity_at_sensitivity: 0.9369 - recall: 0.4825 - precision: 0.8209 - auc: 0.8629 - val_loss: 0.5337 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.8594 - val_specificity_at_sensitivity: 0.9062 - val_recall: 0.7812 - val_precision: 0.7042 - val_auc: 0.8068\n",
            "Epoch 280/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4824 - accuracy: 0.7821 - sensitivity_at_specificity: 0.9358 - specificity_at_sensitivity: 0.9474 - recall: 0.7706 - precision: 0.7000 - auc: 0.8487\n",
            "Epoch 280: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4955 - accuracy: 0.7756 - sensitivity_at_specificity: 0.9256 - specificity_at_sensitivity: 0.9372 - recall: 0.7521 - precision: 0.6947 - auc: 0.8374 - val_loss: 0.4983 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.8987 - val_specificity_at_sensitivity: 0.9136 - val_recall: 0.7089 - val_precision: 0.7887 - val_auc: 0.8427\n",
            "Epoch 281/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5206 - accuracy: 0.7222 - sensitivity_at_specificity: 0.9010 - specificity_at_sensitivity: 0.8289 - recall: 0.4653 - precision: 0.6438 - auc: 0.7889\n",
            "Epoch 281: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5375 - accuracy: 0.7219 - sensitivity_at_specificity: 0.8974 - specificity_at_sensitivity: 0.8227 - recall: 0.4701 - precision: 0.6707 - auc: 0.7826 - val_loss: 0.5233 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.9048 - val_specificity_at_sensitivity: 0.9342 - val_recall: 0.7024 - val_precision: 0.8429 - val_auc: 0.8422\n",
            "Epoch 282/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5219 - accuracy: 0.7431 - sensitivity_at_specificity: 0.8617 - specificity_at_sensitivity: 0.8608 - recall: 0.4787 - precision: 0.6429 - auc: 0.7758\n",
            "Epoch 282: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5113 - accuracy: 0.7500 - sensitivity_at_specificity: 0.8713 - specificity_at_sensitivity: 0.8630 - recall: 0.4851 - precision: 0.6364 - auc: 0.7852 - val_loss: 0.4872 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.8929 - val_specificity_at_sensitivity: 0.9423 - val_recall: 0.5357 - val_precision: 0.7692 - val_auc: 0.8176\n",
            "Epoch 283/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5063 - accuracy: 0.7326 - sensitivity_at_specificity: 0.9151 - specificity_at_sensitivity: 0.8791 - recall: 0.4623 - precision: 0.7101 - auc: 0.8188\n",
            "Epoch 283: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4982 - accuracy: 0.7437 - sensitivity_at_specificity: 0.9224 - specificity_at_sensitivity: 0.8873 - recall: 0.4828 - precision: 0.7179 - auc: 0.8220 - val_loss: 0.5125 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.8696 - val_specificity_at_sensitivity: 0.9341 - val_recall: 0.6812 - val_precision: 0.7581 - val_auc: 0.8210\n",
            "Epoch 284/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4999 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9340 - specificity_at_sensitivity: 0.8681 - recall: 0.6604 - precision: 0.7071 - auc: 0.8198\n",
            "Epoch 284: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4935 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9333 - specificity_at_sensitivity: 0.8800 - recall: 0.6667 - precision: 0.7273 - auc: 0.8266 - val_loss: 0.4820 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 0.9048 - val_specificity_at_sensitivity: 0.9278 - val_recall: 0.6984 - val_precision: 0.7586 - val_auc: 0.8386\n",
            "Epoch 285/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4804 - accuracy: 0.7986 - sensitivity_at_specificity: 0.8796 - specificity_at_sensitivity: 0.9556 - recall: 0.7130 - precision: 0.7404 - auc: 0.8378\n",
            "Epoch 285: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4810 - accuracy: 0.7906 - sensitivity_at_specificity: 0.8908 - specificity_at_sensitivity: 0.9453 - recall: 0.7227 - precision: 0.7167 - auc: 0.8371 - val_loss: 0.5500 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.8841 - val_specificity_at_sensitivity: 0.8901 - val_recall: 0.5362 - val_precision: 0.7551 - val_auc: 0.8052\n",
            "Epoch 286/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4987 - accuracy: 0.7257 - sensitivity_at_specificity: 0.9402 - specificity_at_sensitivity: 0.8772 - recall: 0.5470 - precision: 0.7111 - auc: 0.8351\n",
            "Epoch 286: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5050 - accuracy: 0.7250 - sensitivity_at_specificity: 0.9389 - specificity_at_sensitivity: 0.8730 - recall: 0.5649 - precision: 0.7048 - auc: 0.8291 - val_loss: 0.5186 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.9516 - val_specificity_at_sensitivity: 0.8776 - val_recall: 0.6452 - val_precision: 0.6452 - val_auc: 0.8034\n",
            "Epoch 287/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5012 - accuracy: 0.7674 - sensitivity_at_specificity: 0.9184 - specificity_at_sensitivity: 0.8789 - recall: 0.6327 - precision: 0.6667 - auc: 0.8088\n",
            "Epoch 287: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4923 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9196 - specificity_at_sensitivity: 0.8894 - recall: 0.6429 - precision: 0.6923 - auc: 0.8210 - val_loss: 0.5019 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9500 - val_specificity_at_sensitivity: 0.8800 - val_recall: 0.6000 - val_precision: 0.6545 - val_auc: 0.8165\n",
            "Epoch 288/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5603 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8505 - specificity_at_sensitivity: 0.8398 - recall: 0.5140 - precision: 0.6548 - auc: 0.7604\n",
            "Epoch 288: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5524 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8729 - specificity_at_sensitivity: 0.8465 - recall: 0.5169 - precision: 0.6489 - auc: 0.7663 - val_loss: 0.5031 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.8750 - val_specificity_at_sensitivity: 0.9205 - val_recall: 0.7500 - val_precision: 0.7606 - val_auc: 0.8324\n",
            "Epoch 289/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5166 - accuracy: 0.7464 - sensitivity_at_specificity: 0.8750 - specificity_at_sensitivity: 0.8977 - recall: 0.5385 - precision: 0.7089 - auc: 0.7996\n",
            "Epoch 289: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5258 - accuracy: 0.7436 - sensitivity_at_specificity: 0.8584 - specificity_at_sensitivity: 0.8844 - recall: 0.5398 - precision: 0.6854 - auc: 0.7886 - val_loss: 0.5200 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.9481 - val_specificity_at_sensitivity: 0.9277 - val_recall: 0.5325 - val_precision: 0.8367 - val_auc: 0.8483\n",
            "Epoch 290/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4899 - accuracy: 0.7500 - sensitivity_at_specificity: 0.9160 - specificity_at_sensitivity: 0.9408 - recall: 0.6303 - precision: 0.7282 - auc: 0.8436\n",
            "Epoch 290: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4879 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9231 - specificity_at_sensitivity: 0.9421 - recall: 0.6462 - precision: 0.7059 - auc: 0.8425 - val_loss: 0.4964 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9054 - val_specificity_at_sensitivity: 0.9535 - val_recall: 0.7838 - val_precision: 0.7342 - val_auc: 0.8497\n",
            "Epoch 291/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5140 - accuracy: 0.7569 - sensitivity_at_specificity: 0.9298 - specificity_at_sensitivity: 0.8793 - recall: 0.6316 - precision: 0.7200 - auc: 0.8159\n",
            "Epoch 291: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5063 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9365 - specificity_at_sensitivity: 0.8763 - recall: 0.6270 - precision: 0.7315 - auc: 0.8235 - val_loss: 0.5211 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9016 - val_specificity_at_sensitivity: 0.9091 - val_recall: 0.5574 - val_precision: 0.6939 - val_auc: 0.8074\n",
            "Epoch 292/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5225 - accuracy: 0.7257 - sensitivity_at_specificity: 0.8772 - specificity_at_sensitivity: 0.9023 - recall: 0.6053 - precision: 0.6699 - auc: 0.8046\n",
            "Epoch 292: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5253 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8846 - specificity_at_sensitivity: 0.9263 - recall: 0.6231 - precision: 0.6639 - auc: 0.8046 - val_loss: 0.5204 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9286 - val_specificity_at_sensitivity: 0.8889 - val_recall: 0.7000 - val_precision: 0.6901 - val_auc: 0.8112\n",
            "Epoch 293/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5265 - accuracy: 0.7118 - sensitivity_at_specificity: 0.8992 - specificity_at_sensitivity: 0.8343 - recall: 0.6134 - precision: 0.6636 - auc: 0.8010\n",
            "Epoch 293: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5238 - accuracy: 0.7125 - sensitivity_at_specificity: 0.9219 - specificity_at_sensitivity: 0.8333 - recall: 0.6016 - precision: 0.6525 - auc: 0.8023 - val_loss: 0.5793 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.9014 - val_specificity_at_sensitivity: 0.8652 - val_recall: 0.4789 - val_precision: 0.7727 - val_auc: 0.7967\n",
            "Epoch 294/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4489 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9717 - specificity_at_sensitivity: 0.9176 - recall: 0.6038 - precision: 0.7529 - auc: 0.8661\n",
            "Epoch 294: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4589 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9417 - specificity_at_sensitivity: 0.9200 - recall: 0.6333 - precision: 0.7451 - auc: 0.8589 - val_loss: 0.5132 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.8793 - val_specificity_at_sensitivity: 0.8922 - val_recall: 0.6207 - val_precision: 0.6545 - val_auc: 0.8002\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4772 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9302 - specificity_at_sensitivity: 0.9424 - recall: 0.6124 - precision: 0.7596 - auc: 0.8518\n",
            "Epoch 295: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4772 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9302 - specificity_at_sensitivity: 0.9424 - recall: 0.6124 - precision: 0.7596 - auc: 0.8518 - val_loss: 0.5703 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8382 - val_specificity_at_sensitivity: 0.9022 - val_recall: 0.5735 - val_precision: 0.6842 - val_auc: 0.7693\n",
            "Epoch 296/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4808 - accuracy: 0.7778 - sensitivity_at_specificity: 0.8991 - specificity_at_sensitivity: 0.9330 - recall: 0.6881 - precision: 0.7143 - auc: 0.8450\n",
            "Epoch 296: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4969 - accuracy: 0.7625 - sensitivity_at_specificity: 0.8943 - specificity_at_sensitivity: 0.9086 - recall: 0.6667 - precision: 0.7009 - auc: 0.8297 - val_loss: 0.5713 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.9028 - val_specificity_at_sensitivity: 0.8977 - val_recall: 0.4722 - val_precision: 0.7907 - val_auc: 0.8071\n",
            "Epoch 297/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4809 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9298 - specificity_at_sensitivity: 0.9310 - recall: 0.6140 - precision: 0.7692 - auc: 0.8468\n",
            "Epoch 297: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4896 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9231 - specificity_at_sensitivity: 0.9158 - recall: 0.6077 - precision: 0.7670 - auc: 0.8423 - val_loss: 0.5037 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.8732 - val_specificity_at_sensitivity: 0.9213 - val_recall: 0.8028 - val_precision: 0.7037 - val_auc: 0.8408\n",
            "Epoch 298/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4931 - accuracy: 0.7882 - sensitivity_at_specificity: 0.8952 - specificity_at_sensitivity: 0.8852 - recall: 0.7333 - precision: 0.7000 - auc: 0.8267\n",
            "Epoch 298: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4986 - accuracy: 0.7844 - sensitivity_at_specificity: 0.8760 - specificity_at_sensitivity: 0.8945 - recall: 0.7025 - precision: 0.7203 - auc: 0.8212 - val_loss: 0.5671 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.9351 - val_specificity_at_sensitivity: 0.9036 - val_recall: 0.4286 - val_precision: 0.8250 - val_auc: 0.8371\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5060 - accuracy: 0.7312 - sensitivity_at_specificity: 0.9375 - specificity_at_sensitivity: 0.8606 - recall: 0.4911 - precision: 0.6548 - auc: 0.8146\n",
            "Epoch 299: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5060 - accuracy: 0.7312 - sensitivity_at_specificity: 0.9375 - specificity_at_sensitivity: 0.8606 - recall: 0.4911 - precision: 0.6548 - auc: 0.8146 - val_loss: 0.5388 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.9189 - val_specificity_at_sensitivity: 0.8605 - val_recall: 0.5676 - val_precision: 0.7368 - val_auc: 0.8063\n",
            "Epoch 300/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5261 - accuracy: 0.7431 - sensitivity_at_specificity: 0.8447 - specificity_at_sensitivity: 0.8486 - recall: 0.5631 - precision: 0.6667 - auc: 0.7939\n",
            "Epoch 300: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5080 - accuracy: 0.7531 - sensitivity_at_specificity: 0.8661 - specificity_at_sensitivity: 0.8702 - recall: 0.5804 - precision: 0.6701 - auc: 0.8073 - val_loss: 0.5401 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.9286 - val_specificity_at_sensitivity: 0.9000 - val_recall: 0.5714 - val_precision: 0.7843 - val_auc: 0.8095\n",
            "Epoch 301/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4699 - accuracy: 0.7500 - sensitivity_at_specificity: 0.9722 - specificity_at_sensitivity: 0.9000 - recall: 0.4907 - precision: 0.7571 - auc: 0.8469\n",
            "Epoch 301: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4681 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9750 - specificity_at_sensitivity: 0.9100 - recall: 0.5167 - precision: 0.7470 - auc: 0.8499 - val_loss: 0.4701 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.9242 - val_specificity_at_sensitivity: 0.9362 - val_recall: 0.7879 - val_precision: 0.7222 - val_auc: 0.8623\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4988 - accuracy: 0.7469 - sensitivity_at_specificity: 0.8839 - specificity_at_sensitivity: 0.9135 - recall: 0.6250 - precision: 0.6422 - auc: 0.8145\n",
            "Epoch 302: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4988 - accuracy: 0.7469 - sensitivity_at_specificity: 0.8839 - specificity_at_sensitivity: 0.9135 - recall: 0.6250 - precision: 0.6422 - auc: 0.8145 - val_loss: 0.6383 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.8378 - val_specificity_at_sensitivity: 0.8837 - val_recall: 0.4054 - val_precision: 0.7895 - val_auc: 0.7662\n",
            "Epoch 303/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5027 - accuracy: 0.7292 - sensitivity_at_specificity: 0.9444 - specificity_at_sensitivity: 0.8611 - recall: 0.5093 - precision: 0.6875 - auc: 0.8149\n",
            "Epoch 303: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4992 - accuracy: 0.7437 - sensitivity_at_specificity: 0.9417 - specificity_at_sensitivity: 0.8800 - recall: 0.5417 - precision: 0.7065 - auc: 0.8205 - val_loss: 0.4765 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.9178 - val_specificity_at_sensitivity: 0.9195 - val_recall: 0.6849 - val_precision: 0.7463 - val_auc: 0.8555\n",
            "Epoch 304/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4788 - accuracy: 0.7708 - sensitivity_at_specificity: 0.9231 - specificity_at_sensitivity: 0.8889 - recall: 0.7009 - precision: 0.7257 - auc: 0.8466\n",
            "Epoch 304: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4910 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9134 - specificity_at_sensitivity: 0.8860 - recall: 0.6772 - precision: 0.7049 - auc: 0.8336 - val_loss: 0.4998 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.8889 - val_specificity_at_sensitivity: 0.8969 - val_recall: 0.7460 - val_precision: 0.6812 - val_auc: 0.8264\n",
            "Epoch 305/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5047 - accuracy: 0.7431 - sensitivity_at_specificity: 0.9159 - specificity_at_sensitivity: 0.8895 - recall: 0.6075 - precision: 0.6701 - auc: 0.8149\n",
            "Epoch 305: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4874 - accuracy: 0.7563 - sensitivity_at_specificity: 0.9211 - specificity_at_sensitivity: 0.8981 - recall: 0.6140 - precision: 0.6731 - auc: 0.8251 - val_loss: 0.5621 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8933 - val_specificity_at_sensitivity: 0.8824 - val_recall: 0.4667 - val_precision: 0.8537 - val_auc: 0.8060\n",
            "Epoch 306/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5151 - accuracy: 0.7188 - sensitivity_at_specificity: 0.9180 - specificity_at_sensitivity: 0.9157 - recall: 0.5738 - precision: 0.7071 - auc: 0.8188\n",
            "Epoch 306: val_accuracy did not improve from 0.81250\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5086 - accuracy: 0.7219 - sensitivity_at_specificity: 0.9185 - specificity_at_sensitivity: 0.9189 - recall: 0.5630 - precision: 0.7170 - auc: 0.8253 - val_loss: 0.5546 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.8571 - val_specificity_at_sensitivity: 0.8846 - val_recall: 0.7143 - val_precision: 0.6154 - val_auc: 0.7845\n",
            "Epoch 307/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5168 - accuracy: 0.7431 - sensitivity_at_specificity: 0.8922 - specificity_at_sensitivity: 0.8656 - recall: 0.5490 - precision: 0.6667 - auc: 0.8006\n",
            "Epoch 307: val_accuracy improved from 0.81250 to 0.82500, saving model to ECG_Model_Lead_1.h5\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5162 - accuracy: 0.7437 - sensitivity_at_specificity: 0.9052 - specificity_at_sensitivity: 0.8725 - recall: 0.5431 - precision: 0.6848 - auc: 0.8061 - val_loss: 0.4420 - val_accuracy: 0.8250 - val_sensitivity_at_specificity: 0.9180 - val_specificity_at_sensitivity: 0.9394 - val_recall: 0.7541 - val_precision: 0.7797 - val_auc: 0.8742\n",
            "Epoch 308/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5191 - accuracy: 0.7361 - sensitivity_at_specificity: 0.9083 - specificity_at_sensitivity: 0.8988 - recall: 0.6333 - precision: 0.7037 - auc: 0.8142\n",
            "Epoch 308: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5287 - accuracy: 0.7312 - sensitivity_at_specificity: 0.9015 - specificity_at_sensitivity: 0.8777 - recall: 0.6136 - precision: 0.6983 - auc: 0.8049 - val_loss: 0.5163 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.9130 - val_specificity_at_sensitivity: 0.9011 - val_recall: 0.6522 - val_precision: 0.6923 - val_auc: 0.8149\n",
            "Epoch 309/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5338 - accuracy: 0.7153 - sensitivity_at_specificity: 0.9252 - specificity_at_sensitivity: 0.8398 - recall: 0.4860 - precision: 0.6582 - auc: 0.7971\n",
            "Epoch 309: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5236 - accuracy: 0.7250 - sensitivity_at_specificity: 0.9316 - specificity_at_sensitivity: 0.8522 - recall: 0.4957 - precision: 0.6667 - auc: 0.8042 - val_loss: 0.4707 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9552 - val_specificity_at_sensitivity: 0.9032 - val_recall: 0.6866 - val_precision: 0.7667 - val_auc: 0.8608\n",
            "Epoch 310/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5271 - accuracy: 0.7292 - sensitivity_at_specificity: 0.8829 - specificity_at_sensitivity: 0.9096 - recall: 0.6396 - precision: 0.6514 - auc: 0.8031\n",
            "Epoch 310: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5182 - accuracy: 0.7375 - sensitivity_at_specificity: 0.8968 - specificity_at_sensitivity: 0.9330 - recall: 0.6746 - precision: 0.6641 - auc: 0.8147 - val_loss: 0.4789 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.9559 - val_specificity_at_sensitivity: 0.8804 - val_recall: 0.7206 - val_precision: 0.7424 - val_auc: 0.8430\n",
            "Epoch 311/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4288 - accuracy: 0.7951 - sensitivity_at_specificity: 0.9457 - specificity_at_sensitivity: 0.9388 - recall: 0.5761 - precision: 0.7260 - auc: 0.8700\n",
            "Epoch 311: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4276 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9423 - specificity_at_sensitivity: 0.9444 - recall: 0.5769 - precision: 0.7500 - auc: 0.8724 - val_loss: 0.5745 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.9474 - val_specificity_at_sensitivity: 0.9167 - val_recall: 0.4605 - val_precision: 0.8974 - val_auc: 0.8653\n",
            "Epoch 312/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5457 - accuracy: 0.7083 - sensitivity_at_specificity: 0.8818 - specificity_at_sensitivity: 0.8483 - recall: 0.5455 - precision: 0.6383 - auc: 0.7863\n",
            "Epoch 312: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5432 - accuracy: 0.7125 - sensitivity_at_specificity: 0.8760 - specificity_at_sensitivity: 0.8593 - recall: 0.5702 - precision: 0.6330 - auc: 0.7853 - val_loss: 0.5033 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9254 - val_specificity_at_sensitivity: 0.9140 - val_recall: 0.8657 - val_precision: 0.6304 - val_auc: 0.8408\n",
            "Epoch 313/500\n",
            " 6/10 [=================>............] - ETA: 0s - loss: 0.4952 - accuracy: 0.7500 - sensitivity_at_specificity: 0.9342 - specificity_at_sensitivity: 0.9138 - recall: 0.7237 - precision: 0.6707 - auc: 0.8372\n",
            "Epoch 313: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.4830 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9091 - specificity_at_sensitivity: 0.9246 - recall: 0.6694 - precision: 0.6923 - auc: 0.8408 - val_loss: 0.6779 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.9012 - val_specificity_at_sensitivity: 0.8608 - val_recall: 0.3457 - val_precision: 0.8485 - val_auc: 0.7837\n",
            "Epoch 314/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4815 - accuracy: 0.7674 - sensitivity_at_specificity: 0.9519 - specificity_at_sensitivity: 0.9185 - recall: 0.4615 - precision: 0.8136 - auc: 0.8501\n",
            "Epoch 314: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4821 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9496 - specificity_at_sensitivity: 0.9154 - recall: 0.4622 - precision: 0.8088 - auc: 0.8546 - val_loss: 0.5546 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8611 - val_specificity_at_sensitivity: 0.8182 - val_recall: 0.6250 - val_precision: 0.6818 - val_auc: 0.7845\n",
            "Epoch 315/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4650 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9140 - specificity_at_sensitivity: 0.9231 - recall: 0.6989 - precision: 0.6373 - auc: 0.8463\n",
            "Epoch 315: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4691 - accuracy: 0.7781 - sensitivity_at_specificity: 0.9048 - specificity_at_sensitivity: 0.9256 - recall: 0.6952 - precision: 0.6518 - auc: 0.8416 - val_loss: 0.4848 - val_accuracy: 0.8000 - val_sensitivity_at_specificity: 0.9459 - val_specificity_at_sensitivity: 0.9535 - val_recall: 0.6351 - val_precision: 0.9038 - val_auc: 0.8776\n",
            "Epoch 316/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5244 - accuracy: 0.7326 - sensitivity_at_specificity: 0.8700 - specificity_at_sensitivity: 0.8723 - recall: 0.3800 - precision: 0.7170 - auc: 0.8055       \n",
            "Epoch 316: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5192 - accuracy: 0.7312 - sensitivity_at_specificity: 0.8772 - specificity_at_sensitivity: 0.8689 - recall: 0.3947 - precision: 0.7258 - auc: 0.8134 - val_loss: 0.5204 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.8406 - val_specificity_at_sensitivity: 0.9341 - val_recall: 0.6812 - val_precision: 0.7966 - val_auc: 0.8129\n",
            "Epoch 317/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5044 - accuracy: 0.7361 - sensitivity_at_specificity: 0.9541 - specificity_at_sensitivity: 0.8659 - recall: 0.6881 - precision: 0.6410 - auc: 0.8215\n",
            "Epoch 317: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5084 - accuracy: 0.7281 - sensitivity_at_specificity: 0.9512 - specificity_at_sensitivity: 0.8934 - recall: 0.6992 - precision: 0.6324 - auc: 0.8201 - val_loss: 0.4694 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.9041 - val_specificity_at_sensitivity: 0.9540 - val_recall: 0.8219 - val_precision: 0.7229 - val_auc: 0.8667\n",
            "Epoch 318/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5228 - accuracy: 0.7153 - sensitivity_at_specificity: 0.9187 - specificity_at_sensitivity: 0.8848 - recall: 0.6260 - precision: 0.6814 - auc: 0.8109\n",
            "Epoch 318: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5310 - accuracy: 0.7094 - sensitivity_at_specificity: 0.8963 - specificity_at_sensitivity: 0.8541 - recall: 0.6000 - precision: 0.6750 - auc: 0.8029 - val_loss: 0.5104 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9306 - val_specificity_at_sensitivity: 0.8864 - val_recall: 0.6806 - val_precision: 0.7101 - val_auc: 0.8268\n",
            "Epoch 319/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5069 - accuracy: 0.7257 - sensitivity_at_specificity: 0.9231 - specificity_at_sensitivity: 0.8804 - recall: 0.5673 - precision: 0.6344 - auc: 0.8099\n",
            "Epoch 319: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5195 - accuracy: 0.7156 - sensitivity_at_specificity: 0.9237 - specificity_at_sensitivity: 0.8564 - recall: 0.5678 - precision: 0.6262 - auc: 0.8027 - val_loss: 0.5750 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.8551 - val_specificity_at_sensitivity: 0.8242 - val_recall: 0.5652 - val_precision: 0.6610 - val_auc: 0.7654\n",
            "Epoch 320/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4961 - accuracy: 0.7639 - sensitivity_at_specificity: 0.9175 - specificity_at_sensitivity: 0.8796 - recall: 0.5464 - precision: 0.6883 - auc: 0.8121\n",
            "Epoch 320: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4811 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9266 - specificity_at_sensitivity: 0.8863 - recall: 0.5688 - precision: 0.7126 - auc: 0.8299 - val_loss: 0.5156 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.9180 - val_specificity_at_sensitivity: 0.8889 - val_recall: 0.4590 - val_precision: 0.7778 - val_auc: 0.8124\n",
            "Epoch 321/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5118 - accuracy: 0.7500 - sensitivity_at_specificity: 0.8981 - specificity_at_sensitivity: 0.9000 - recall: 0.6019 - precision: 0.6915 - auc: 0.8077\n",
            "Epoch 321: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5014 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9016 - specificity_at_sensitivity: 0.9091 - recall: 0.6066 - precision: 0.7048 - auc: 0.8192 - val_loss: 0.4749 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.9710 - val_specificity_at_sensitivity: 0.9121 - val_recall: 0.6667 - val_precision: 0.7302 - val_auc: 0.8522\n",
            "Epoch 322/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4417 - accuracy: 0.8090 - sensitivity_at_specificity: 0.9706 - specificity_at_sensitivity: 0.9247 - recall: 0.6765 - precision: 0.7582 - auc: 0.8693\n",
            "Epoch 322: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4413 - accuracy: 0.8062 - sensitivity_at_specificity: 0.9744 - specificity_at_sensitivity: 0.9261 - recall: 0.6667 - precision: 0.7723 - auc: 0.8746 - val_loss: 0.4817 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9016 - val_specificity_at_sensitivity: 0.9394 - val_recall: 0.6885 - val_precision: 0.7000 - val_auc: 0.8384\n",
            "Epoch 323/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4553 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9596 - specificity_at_sensitivity: 0.9116 - recall: 0.6162 - precision: 0.7093 - auc: 0.8531\n",
            "Epoch 323: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4565 - accuracy: 0.7885 - sensitivity_at_specificity: 0.9558 - specificity_at_sensitivity: 0.9196 - recall: 0.6372 - precision: 0.7423 - auc: 0.8559 - val_loss: 0.4556 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.9420 - val_specificity_at_sensitivity: 0.9670 - val_recall: 0.7391 - val_precision: 0.7612 - val_auc: 0.8638\n",
            "Epoch 324/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4707 - accuracy: 0.7674 - sensitivity_at_specificity: 0.9111 - specificity_at_sensitivity: 0.8939 - recall: 0.6333 - precision: 0.6264 - auc: 0.8251\n",
            "Epoch 324: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4876 - accuracy: 0.7563 - sensitivity_at_specificity: 0.8942 - specificity_at_sensitivity: 0.8981 - recall: 0.5962 - precision: 0.6327 - auc: 0.8146 - val_loss: 0.5875 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.8714 - val_specificity_at_sensitivity: 0.9111 - val_recall: 0.4571 - val_precision: 0.8205 - val_auc: 0.8083\n",
            "Epoch 325/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5712 - accuracy: 0.7049 - sensitivity_at_specificity: 0.8615 - specificity_at_sensitivity: 0.8228 - recall: 0.6538 - precision: 0.6800 - auc: 0.7789\n",
            "Epoch 325: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5548 - accuracy: 0.7219 - sensitivity_at_specificity: 0.8750 - specificity_at_sensitivity: 0.8295 - recall: 0.6875 - precision: 0.6923 - auc: 0.7914 - val_loss: 0.5222 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9531 - val_specificity_at_sensitivity: 0.9167 - val_recall: 0.8906 - val_precision: 0.6196 - val_auc: 0.8622\n",
            "Epoch 326/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4663 - accuracy: 0.8021 - sensitivity_at_specificity: 0.9279 - specificity_at_sensitivity: 0.9266 - recall: 0.8018 - precision: 0.7177 - auc: 0.8622\n",
            "Epoch 326: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4838 - accuracy: 0.7906 - sensitivity_at_specificity: 0.9055 - specificity_at_sensitivity: 0.9171 - recall: 0.7559 - precision: 0.7273 - auc: 0.8421 - val_loss: 0.5763 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8919 - val_specificity_at_sensitivity: 0.9070 - val_recall: 0.4459 - val_precision: 0.8684 - val_auc: 0.8272\n",
            "Epoch 327/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5119 - accuracy: 0.7639 - sensitivity_at_specificity: 0.8889 - specificity_at_sensitivity: 0.8942 - recall: 0.5051 - precision: 0.7246 - auc: 0.7985\n",
            "Epoch 327: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5117 - accuracy: 0.7688 - sensitivity_at_specificity: 0.8785 - specificity_at_sensitivity: 0.8967 - recall: 0.5047 - precision: 0.7200 - auc: 0.7931 - val_loss: 0.5141 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.8939 - val_specificity_at_sensitivity: 0.9574 - val_recall: 0.6061 - val_precision: 0.8000 - val_auc: 0.8179\n",
            "Epoch 328/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4391 - accuracy: 0.8160 - sensitivity_at_specificity: 0.9457 - specificity_at_sensitivity: 0.9490 - recall: 0.5326 - precision: 0.8305 - auc: 0.8610\n",
            "Epoch 328: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4496 - accuracy: 0.8094 - sensitivity_at_specificity: 0.9333 - specificity_at_sensitivity: 0.9488 - recall: 0.5238 - precision: 0.8333 - auc: 0.8528 - val_loss: 0.4842 - val_accuracy: 0.8000 - val_sensitivity_at_specificity: 0.9219 - val_specificity_at_sensitivity: 0.9583 - val_recall: 0.5781 - val_precision: 0.8810 - val_auc: 0.8502\n",
            "Epoch 329/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4611 - accuracy: 0.7847 - sensitivity_at_specificity: 0.9505 - specificity_at_sensitivity: 0.9144 - recall: 0.5941 - precision: 0.7407 - auc: 0.8480\n",
            "Epoch 329: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4691 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9292 - specificity_at_sensitivity: 0.9082 - recall: 0.6106 - precision: 0.7419 - auc: 0.8408 - val_loss: 0.4504 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9444 - val_specificity_at_sensitivity: 0.9659 - val_recall: 0.6389 - val_precision: 0.7797 - val_auc: 0.8750\n",
            "Epoch 330/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4892 - accuracy: 0.7778 - sensitivity_at_specificity: 0.9224 - specificity_at_sensitivity: 0.9477 - recall: 0.6466 - precision: 0.7653 - auc: 0.8437\n",
            "Epoch 330: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4844 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9323 - specificity_at_sensitivity: 0.9198 - recall: 0.6617 - precision: 0.7857 - auc: 0.8504 - val_loss: 0.5291 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.8857 - val_specificity_at_sensitivity: 0.9222 - val_recall: 0.6857 - val_precision: 0.7273 - val_auc: 0.8075\n",
            "Epoch 331/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5108 - accuracy: 0.7465 - sensitivity_at_specificity: 0.8972 - specificity_at_sensitivity: 0.8840 - recall: 0.6542 - precision: 0.6604 - auc: 0.8140\n",
            "Epoch 331: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5252 - accuracy: 0.7344 - sensitivity_at_specificity: 0.8934 - specificity_at_sensitivity: 0.8687 - recall: 0.6066 - precision: 0.6667 - auc: 0.8015 - val_loss: 0.4963 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 0.8871 - val_specificity_at_sensitivity: 0.9592 - val_recall: 0.6129 - val_precision: 0.8085 - val_auc: 0.8209\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5150 - accuracy: 0.7719 - sensitivity_at_specificity: 0.8760 - specificity_at_sensitivity: 0.9162 - recall: 0.6279 - precision: 0.7642 - auc: 0.8168\n",
            "Epoch 332: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5150 - accuracy: 0.7719 - sensitivity_at_specificity: 0.8760 - specificity_at_sensitivity: 0.9162 - recall: 0.6279 - precision: 0.7642 - auc: 0.8168 - val_loss: 0.5197 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8281 - val_specificity_at_sensitivity: 0.9688 - val_recall: 0.6562 - val_precision: 0.6774 - val_auc: 0.7982\n",
            "Epoch 333/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5150 - accuracy: 0.7569 - sensitivity_at_specificity: 0.9355 - specificity_at_sensitivity: 0.8902 - recall: 0.6855 - precision: 0.7328 - auc: 0.8252\n",
            "Epoch 333: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5145 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9281 - specificity_at_sensitivity: 0.8950 - recall: 0.6835 - precision: 0.7422 - auc: 0.8261 - val_loss: 0.4813 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.9412 - val_specificity_at_sensitivity: 0.9239 - val_recall: 0.7206 - val_precision: 0.7424 - val_auc: 0.8499\n",
            "Epoch 334/500\n",
            " 6/10 [=================>............] - ETA: 0s - loss: 0.4450 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9545 - specificity_at_sensitivity: 0.9444 - recall: 0.5758 - precision: 0.7308 - auc: 0.8600\n",
            "Epoch 334: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4630 - accuracy: 0.7688 - sensitivity_at_specificity: 0.9464 - specificity_at_sensitivity: 0.9183 - recall: 0.5446 - precision: 0.7262 - auc: 0.8464 - val_loss: 0.5383 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8824 - val_specificity_at_sensitivity: 0.8804 - val_recall: 0.4853 - val_precision: 0.7500 - val_auc: 0.8147\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4830 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9244 - specificity_at_sensitivity: 0.9005 - recall: 0.5630 - precision: 0.7444 - auc: 0.8378\n",
            "Epoch 335: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4830 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9244 - specificity_at_sensitivity: 0.9005 - recall: 0.5630 - precision: 0.7444 - auc: 0.8378 - val_loss: 0.5141 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9242 - val_specificity_at_sensitivity: 0.8830 - val_recall: 0.7576 - val_precision: 0.6579 - val_auc: 0.8241\n",
            "Epoch 336/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4912 - accuracy: 0.7569 - sensitivity_at_specificity: 0.9217 - specificity_at_sensitivity: 0.9133 - recall: 0.6957 - precision: 0.6957 - auc: 0.8340\n",
            "Epoch 336: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4831 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9187 - specificity_at_sensitivity: 0.9137 - recall: 0.6911 - precision: 0.6967 - auc: 0.8383 - val_loss: 0.4996 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.9333 - val_specificity_at_sensitivity: 0.8824 - val_recall: 0.6667 - val_precision: 0.7692 - val_auc: 0.8462\n",
            "Epoch 337/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4698 - accuracy: 0.7847 - sensitivity_at_specificity: 0.9537 - specificity_at_sensitivity: 0.8667 - recall: 0.6944 - precision: 0.7212 - auc: 0.8450\n",
            "Epoch 337: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4815 - accuracy: 0.7688 - sensitivity_at_specificity: 0.9516 - specificity_at_sensitivity: 0.8673 - recall: 0.6532 - precision: 0.7232 - auc: 0.8411 - val_loss: 0.4953 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9275 - val_specificity_at_sensitivity: 0.9231 - val_recall: 0.5362 - val_precision: 0.7872 - val_auc: 0.8424\n",
            "Epoch 338/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5385 - accuracy: 0.7465 - sensitivity_at_specificity: 0.8968 - specificity_at_sensitivity: 0.8642 - recall: 0.7460 - precision: 0.6963 - auc: 0.8064\n",
            "Epoch 338: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.5220 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9058 - specificity_at_sensitivity: 0.8791 - recall: 0.7609 - precision: 0.7095 - auc: 0.8204 - val_loss: 0.4844 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9143 - val_specificity_at_sensitivity: 0.9111 - val_recall: 0.7286 - val_precision: 0.7286 - val_auc: 0.8424\n",
            "Epoch 339/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5048 - accuracy: 0.7396 - sensitivity_at_specificity: 0.9154 - specificity_at_sensitivity: 0.9051 - recall: 0.6615 - precision: 0.7350 - auc: 0.8325\n",
            "Epoch 339: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5047 - accuracy: 0.7437 - sensitivity_at_specificity: 0.9167 - specificity_at_sensitivity: 0.9034 - recall: 0.6736 - precision: 0.7348 - auc: 0.8320 - val_loss: 0.4982 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9178 - val_specificity_at_sensitivity: 0.8851 - val_recall: 0.6575 - val_precision: 0.7273 - val_auc: 0.8361\n",
            "Epoch 340/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4423 - accuracy: 0.7951 - sensitivity_at_specificity: 0.9727 - specificity_at_sensitivity: 0.9438 - recall: 0.6636 - precision: 0.7684 - auc: 0.8706\n",
            "Epoch 340: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4562 - accuracy: 0.7937 - sensitivity_at_specificity: 0.9512 - specificity_at_sensitivity: 0.9594 - recall: 0.6585 - precision: 0.7714 - auc: 0.8611 - val_loss: 0.5219 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9512 - val_specificity_at_sensitivity: 0.9231 - val_recall: 0.6341 - val_precision: 0.8000 - val_auc: 0.8359\n",
            "Epoch 341/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5111 - accuracy: 0.7535 - sensitivity_at_specificity: 0.8687 - specificity_at_sensitivity: 0.8571 - recall: 0.5859 - precision: 0.6591 - auc: 0.7993\n",
            "Epoch 341: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5146 - accuracy: 0.7437 - sensitivity_at_specificity: 0.8716 - specificity_at_sensitivity: 0.8531 - recall: 0.5780 - precision: 0.6364 - auc: 0.7946 - val_loss: 0.5232 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8594 - val_specificity_at_sensitivity: 0.9271 - val_recall: 0.5781 - val_precision: 0.7115 - val_auc: 0.8001\n",
            "Epoch 342/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5050 - accuracy: 0.7714 - sensitivity_at_specificity: 0.8679 - specificity_at_sensitivity: 0.9368 - recall: 0.6038 - precision: 0.7442 - auc: 0.8095\n",
            "Epoch 342: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5008 - accuracy: 0.7628 - sensitivity_at_specificity: 0.8793 - specificity_at_sensitivity: 0.9235 - recall: 0.5948 - precision: 0.7188 - auc: 0.8116 - val_loss: 0.4687 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9730 - val_specificity_at_sensitivity: 0.9302 - val_recall: 0.6351 - val_precision: 0.7966 - val_auc: 0.8627\n",
            "Epoch 343/500\n",
            " 6/10 [=================>............] - ETA: 0s - loss: 0.4697 - accuracy: 0.7760 - sensitivity_at_specificity: 0.9118 - specificity_at_sensitivity: 0.9274 - recall: 0.5588 - precision: 0.7451 - auc: 0.8396\n",
            "Epoch 343: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4682 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9352 - specificity_at_sensitivity: 0.9104 - recall: 0.5093 - precision: 0.7143 - auc: 0.8393 - val_loss: 0.5779 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.9079 - val_specificity_at_sensitivity: 0.8929 - val_recall: 0.5000 - val_precision: 0.8085 - val_auc: 0.8029\n",
            "Epoch 344/500\n",
            " 6/10 [=================>............] - ETA: 0s - loss: 0.5152 - accuracy: 0.7500 - sensitivity_at_specificity: 0.8608 - specificity_at_sensitivity: 0.9027 - recall: 0.5949 - precision: 0.7460 - auc: 0.8133\n",
            "Epoch 344: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4876 - accuracy: 0.7719 - sensitivity_at_specificity: 0.8976 - specificity_at_sensitivity: 0.9171 - recall: 0.6614 - precision: 0.7368 - auc: 0.8340 - val_loss: 0.5374 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.8824 - val_specificity_at_sensitivity: 0.8478 - val_recall: 0.6324 - val_precision: 0.6935 - val_auc: 0.7948\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4747 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9431 - specificity_at_sensitivity: 0.9340 - recall: 0.6179 - precision: 0.7238 - auc: 0.8418\n",
            "Epoch 345: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4747 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9431 - specificity_at_sensitivity: 0.9340 - recall: 0.6179 - precision: 0.7238 - auc: 0.8418 - val_loss: 0.5172 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.9200 - val_specificity_at_sensitivity: 0.8941 - val_recall: 0.6400 - val_precision: 0.7742 - val_auc: 0.8277\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4563 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9505 - specificity_at_sensitivity: 0.8950 - recall: 0.5842 - precision: 0.6782 - auc: 0.8476\n",
            "Epoch 346: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4563 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9505 - specificity_at_sensitivity: 0.8950 - recall: 0.5842 - precision: 0.6782 - auc: 0.8476 - val_loss: 0.4956 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9231 - val_specificity_at_sensitivity: 0.9263 - val_recall: 0.5692 - val_precision: 0.8409 - val_auc: 0.8470\n",
            "Epoch 347/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4929 - accuracy: 0.7361 - sensitivity_at_specificity: 0.9487 - specificity_at_sensitivity: 0.8830 - recall: 0.6154 - precision: 0.6990 - auc: 0.8399\n",
            "Epoch 347: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4803 - accuracy: 0.7437 - sensitivity_at_specificity: 0.9470 - specificity_at_sensitivity: 0.8883 - recall: 0.6288 - precision: 0.7155 - auc: 0.8499 - val_loss: 0.5549 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.9062 - val_specificity_at_sensitivity: 0.8333 - val_recall: 0.7188 - val_precision: 0.5750 - val_auc: 0.7784\n",
            "Epoch 348/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4627 - accuracy: 0.7847 - sensitivity_at_specificity: 0.8791 - specificity_at_sensitivity: 0.9086 - recall: 0.5275 - precision: 0.7164 - auc: 0.8294\n",
            "Epoch 348: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4715 - accuracy: 0.7875 - sensitivity_at_specificity: 0.8835 - specificity_at_sensitivity: 0.9171 - recall: 0.5243 - precision: 0.7397 - auc: 0.8243 - val_loss: 0.5846 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8611 - val_specificity_at_sensitivity: 0.8864 - val_recall: 0.4861 - val_precision: 0.7778 - val_auc: 0.7925\n",
            "Epoch 349/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5086 - accuracy: 0.7396 - sensitivity_at_specificity: 0.9298 - specificity_at_sensitivity: 0.8621 - recall: 0.6842 - precision: 0.6667 - auc: 0.8220\n",
            "Epoch 349: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5012 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9355 - specificity_at_sensitivity: 0.8776 - recall: 0.6935 - precision: 0.6667 - auc: 0.8290 - val_loss: 0.5198 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.9342 - val_specificity_at_sensitivity: 0.8810 - val_recall: 0.7632 - val_precision: 0.6905 - val_auc: 0.8240\n",
            "Epoch 350/500\n",
            " 6/10 [=================>............] - ETA: 0s - loss: 0.4506 - accuracy: 0.7969 - sensitivity_at_specificity: 0.9344 - specificity_at_sensitivity: 0.9008 - recall: 0.7049 - precision: 0.6719 - auc: 0.8521\n",
            "Epoch 350: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4691 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9504 - specificity_at_sensitivity: 0.9045 - recall: 0.6198 - precision: 0.7075 - auc: 0.8486 - val_loss: 0.5208 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.8667 - val_specificity_at_sensitivity: 0.9100 - val_recall: 0.5333 - val_precision: 0.7111 - val_auc: 0.8043\n",
            "Epoch 351/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5004 - accuracy: 0.7847 - sensitivity_at_specificity: 0.8879 - specificity_at_sensitivity: 0.9282 - recall: 0.6355 - precision: 0.7473 - auc: 0.8147\n",
            "Epoch 351: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5041 - accuracy: 0.7781 - sensitivity_at_specificity: 0.8952 - specificity_at_sensitivity: 0.9337 - recall: 0.6290 - precision: 0.7573 - auc: 0.8160 - val_loss: 0.5041 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9286 - val_specificity_at_sensitivity: 0.9333 - val_recall: 0.7429 - val_precision: 0.7324 - val_auc: 0.8347\n",
            "Epoch 352/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5068 - accuracy: 0.7847 - sensitivity_at_specificity: 0.8843 - specificity_at_sensitivity: 0.8982 - recall: 0.7273 - precision: 0.7521 - auc: 0.8247\n",
            "Epoch 352: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5057 - accuracy: 0.7781 - sensitivity_at_specificity: 0.8889 - specificity_at_sensitivity: 0.9081 - recall: 0.7111 - precision: 0.7500 - auc: 0.8266 - val_loss: 0.5235 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.9412 - val_specificity_at_sensitivity: 0.8478 - val_recall: 0.6029 - val_precision: 0.7069 - val_auc: 0.8146\n",
            "Epoch 353/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5236 - accuracy: 0.7361 - sensitivity_at_specificity: 0.8713 - specificity_at_sensitivity: 0.8930 - recall: 0.5248 - precision: 0.6543 - auc: 0.7875\n",
            "Epoch 353: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.5172 - accuracy: 0.7375 - sensitivity_at_specificity: 0.8850 - specificity_at_sensitivity: 0.8744 - recall: 0.5310 - precision: 0.6593 - auc: 0.7969 - val_loss: 0.5584 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8714 - val_specificity_at_sensitivity: 0.8556 - val_recall: 0.5286 - val_precision: 0.7400 - val_auc: 0.7888\n",
            "Epoch 354/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5285 - accuracy: 0.7257 - sensitivity_at_specificity: 0.9018 - specificity_at_sensitivity: 0.8466 - recall: 0.6429 - precision: 0.6486 - auc: 0.7981\n",
            "Epoch 354: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5261 - accuracy: 0.7312 - sensitivity_at_specificity: 0.8952 - specificity_at_sensitivity: 0.8469 - recall: 0.6371 - precision: 0.6583 - auc: 0.7994 - val_loss: 0.5198 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.9178 - val_specificity_at_sensitivity: 0.8851 - val_recall: 0.6438 - val_precision: 0.6912 - val_auc: 0.8155\n",
            "Epoch 355/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4807 - accuracy: 0.7639 - sensitivity_at_specificity: 0.9569 - specificity_at_sensitivity: 0.9012 - recall: 0.7155 - precision: 0.7034 - auc: 0.8431\n",
            "Epoch 355: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4848 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9466 - specificity_at_sensitivity: 0.8995 - recall: 0.7176 - precision: 0.7121 - auc: 0.8411 - val_loss: 0.5738 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8608 - val_specificity_at_sensitivity: 0.9136 - val_recall: 0.6076 - val_precision: 0.7500 - val_auc: 0.7882\n",
            "Epoch 356/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4804 - accuracy: 0.7569 - sensitivity_at_specificity: 0.9159 - specificity_at_sensitivity: 0.8785 - recall: 0.6262 - precision: 0.6907 - auc: 0.8343\n",
            "Epoch 356: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4863 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9091 - specificity_at_sensitivity: 0.8945 - recall: 0.6364 - precision: 0.7000 - auc: 0.8324 - val_loss: 0.5018 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9014 - val_specificity_at_sensitivity: 0.8989 - val_recall: 0.6901 - val_precision: 0.7656 - val_auc: 0.8362\n",
            "Epoch 357/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4634 - accuracy: 0.7951 - sensitivity_at_specificity: 0.9237 - specificity_at_sensitivity: 0.9235 - recall: 0.7034 - precision: 0.7757 - auc: 0.8598\n",
            "Epoch 357: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4651 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9385 - specificity_at_sensitivity: 0.9263 - recall: 0.7000 - precision: 0.7845 - auc: 0.8594 - val_loss: 0.5220 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9189 - val_specificity_at_sensitivity: 0.9302 - val_recall: 0.5946 - val_precision: 0.8302 - val_auc: 0.8308\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9450 - specificity_at_sensitivity: 0.8910 - recall: 0.6422 - precision: 0.7000 - auc: 0.8498\n",
            "Epoch 358: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4645 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9450 - specificity_at_sensitivity: 0.8910 - recall: 0.6422 - precision: 0.7000 - auc: 0.8498 - val_loss: 0.5734 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.9079 - val_specificity_at_sensitivity: 0.8690 - val_recall: 0.5658 - val_precision: 0.7679 - val_auc: 0.7924\n",
            "Epoch 359/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5052 - accuracy: 0.7639 - sensitivity_at_specificity: 0.8900 - specificity_at_sensitivity: 0.8936 - recall: 0.4500 - precision: 0.7759 - auc: 0.8084\n",
            "Epoch 359: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4985 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9027 - specificity_at_sensitivity: 0.9082 - recall: 0.4779 - precision: 0.7714 - auc: 0.8176 - val_loss: 0.4861 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9000 - val_specificity_at_sensitivity: 0.9500 - val_recall: 0.5833 - val_precision: 0.7292 - val_auc: 0.8217\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4332 - accuracy: 0.8188 - sensitivity_at_specificity: 0.9600 - specificity_at_sensitivity: 0.9487 - recall: 0.7600 - precision: 0.7724 - auc: 0.8828\n",
            "Epoch 360: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4332 - accuracy: 0.8188 - sensitivity_at_specificity: 0.9600 - specificity_at_sensitivity: 0.9487 - recall: 0.7600 - precision: 0.7724 - auc: 0.8828 - val_loss: 0.4522 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.9286 - val_specificity_at_sensitivity: 0.9556 - val_recall: 0.7286 - val_precision: 0.7727 - val_auc: 0.8739\n",
            "Epoch 361/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4459 - accuracy: 0.7847 - sensitivity_at_specificity: 0.9533 - specificity_at_sensitivity: 0.9337 - recall: 0.6822 - precision: 0.7228 - auc: 0.8644\n",
            "Epoch 361: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4503 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9593 - specificity_at_sensitivity: 0.9391 - recall: 0.6748 - precision: 0.7345 - auc: 0.8646 - val_loss: 0.5688 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.8784 - val_specificity_at_sensitivity: 0.8953 - val_recall: 0.6081 - val_precision: 0.8036 - val_auc: 0.7958\n",
            "Epoch 362/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5129 - accuracy: 0.7569 - sensitivity_at_specificity: 0.8807 - specificity_at_sensitivity: 0.8994 - recall: 0.6239 - precision: 0.7010 - auc: 0.8126\n",
            "Epoch 362: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5249 - accuracy: 0.7563 - sensitivity_at_specificity: 0.8770 - specificity_at_sensitivity: 0.8990 - recall: 0.6148 - precision: 0.7075 - auc: 0.8057 - val_loss: 0.5100 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9178 - val_specificity_at_sensitivity: 0.9425 - val_recall: 0.4932 - val_precision: 0.8780 - val_auc: 0.8529\n",
            "Epoch 363/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4599 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9358 - specificity_at_sensitivity: 0.9162 - recall: 0.6789 - precision: 0.7115 - auc: 0.8550\n",
            "Epoch 363: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4548 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9431 - specificity_at_sensitivity: 0.9340 - recall: 0.6992 - precision: 0.7227 - auc: 0.8598 - val_loss: 0.4977 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.8750 - val_specificity_at_sensitivity: 0.9205 - val_recall: 0.6944 - val_precision: 0.7246 - val_auc: 0.8318\n",
            "Epoch 364/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4870 - accuracy: 0.7639 - sensitivity_at_specificity: 0.9107 - specificity_at_sensitivity: 0.8864 - recall: 0.6518 - precision: 0.7157 - auc: 0.8289\n",
            "Epoch 364: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4707 - accuracy: 0.7781 - sensitivity_at_specificity: 0.9180 - specificity_at_sensitivity: 0.8990 - recall: 0.6721 - precision: 0.7257 - auc: 0.8423 - val_loss: 0.4636 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.9412 - val_specificity_at_sensitivity: 0.9457 - val_recall: 0.6176 - val_precision: 0.8400 - val_auc: 0.8772\n",
            "Epoch 365/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5009 - accuracy: 0.7569 - sensitivity_at_specificity: 0.9307 - specificity_at_sensitivity: 0.8770 - recall: 0.6139 - precision: 0.6667 - auc: 0.8178\n",
            "Epoch 365: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5087 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9035 - specificity_at_sensitivity: 0.8835 - recall: 0.5877 - precision: 0.6768 - auc: 0.8109 - val_loss: 0.5210 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.9200 - val_specificity_at_sensitivity: 0.9412 - val_recall: 0.5467 - val_precision: 0.8723 - val_auc: 0.8506\n",
            "Epoch 366/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4568 - accuracy: 0.7882 - sensitivity_at_specificity: 0.9500 - specificity_at_sensitivity: 0.9309 - recall: 0.6700 - precision: 0.7053 - auc: 0.8522\n",
            "Epoch 366: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4631 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9464 - specificity_at_sensitivity: 0.9231 - recall: 0.6518 - precision: 0.7157 - auc: 0.8475 - val_loss: 0.5036 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.8519 - val_specificity_at_sensitivity: 0.8868 - val_recall: 0.4630 - val_precision: 0.7353 - val_auc: 0.7925\n",
            "Epoch 367/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5296 - accuracy: 0.7396 - sensitivity_at_specificity: 0.8500 - specificity_at_sensitivity: 0.8777 - recall: 0.3700 - precision: 0.7551 - auc: 0.7826\n",
            "Epoch 367: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5219 - accuracy: 0.7437 - sensitivity_at_specificity: 0.8455 - specificity_at_sensitivity: 0.8857 - recall: 0.3636 - precision: 0.7692 - auc: 0.7905 - val_loss: 0.4623 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9206 - val_specificity_at_sensitivity: 0.9485 - val_recall: 0.6349 - val_precision: 0.7407 - val_auc: 0.8602\n",
            "Epoch 368/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4725 - accuracy: 0.7674 - sensitivity_at_specificity: 0.9298 - specificity_at_sensitivity: 0.9483 - recall: 0.7281 - precision: 0.6975 - auc: 0.8527\n",
            "Epoch 368: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4696 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9180 - specificity_at_sensitivity: 0.9444 - recall: 0.7213 - precision: 0.6929 - auc: 0.8524 - val_loss: 0.4519 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9672 - val_specificity_at_sensitivity: 0.9394 - val_recall: 0.6557 - val_precision: 0.6897 - val_auc: 0.8644\n",
            "Epoch 369/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5191 - accuracy: 0.7535 - sensitivity_at_specificity: 0.8416 - specificity_at_sensitivity: 0.9037 - recall: 0.4554 - precision: 0.7419 - auc: 0.7928\n",
            "Epoch 369: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5246 - accuracy: 0.7406 - sensitivity_at_specificity: 0.8534 - specificity_at_sensitivity: 0.8971 - recall: 0.4310 - precision: 0.7463 - auc: 0.7983 - val_loss: 0.5549 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.9268 - val_specificity_at_sensitivity: 0.9103 - val_recall: 0.5122 - val_precision: 0.8571 - val_auc: 0.8396\n",
            "Epoch 370/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4609 - accuracy: 0.7674 - sensitivity_at_specificity: 0.9590 - specificity_at_sensitivity: 0.9277 - recall: 0.7213 - precision: 0.7273 - auc: 0.8657\n",
            "Epoch 370: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4640 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9621 - specificity_at_sensitivity: 0.9149 - recall: 0.7045 - precision: 0.7099 - auc: 0.8611 - val_loss: 0.5458 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.9219 - val_specificity_at_sensitivity: 0.9167 - val_recall: 0.7500 - val_precision: 0.6234 - val_auc: 0.8182\n",
            "Epoch 371/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4859 - accuracy: 0.7639 - sensitivity_at_specificity: 0.9222 - specificity_at_sensitivity: 0.9091 - recall: 0.5667 - precision: 0.6375 - auc: 0.8153\n",
            "Epoch 371: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4945 - accuracy: 0.7563 - sensitivity_at_specificity: 0.9020 - specificity_at_sensitivity: 0.9037 - recall: 0.5588 - precision: 0.6333 - auc: 0.8066 - val_loss: 0.5396 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.9275 - val_specificity_at_sensitivity: 0.9121 - val_recall: 0.4203 - val_precision: 0.8286 - val_auc: 0.8636\n",
            "Epoch 372/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5158 - accuracy: 0.7500 - sensitivity_at_specificity: 0.9018 - specificity_at_sensitivity: 0.9034 - recall: 0.5089 - precision: 0.7703 - auc: 0.8158\n",
            "Epoch 372: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5133 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9113 - specificity_at_sensitivity: 0.8929 - recall: 0.5403 - precision: 0.7528 - auc: 0.8148 - val_loss: 0.4824 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.9524 - val_specificity_at_sensitivity: 0.9175 - val_recall: 0.7778 - val_precision: 0.6447 - val_auc: 0.8578\n",
            "Epoch 373/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4527 - accuracy: 0.8299 - sensitivity_at_specificity: 0.9256 - specificity_at_sensitivity: 0.9461 - recall: 0.7769 - precision: 0.8103 - auc: 0.8740\n",
            "Epoch 373: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4528 - accuracy: 0.8188 - sensitivity_at_specificity: 0.9297 - specificity_at_sensitivity: 0.9427 - recall: 0.7656 - precision: 0.7778 - auc: 0.8724 - val_loss: 0.4911 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.9091 - val_specificity_at_sensitivity: 0.9362 - val_recall: 0.6364 - val_precision: 0.7778 - val_auc: 0.8367\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.7344 - sensitivity_at_specificity: 0.9242 - specificity_at_sensitivity: 0.8830 - recall: 0.5909 - precision: 0.7156 - auc: 0.8347\n",
            "Epoch 374: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5058 - accuracy: 0.7344 - sensitivity_at_specificity: 0.9242 - specificity_at_sensitivity: 0.8830 - recall: 0.5909 - precision: 0.7156 - auc: 0.8347 - val_loss: 0.4886 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.9861 - val_specificity_at_sensitivity: 0.9318 - val_recall: 0.6250 - val_precision: 0.7143 - val_auc: 0.8439\n",
            "Epoch 375/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4806 - accuracy: 0.7431 - sensitivity_at_specificity: 0.9469 - specificity_at_sensitivity: 0.9200 - recall: 0.6018 - precision: 0.7010 - auc: 0.8429\n",
            "Epoch 375: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4719 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9520 - specificity_at_sensitivity: 0.9179 - recall: 0.6320 - precision: 0.7182 - auc: 0.8508 - val_loss: 0.5172 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9231 - val_specificity_at_sensitivity: 0.8902 - val_recall: 0.6282 - val_precision: 0.7903 - val_auc: 0.8327\n",
            "Epoch 376/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4041 - accuracy: 0.8393 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9345 - recall: 0.7768 - precision: 0.8131 - auc: 0.9052\n",
            "Epoch 376: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.3975 - accuracy: 0.8333 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9351 - recall: 0.7638 - precision: 0.8151 - auc: 0.9094 - val_loss: 0.4883 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.8710 - val_specificity_at_sensitivity: 0.9388 - val_recall: 0.6613 - val_precision: 0.6949 - val_auc: 0.8265\n",
            "Epoch 377/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4397 - accuracy: 0.7917 - sensitivity_at_specificity: 0.9596 - specificity_at_sensitivity: 0.9153 - recall: 0.6465 - precision: 0.7191 - auc: 0.8637\n",
            "Epoch 377: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4363 - accuracy: 0.7906 - sensitivity_at_specificity: 0.9640 - specificity_at_sensitivity: 0.8995 - recall: 0.6306 - precision: 0.7292 - auc: 0.8669 - val_loss: 0.4962 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.9467 - val_specificity_at_sensitivity: 0.9412 - val_recall: 0.5867 - val_precision: 0.8148 - val_auc: 0.8611\n",
            "Epoch 378/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4837 - accuracy: 0.7639 - sensitivity_at_specificity: 0.9510 - specificity_at_sensitivity: 0.9140 - recall: 0.6471 - precision: 0.6735 - auc: 0.8315\n",
            "Epoch 378: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4961 - accuracy: 0.7563 - sensitivity_at_specificity: 0.9397 - specificity_at_sensitivity: 0.9167 - recall: 0.6207 - precision: 0.6792 - auc: 0.8249 - val_loss: 0.5455 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9211 - val_specificity_at_sensitivity: 0.9167 - val_recall: 0.5263 - val_precision: 0.8511 - val_auc: 0.8411\n",
            "Epoch 379/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5446 - accuracy: 0.7292 - sensitivity_at_specificity: 0.8835 - specificity_at_sensitivity: 0.8757 - recall: 0.6117 - precision: 0.6238 - auc: 0.7857\n",
            "Epoch 379: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5583 - accuracy: 0.7250 - sensitivity_at_specificity: 0.8879 - specificity_at_sensitivity: 0.8676 - recall: 0.6121 - precision: 0.6228 - auc: 0.7746 - val_loss: 0.4885 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9306 - val_specificity_at_sensitivity: 0.9659 - val_recall: 0.6389 - val_precision: 0.7931 - val_auc: 0.8481\n",
            "Epoch 380/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4795 - accuracy: 0.7674 - sensitivity_at_specificity: 0.9038 - specificity_at_sensitivity: 0.9293 - recall: 0.6154 - precision: 0.7033 - auc: 0.8326\n",
            "Epoch 380: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4776 - accuracy: 0.7688 - sensitivity_at_specificity: 0.9138 - specificity_at_sensitivity: 0.9314 - recall: 0.6034 - precision: 0.7143 - auc: 0.8342 - val_loss: 0.5128 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9531 - val_specificity_at_sensitivity: 0.8646 - val_recall: 0.5469 - val_precision: 0.7292 - val_auc: 0.8219\n",
            "Epoch 381/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4964 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9151 - specificity_at_sensitivity: 0.9011 - recall: 0.5566 - precision: 0.7662 - auc: 0.8237\n",
            "Epoch 381: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4834 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9237 - specificity_at_sensitivity: 0.9109 - recall: 0.5763 - precision: 0.7727 - auc: 0.8353 - val_loss: 0.5258 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.9143 - val_specificity_at_sensitivity: 0.9111 - val_recall: 0.7000 - val_precision: 0.7101 - val_auc: 0.8108\n",
            "Epoch 382/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4681 - accuracy: 0.8090 - sensitivity_at_specificity: 0.9636 - specificity_at_sensitivity: 0.9382 - recall: 0.7000 - precision: 0.7778 - auc: 0.8573\n",
            "Epoch 382: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4754 - accuracy: 0.7969 - sensitivity_at_specificity: 0.9683 - specificity_at_sensitivity: 0.9227 - recall: 0.7063 - precision: 0.7607 - auc: 0.8545 - val_loss: 0.4843 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9016 - val_specificity_at_sensitivity: 0.9091 - val_recall: 0.6721 - val_precision: 0.7321 - val_auc: 0.8364\n",
            "Epoch 383/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4535 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9495 - specificity_at_sensitivity: 0.8889 - recall: 0.6162 - precision: 0.6932 - auc: 0.8514\n",
            "Epoch 383: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4551 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9561 - specificity_at_sensitivity: 0.8981 - recall: 0.6140 - precision: 0.7071 - auc: 0.8526 - val_loss: 0.4776 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.8966 - val_specificity_at_sensitivity: 0.9314 - val_recall: 0.6034 - val_precision: 0.7292 - val_auc: 0.8362\n",
            "Epoch 384/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4437 - accuracy: 0.8125 - sensitivity_at_specificity: 0.9524 - specificity_at_sensitivity: 0.9508 - recall: 0.6571 - precision: 0.7931 - auc: 0.8649\n",
            "Epoch 384: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4467 - accuracy: 0.8062 - sensitivity_at_specificity: 0.9459 - specificity_at_sensitivity: 0.9378 - recall: 0.6486 - precision: 0.7579 - auc: 0.8566 - val_loss: 0.4296 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.9355 - val_specificity_at_sensitivity: 0.9286 - val_recall: 0.7903 - val_precision: 0.7000 - val_auc: 0.8855\n",
            "Epoch 385/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4986 - accuracy: 0.7604 - sensitivity_at_specificity: 0.9048 - specificity_at_sensitivity: 0.9071 - recall: 0.5048 - precision: 0.7571 - auc: 0.8208\n",
            "Epoch 385: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4991 - accuracy: 0.7563 - sensitivity_at_specificity: 0.9138 - specificity_at_sensitivity: 0.9020 - recall: 0.5000 - precision: 0.7436 - auc: 0.8211 - val_loss: 0.5323 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.8906 - val_specificity_at_sensitivity: 0.8438 - val_recall: 0.7188 - val_precision: 0.6479 - val_auc: 0.7977\n",
            "Epoch 386/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5233 - accuracy: 0.7604 - sensitivity_at_specificity: 0.8793 - specificity_at_sensitivity: 0.9012 - recall: 0.7586 - precision: 0.6822 - auc: 0.8144\n",
            "Epoch 386: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5192 - accuracy: 0.7625 - sensitivity_at_specificity: 0.8828 - specificity_at_sensitivity: 0.9010 - recall: 0.7578 - precision: 0.6831 - auc: 0.8176 - val_loss: 0.4111 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 0.9385 - val_specificity_at_sensitivity: 0.9789 - val_recall: 0.7385 - val_precision: 0.7500 - val_auc: 0.8974\n",
            "Epoch 387/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4716 - accuracy: 0.7986 - sensitivity_at_specificity: 0.8947 - specificity_at_sensitivity: 0.9655 - recall: 0.6491 - precision: 0.8043 - auc: 0.8443\n",
            "Epoch 387: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4525 - accuracy: 0.8094 - sensitivity_at_specificity: 0.9113 - specificity_at_sensitivity: 0.9694 - recall: 0.6532 - precision: 0.8182 - auc: 0.8572 - val_loss: 0.5015 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.9041 - val_specificity_at_sensitivity: 0.9310 - val_recall: 0.6164 - val_precision: 0.7895 - val_auc: 0.8398\n",
            "Epoch 388/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4770 - accuracy: 0.7639 - sensitivity_at_specificity: 0.9358 - specificity_at_sensitivity: 0.8883 - recall: 0.6147 - precision: 0.7204 - auc: 0.8465\n",
            "Epoch 388: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4716 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9435 - specificity_at_sensitivity: 0.9031 - recall: 0.6452 - precision: 0.7339 - auc: 0.8537 - val_loss: 0.4845 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9200 - val_specificity_at_sensitivity: 0.9412 - val_recall: 0.6533 - val_precision: 0.8448 - val_auc: 0.8654\n",
            "Epoch 389/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4681 - accuracy: 0.7882 - sensitivity_at_specificity: 0.9068 - specificity_at_sensitivity: 0.9235 - recall: 0.7034 - precision: 0.7615 - auc: 0.8525\n",
            "Epoch 389: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4655 - accuracy: 0.7906 - sensitivity_at_specificity: 0.9055 - specificity_at_sensitivity: 0.9275 - recall: 0.6850 - precision: 0.7632 - auc: 0.8518 - val_loss: 0.5714 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8548 - val_specificity_at_sensitivity: 0.8673 - val_recall: 0.5323 - val_precision: 0.6600 - val_auc: 0.7605\n",
            "Epoch 390/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4906 - accuracy: 0.7604 - sensitivity_at_specificity: 0.9000 - specificity_at_sensitivity: 0.9157 - recall: 0.6000 - precision: 0.7253 - auc: 0.8297\n",
            "Epoch 390: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4814 - accuracy: 0.7688 - sensitivity_at_specificity: 0.9127 - specificity_at_sensitivity: 0.9278 - recall: 0.6429 - precision: 0.7364 - auc: 0.8406 - val_loss: 0.4401 - val_accuracy: 0.8062 - val_sensitivity_at_specificity: 0.9733 - val_specificity_at_sensitivity: 0.9412 - val_recall: 0.7333 - val_precision: 0.8333 - val_auc: 0.8861\n",
            "Epoch 391/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4768 - accuracy: 0.7396 - sensitivity_at_specificity: 0.9612 - specificity_at_sensitivity: 0.8865 - recall: 0.5340 - precision: 0.6707 - auc: 0.8343\n",
            "Epoch 391: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4652 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9459 - specificity_at_sensitivity: 0.8947 - recall: 0.5405 - precision: 0.6818 - auc: 0.8414 - val_loss: 0.4895 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.8906 - val_specificity_at_sensitivity: 0.9271 - val_recall: 0.6094 - val_precision: 0.8125 - val_auc: 0.8398\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4852 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9123 - specificity_at_sensitivity: 0.9078 - recall: 0.6491 - precision: 0.7184 - auc: 0.8256\n",
            "Epoch 392: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4852 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9123 - specificity_at_sensitivity: 0.9078 - recall: 0.6491 - precision: 0.7184 - auc: 0.8256 - val_loss: 0.4830 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9296 - val_specificity_at_sensitivity: 0.8989 - val_recall: 0.7183 - val_precision: 0.7500 - val_auc: 0.8474\n",
            "Epoch 393/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5028 - accuracy: 0.7431 - sensitivity_at_specificity: 0.9135 - specificity_at_sensitivity: 0.8967 - recall: 0.5962 - precision: 0.6596 - auc: 0.8124\n",
            "Epoch 393: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5003 - accuracy: 0.7437 - sensitivity_at_specificity: 0.9153 - specificity_at_sensitivity: 0.8960 - recall: 0.6017 - precision: 0.6698 - auc: 0.8174 - val_loss: 0.4569 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9630 - val_specificity_at_sensitivity: 0.8868 - val_recall: 0.5556 - val_precision: 0.6977 - val_auc: 0.8487\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4768 - accuracy: 0.7812 - sensitivity_at_specificity: 0.8984 - specificity_at_sensitivity: 0.9115 - recall: 0.6484 - precision: 0.7685 - auc: 0.8444\n",
            "Epoch 394: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4768 - accuracy: 0.7812 - sensitivity_at_specificity: 0.8984 - specificity_at_sensitivity: 0.9115 - recall: 0.6484 - precision: 0.7685 - auc: 0.8444 - val_loss: 0.4775 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.9206 - val_specificity_at_sensitivity: 0.9381 - val_recall: 0.6984 - val_precision: 0.7458 - val_auc: 0.8475\n",
            "Epoch 395/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4739 - accuracy: 0.7917 - sensitivity_at_specificity: 0.9298 - specificity_at_sensitivity: 0.9080 - recall: 0.7018 - precision: 0.7547 - auc: 0.8481\n",
            "Epoch 395: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4679 - accuracy: 0.7969 - sensitivity_at_specificity: 0.9297 - specificity_at_sensitivity: 0.9115 - recall: 0.7109 - precision: 0.7647 - auc: 0.8533 - val_loss: 0.5255 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9333 - val_specificity_at_sensitivity: 0.9176 - val_recall: 0.6667 - val_precision: 0.7937 - val_auc: 0.8238\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4295 - accuracy: 0.8013 - sensitivity_at_specificity: 0.9580 - specificity_at_sensitivity: 0.9378 - recall: 0.6975 - precision: 0.7615 - auc: 0.8746\n",
            "Epoch 396: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4295 - accuracy: 0.8013 - sensitivity_at_specificity: 0.9580 - specificity_at_sensitivity: 0.9378 - recall: 0.6975 - precision: 0.7615 - auc: 0.8746 - val_loss: 0.5010 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9143 - val_specificity_at_sensitivity: 0.8889 - val_recall: 0.6286 - val_precision: 0.7719 - val_auc: 0.8350\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4789 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9060 - specificity_at_sensitivity: 0.9163 - recall: 0.5385 - precision: 0.7683 - auc: 0.8361\n",
            "Epoch 397: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4789 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9060 - specificity_at_sensitivity: 0.9163 - recall: 0.5385 - precision: 0.7683 - auc: 0.8361 - val_loss: 0.4536 - val_accuracy: 0.8250 - val_sensitivity_at_specificity: 0.9219 - val_specificity_at_sensitivity: 0.9375 - val_recall: 0.7656 - val_precision: 0.7903 - val_auc: 0.8638\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4467 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9504 - specificity_at_sensitivity: 0.9296 - recall: 0.7025 - precision: 0.7522 - auc: 0.8628\n",
            "Epoch 398: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4467 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9504 - specificity_at_sensitivity: 0.9296 - recall: 0.7025 - precision: 0.7522 - auc: 0.8628 - val_loss: 0.4950 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9359 - val_specificity_at_sensitivity: 0.9146 - val_recall: 0.6923 - val_precision: 0.7500 - val_auc: 0.8398\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4663 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9435 - specificity_at_sensitivity: 0.8929 - recall: 0.6532 - precision: 0.7570 - auc: 0.8511\n",
            "Epoch 399: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4663 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9435 - specificity_at_sensitivity: 0.8929 - recall: 0.6532 - precision: 0.7570 - auc: 0.8511 - val_loss: 0.5213 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.8551 - val_specificity_at_sensitivity: 0.9451 - val_recall: 0.6522 - val_precision: 0.6923 - val_auc: 0.8139\n",
            "Epoch 400/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4785 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9386 - specificity_at_sensitivity: 0.9425 - recall: 0.7105 - precision: 0.7168 - auc: 0.8442\n",
            "Epoch 400: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4771 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9350 - specificity_at_sensitivity: 0.9391 - recall: 0.7154 - precision: 0.6984 - auc: 0.8433 - val_loss: 0.4635 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.9219 - val_specificity_at_sensitivity: 0.9271 - val_recall: 0.7344 - val_precision: 0.6714 - val_auc: 0.8565\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4808 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9449 - specificity_at_sensitivity: 0.9119 - recall: 0.5669 - precision: 0.7826 - auc: 0.8541\n",
            "Epoch 401: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4808 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9449 - specificity_at_sensitivity: 0.9119 - recall: 0.5669 - precision: 0.7826 - auc: 0.8541 - val_loss: 0.4971 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.9138 - val_specificity_at_sensitivity: 0.9216 - val_recall: 0.6034 - val_precision: 0.6731 - val_auc: 0.8217\n",
            "Epoch 402/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4829 - accuracy: 0.7361 - sensitivity_at_specificity: 0.9369 - specificity_at_sensitivity: 0.9322 - recall: 0.7658 - precision: 0.6296 - auc: 0.8451\n",
            "Epoch 402: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4784 - accuracy: 0.7312 - sensitivity_at_specificity: 0.9431 - specificity_at_sensitivity: 0.9492 - recall: 0.7724 - precision: 0.6209 - auc: 0.8501 - val_loss: 0.5129 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.8889 - val_specificity_at_sensitivity: 0.9091 - val_recall: 0.6528 - val_precision: 0.7581 - val_auc: 0.8258\n",
            "Epoch 403/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4856 - accuracy: 0.7569 - sensitivity_at_specificity: 0.9314 - specificity_at_sensitivity: 0.9140 - recall: 0.4706 - precision: 0.7500 - auc: 0.8383\n",
            "Epoch 403: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4840 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9145 - specificity_at_sensitivity: 0.9163 - recall: 0.4957 - precision: 0.7733 - auc: 0.8436 - val_loss: 0.5095 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.9412 - val_specificity_at_sensitivity: 0.8478 - val_recall: 0.6324 - val_precision: 0.7288 - val_auc: 0.8191\n",
            "Epoch 404/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4916 - accuracy: 0.7535 - sensitivity_at_specificity: 0.9244 - specificity_at_sensitivity: 0.9172 - recall: 0.6891 - precision: 0.7069 - auc: 0.8359\n",
            "Epoch 404: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4845 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9308 - specificity_at_sensitivity: 0.9263 - recall: 0.7000 - precision: 0.7054 - auc: 0.8406 - val_loss: 0.4780 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.9487 - val_specificity_at_sensitivity: 0.8902 - val_recall: 0.8333 - val_precision: 0.7386 - val_auc: 0.8500\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9160 - specificity_at_sensitivity: 0.9365 - recall: 0.6565 - precision: 0.7890 - auc: 0.8633\n",
            "Epoch 405: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4659 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9160 - specificity_at_sensitivity: 0.9365 - recall: 0.6565 - precision: 0.7890 - auc: 0.8633 - val_loss: 0.4975 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9531 - val_specificity_at_sensitivity: 0.8854 - val_recall: 0.6875 - val_precision: 0.6567 - val_auc: 0.8261\n",
            "Epoch 406/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4887 - accuracy: 0.7639 - sensitivity_at_specificity: 0.9426 - specificity_at_sensitivity: 0.8614 - recall: 0.7623 - precision: 0.7045 - auc: 0.8411\n",
            "Epoch 406: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4760 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9493 - specificity_at_sensitivity: 0.8736 - recall: 0.7754 - precision: 0.7181 - auc: 0.8523 - val_loss: 0.4598 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9367 - val_specificity_at_sensitivity: 0.9506 - val_recall: 0.7722 - val_precision: 0.7821 - val_auc: 0.8683\n",
            "Epoch 407/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4227 - accuracy: 0.8056 - sensitivity_at_specificity: 0.9630 - specificity_at_sensitivity: 0.9444 - recall: 0.6852 - precision: 0.7708 - auc: 0.8900\n",
            "Epoch 407: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4377 - accuracy: 0.7937 - sensitivity_at_specificity: 0.9680 - specificity_at_sensitivity: 0.9385 - recall: 0.6640 - precision: 0.7757 - auc: 0.8793 - val_loss: 0.5113 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.9600 - val_specificity_at_sensitivity: 0.9176 - val_recall: 0.5600 - val_precision: 0.8400 - val_auc: 0.8483\n",
            "Epoch 408/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4322 - accuracy: 0.7882 - sensitivity_at_specificity: 0.9528 - specificity_at_sensitivity: 0.9286 - recall: 0.6792 - precision: 0.7273 - auc: 0.8754\n",
            "Epoch 408: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4246 - accuracy: 0.7937 - sensitivity_at_specificity: 0.9573 - specificity_at_sensitivity: 0.9310 - recall: 0.6838 - precision: 0.7339 - auc: 0.8807 - val_loss: 0.6039 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.9277 - val_specificity_at_sensitivity: 0.8831 - val_recall: 0.5181 - val_precision: 0.8269 - val_auc: 0.8161\n",
            "Epoch 409/500\n",
            " 6/10 [=================>............] - ETA: 0s - loss: 0.5082 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9241 - specificity_at_sensitivity: 0.9204 - recall: 0.6076 - precision: 0.7742 - auc: 0.8414\n",
            "Epoch 409: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4530 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9444 - specificity_at_sensitivity: 0.9381 - recall: 0.6984 - precision: 0.7719 - auc: 0.8694 - val_loss: 0.4925 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9359 - val_specificity_at_sensitivity: 0.9268 - val_recall: 0.7308 - val_precision: 0.8028 - val_auc: 0.8535\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4480 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9360 - specificity_at_sensitivity: 0.9641 - recall: 0.6800 - precision: 0.7522 - auc: 0.8615\n",
            "Epoch 410: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4480 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9360 - specificity_at_sensitivity: 0.9641 - recall: 0.6800 - precision: 0.7522 - auc: 0.8615 - val_loss: 0.5326 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.8592 - val_specificity_at_sensitivity: 0.9438 - val_recall: 0.5915 - val_precision: 0.8571 - val_auc: 0.8163\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5056 - accuracy: 0.7312 - sensitivity_at_specificity: 0.9250 - specificity_at_sensitivity: 0.8900 - recall: 0.5417 - precision: 0.6771 - auc: 0.8203\n",
            "Epoch 411: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5056 - accuracy: 0.7312 - sensitivity_at_specificity: 0.9250 - specificity_at_sensitivity: 0.8900 - recall: 0.5417 - precision: 0.6771 - auc: 0.8203 - val_loss: 0.5543 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8784 - val_specificity_at_sensitivity: 0.9070 - val_recall: 0.5946 - val_precision: 0.7857 - val_auc: 0.8066\n",
            "Epoch 412/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4449 - accuracy: 0.7847 - sensitivity_at_specificity: 0.9717 - specificity_at_sensitivity: 0.9286 - recall: 0.7075 - precision: 0.7075 - auc: 0.8660\n",
            "Epoch 412: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4394 - accuracy: 0.7906 - sensitivity_at_specificity: 0.9750 - specificity_at_sensitivity: 0.9350 - recall: 0.7250 - precision: 0.7190 - auc: 0.8717 - val_loss: 0.5298 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.9589 - val_specificity_at_sensitivity: 0.9195 - val_recall: 0.5342 - val_precision: 0.7959 - val_auc: 0.8419\n",
            "Epoch 413/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4367 - accuracy: 0.7951 - sensitivity_at_specificity: 0.9697 - specificity_at_sensitivity: 0.9153 - recall: 0.5859 - precision: 0.7632 - auc: 0.8694\n",
            "Epoch 413: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4498 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9649 - specificity_at_sensitivity: 0.9175 - recall: 0.5702 - precision: 0.7738 - auc: 0.8637 - val_loss: 0.4969 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9206 - val_specificity_at_sensitivity: 0.9175 - val_recall: 0.5238 - val_precision: 0.8049 - val_auc: 0.8245\n",
            "Epoch 414/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4649 - accuracy: 0.7847 - sensitivity_at_specificity: 0.8981 - specificity_at_sensitivity: 0.9389 - recall: 0.6667 - precision: 0.7347 - auc: 0.8448\n",
            "Epoch 414: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4580 - accuracy: 0.7875 - sensitivity_at_specificity: 0.8947 - specificity_at_sensitivity: 0.9417 - recall: 0.6579 - precision: 0.7212 - auc: 0.8451 - val_loss: 0.4512 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.9375 - val_specificity_at_sensitivity: 0.9271 - val_recall: 0.8125 - val_precision: 0.7027 - val_auc: 0.8750\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4701 - accuracy: 0.7937 - sensitivity_at_specificity: 0.9196 - specificity_at_sensitivity: 0.9087 - recall: 0.6071 - precision: 0.7556 - auc: 0.8383\n",
            "Epoch 415: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4701 - accuracy: 0.7937 - sensitivity_at_specificity: 0.9196 - specificity_at_sensitivity: 0.9087 - recall: 0.6071 - precision: 0.7556 - auc: 0.8383 - val_loss: 0.4623 - val_accuracy: 0.8125 - val_sensitivity_at_specificity: 0.9254 - val_specificity_at_sensitivity: 0.9785 - val_recall: 0.6567 - val_precision: 0.8627 - val_auc: 0.8658\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4621 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9123 - specificity_at_sensitivity: 0.9272 - recall: 0.5877 - precision: 0.7528 - auc: 0.8407\n",
            "Epoch 416: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4621 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9123 - specificity_at_sensitivity: 0.9272 - recall: 0.5877 - precision: 0.7528 - auc: 0.8407 - val_loss: 0.5372 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.9000 - val_specificity_at_sensitivity: 0.8556 - val_recall: 0.5857 - val_precision: 0.7069 - val_auc: 0.7964\n",
            "Epoch 417/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5185 - accuracy: 0.7569 - sensitivity_at_specificity: 0.9254 - specificity_at_sensitivity: 0.8636 - recall: 0.7164 - precision: 0.7500 - auc: 0.8306\n",
            "Epoch 417: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5075 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9310 - specificity_at_sensitivity: 0.8743 - recall: 0.7241 - precision: 0.7500 - auc: 0.8366 - val_loss: 0.4389 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9853 - val_specificity_at_sensitivity: 0.9565 - val_recall: 0.8088 - val_precision: 0.7143 - val_auc: 0.8842\n",
            "Epoch 418/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4743 - accuracy: 0.7743 - sensitivity_at_specificity: 0.8958 - specificity_at_sensitivity: 0.9167 - recall: 0.5625 - precision: 0.7013 - auc: 0.8196\n",
            "Epoch 418: val_accuracy did not improve from 0.82500\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4760 - accuracy: 0.7781 - sensitivity_at_specificity: 0.8952 - specificity_at_sensitivity: 0.9163 - recall: 0.5619 - precision: 0.7024 - auc: 0.8198 - val_loss: 0.5192 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9867 - val_specificity_at_sensitivity: 0.9412 - val_recall: 0.4800 - val_precision: 0.9000 - val_auc: 0.8642\n",
            "Epoch 419/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5012 - accuracy: 0.7535 - sensitivity_at_specificity: 0.9381 - specificity_at_sensitivity: 0.8914 - recall: 0.5752 - precision: 0.7386 - auc: 0.8317\n",
            "Epoch 419: val_accuracy improved from 0.82500 to 0.85625, saving model to ECG_Model_Lead_1.h5\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5065 - accuracy: 0.7563 - sensitivity_at_specificity: 0.9417 - specificity_at_sensitivity: 0.8850 - recall: 0.6000 - precision: 0.7059 - auc: 0.8234 - val_loss: 0.3926 - val_accuracy: 0.8562 - val_sensitivity_at_specificity: 0.9444 - val_specificity_at_sensitivity: 0.9886 - val_recall: 0.7917 - val_precision: 0.8769 - val_auc: 0.9163\n",
            "Epoch 420/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4608 - accuracy: 0.7639 - sensitivity_at_specificity: 0.9519 - specificity_at_sensitivity: 0.9130 - recall: 0.5192 - precision: 0.7500 - auc: 0.8474\n",
            "Epoch 420: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4464 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9643 - specificity_at_sensitivity: 0.9183 - recall: 0.5268 - precision: 0.7564 - auc: 0.8601 - val_loss: 0.5529 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.9250 - val_specificity_at_sensitivity: 0.8375 - val_recall: 0.5625 - val_precision: 0.7759 - val_auc: 0.8205\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4578 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9487 - specificity_at_sensitivity: 0.9261 - recall: 0.6154 - precision: 0.7500 - auc: 0.8568\n",
            "Epoch 421: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4578 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9487 - specificity_at_sensitivity: 0.9261 - recall: 0.6154 - precision: 0.7500 - auc: 0.8568 - val_loss: 0.4705 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9545 - val_specificity_at_sensitivity: 0.9362 - val_recall: 0.7576 - val_precision: 0.6944 - val_auc: 0.8540\n",
            "Epoch 422/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4925 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9143 - specificity_at_sensitivity: 0.9016 - recall: 0.6381 - precision: 0.7283 - auc: 0.8228\n",
            "Epoch 422: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4822 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9217 - specificity_at_sensitivity: 0.9073 - recall: 0.6435 - precision: 0.7184 - auc: 0.8293 - val_loss: 0.5123 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8784 - val_specificity_at_sensitivity: 0.9302 - val_recall: 0.5946 - val_precision: 0.7857 - val_auc: 0.8239\n",
            "Epoch 423/500\n",
            " 6/10 [=================>............] - ETA: 0s - loss: 0.5354 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8784 - specificity_at_sensitivity: 0.8559 - recall: 0.4865 - precision: 0.6923 - auc: 0.7935\n",
            "Epoch 423: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5024 - accuracy: 0.7406 - sensitivity_at_specificity: 0.9043 - specificity_at_sensitivity: 0.8927 - recall: 0.5739 - precision: 0.6600 - auc: 0.8076 - val_loss: 0.5162 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.9365 - val_specificity_at_sensitivity: 0.8763 - val_recall: 0.5397 - val_precision: 0.6667 - val_auc: 0.8120\n",
            "Epoch 424/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4497 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9474 - specificity_at_sensitivity: 0.9080 - recall: 0.6579 - precision: 0.7576 - auc: 0.8688\n",
            "Epoch 424: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4516 - accuracy: 0.7781 - sensitivity_at_specificity: 0.9508 - specificity_at_sensitivity: 0.8990 - recall: 0.6639 - precision: 0.7297 - auc: 0.8616 - val_loss: 0.5013 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9500 - val_specificity_at_sensitivity: 0.9125 - val_recall: 0.6875 - val_precision: 0.7971 - val_auc: 0.8487\n",
            "Epoch 425/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4826 - accuracy: 0.7604 - sensitivity_at_specificity: 0.9667 - specificity_at_sensitivity: 0.8929 - recall: 0.6917 - precision: 0.7217 - auc: 0.8458\n",
            "Epoch 425: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4871 - accuracy: 0.7563 - sensitivity_at_specificity: 0.9695 - specificity_at_sensitivity: 0.8783 - recall: 0.6947 - precision: 0.7054 - auc: 0.8402 - val_loss: 0.4970 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9265 - val_specificity_at_sensitivity: 0.9130 - val_recall: 0.7206 - val_precision: 0.6806 - val_auc: 0.8322\n",
            "Epoch 426/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4363 - accuracy: 0.7778 - sensitivity_at_specificity: 0.9533 - specificity_at_sensitivity: 0.9503 - recall: 0.5981 - precision: 0.7529 - auc: 0.8724\n",
            "Epoch 426: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4382 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9500 - specificity_at_sensitivity: 0.9450 - recall: 0.6250 - precision: 0.7500 - auc: 0.8698 - val_loss: 0.5347 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9000 - val_specificity_at_sensitivity: 0.9111 - val_recall: 0.5571 - val_precision: 0.7800 - val_auc: 0.8089\n",
            "Epoch 427/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4719 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9474 - specificity_at_sensitivity: 0.8851 - recall: 0.6754 - precision: 0.7333 - auc: 0.8487\n",
            "Epoch 427: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4602 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9612 - specificity_at_sensitivity: 0.9005 - recall: 0.6899 - precision: 0.7479 - auc: 0.8585 - val_loss: 0.5553 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.9032 - val_specificity_at_sensitivity: 0.8571 - val_recall: 0.5806 - val_precision: 0.6429 - val_auc: 0.7758\n",
            "Epoch 428/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4405 - accuracy: 0.7847 - sensitivity_at_specificity: 0.9600 - specificity_at_sensitivity: 0.9149 - recall: 0.6600 - precision: 0.7021 - auc: 0.8632\n",
            "Epoch 428: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4490 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9455 - specificity_at_sensitivity: 0.9143 - recall: 0.6455 - precision: 0.6961 - auc: 0.8537 - val_loss: 0.4868 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9559 - val_specificity_at_sensitivity: 0.9457 - val_recall: 0.5588 - val_precision: 0.8837 - val_auc: 0.8655\n",
            "Epoch 429/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4701 - accuracy: 0.7639 - sensitivity_at_specificity: 0.9434 - specificity_at_sensitivity: 0.9231 - recall: 0.6038 - precision: 0.7111 - auc: 0.8400\n",
            "Epoch 429: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4781 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9224 - specificity_at_sensitivity: 0.9314 - recall: 0.6034 - precision: 0.7216 - auc: 0.8321 - val_loss: 0.5006 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9464 - val_specificity_at_sensitivity: 0.8750 - val_recall: 0.6607 - val_precision: 0.6491 - val_auc: 0.8236\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.7969 - sensitivity_at_specificity: 0.9773 - specificity_at_sensitivity: 0.9362 - recall: 0.7652 - precision: 0.7481 - auc: 0.8813\n",
            "Epoch 430: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4313 - accuracy: 0.7969 - sensitivity_at_specificity: 0.9773 - specificity_at_sensitivity: 0.9362 - recall: 0.7652 - precision: 0.7481 - auc: 0.8813 - val_loss: 0.4933 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.9028 - val_specificity_at_sensitivity: 0.9318 - val_recall: 0.6528 - val_precision: 0.7581 - val_auc: 0.8394\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.7781 - sensitivity_at_specificity: 0.9043 - specificity_at_sensitivity: 0.8927 - recall: 0.6261 - precision: 0.7200 - auc: 0.8327\n",
            "Epoch 431: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4756 - accuracy: 0.7781 - sensitivity_at_specificity: 0.9043 - specificity_at_sensitivity: 0.8927 - recall: 0.6261 - precision: 0.7200 - auc: 0.8327 - val_loss: 0.4637 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9483 - val_specificity_at_sensitivity: 0.9216 - val_recall: 0.5172 - val_precision: 0.7692 - val_auc: 0.8556\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5502 - accuracy: 0.7406 - sensitivity_at_specificity: 0.8480 - specificity_at_sensitivity: 0.8769 - recall: 0.5520 - precision: 0.7188 - auc: 0.7899\n",
            "Epoch 432: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5502 - accuracy: 0.7406 - sensitivity_at_specificity: 0.8480 - specificity_at_sensitivity: 0.8769 - recall: 0.5520 - precision: 0.7188 - auc: 0.7899 - val_loss: 0.4803 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9683 - val_specificity_at_sensitivity: 0.9381 - val_recall: 0.8413 - val_precision: 0.6543 - val_auc: 0.8612\n",
            "Epoch 433/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4384 - accuracy: 0.8194 - sensitivity_at_specificity: 0.9266 - specificity_at_sensitivity: 0.9330 - recall: 0.6972 - precision: 0.8000 - auc: 0.8722\n",
            "Epoch 433: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4352 - accuracy: 0.8188 - sensitivity_at_specificity: 0.9274 - specificity_at_sensitivity: 0.9337 - recall: 0.6935 - precision: 0.8113 - auc: 0.8760 - val_loss: 0.5345 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.9231 - val_specificity_at_sensitivity: 0.8902 - val_recall: 0.6282 - val_precision: 0.8033 - val_auc: 0.8204\n",
            "Epoch 434/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4721 - accuracy: 0.7917 - sensitivity_at_specificity: 0.9029 - specificity_at_sensitivity: 0.8973 - recall: 0.6408 - precision: 0.7416 - auc: 0.8430\n",
            "Epoch 434: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4603 - accuracy: 0.8031 - sensitivity_at_specificity: 0.9138 - specificity_at_sensitivity: 0.9265 - recall: 0.6724 - precision: 0.7573 - auc: 0.8546 - val_loss: 0.4948 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9315 - val_specificity_at_sensitivity: 0.9310 - val_recall: 0.6438 - val_precision: 0.7966 - val_auc: 0.8446\n",
            "Epoch 435/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4579 - accuracy: 0.7951 - sensitivity_at_specificity: 0.9439 - specificity_at_sensitivity: 0.9448 - recall: 0.6075 - precision: 0.7927 - auc: 0.8621\n",
            "Epoch 435: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4645 - accuracy: 0.7906 - sensitivity_at_specificity: 0.9322 - specificity_at_sensitivity: 0.9406 - recall: 0.5932 - precision: 0.7865 - auc: 0.8553 - val_loss: 0.5292 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8689 - val_specificity_at_sensitivity: 0.8889 - val_recall: 0.6066 - val_precision: 0.6727 - val_auc: 0.7975\n",
            "Epoch 436/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4893 - accuracy: 0.7465 - sensitivity_at_specificity: 0.9204 - specificity_at_sensitivity: 0.9143 - recall: 0.6726 - precision: 0.6786 - auc: 0.8297\n",
            "Epoch 436: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4753 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9370 - specificity_at_sensitivity: 0.9223 - recall: 0.6929 - precision: 0.6984 - auc: 0.8428 - val_loss: 0.4750 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.9375 - val_specificity_at_sensitivity: 0.9271 - val_recall: 0.6250 - val_precision: 0.7692 - val_auc: 0.8456\n",
            "Epoch 437/500\n",
            " 6/10 [=================>............] - ETA: 0s - loss: 0.4783 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9167 - specificity_at_sensitivity: 0.8917 - recall: 0.6528 - precision: 0.7344 - auc: 0.8446\n",
            "Epoch 437: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5176 - accuracy: 0.7406 - sensitivity_at_specificity: 0.9154 - specificity_at_sensitivity: 0.8842 - recall: 0.5923 - precision: 0.7196 - auc: 0.8163 - val_loss: 0.4928 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9306 - val_specificity_at_sensitivity: 0.8977 - val_recall: 0.7083 - val_precision: 0.7391 - val_auc: 0.8359\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4776 - accuracy: 0.7937 - sensitivity_at_specificity: 0.9516 - specificity_at_sensitivity: 0.9337 - recall: 0.7661 - precision: 0.7197 - auc: 0.8510\n",
            "Epoch 438: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4776 - accuracy: 0.7937 - sensitivity_at_specificity: 0.9516 - specificity_at_sensitivity: 0.9337 - recall: 0.7661 - precision: 0.7197 - auc: 0.8510 - val_loss: 0.5092 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.9565 - val_specificity_at_sensitivity: 0.9011 - val_recall: 0.5797 - val_precision: 0.7143 - val_auc: 0.8235\n",
            "Epoch 439/500\n",
            " 6/10 [=================>............] - ETA: 0s - loss: 0.4487 - accuracy: 0.7772 - sensitivity_at_specificity: 0.9437 - specificity_at_sensitivity: 0.9381 - recall: 0.5775 - precision: 0.7885 - auc: 0.8707\n",
            "Epoch 439: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4354 - accuracy: 0.7853 - sensitivity_at_specificity: 0.9580 - specificity_at_sensitivity: 0.9482 - recall: 0.5966 - precision: 0.7889 - auc: 0.8774 - val_loss: 0.4515 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 0.9855 - val_specificity_at_sensitivity: 0.9121 - val_recall: 0.6522 - val_precision: 0.8333 - val_auc: 0.8803\n",
            "Epoch 440/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4475 - accuracy: 0.7847 - sensitivity_at_specificity: 0.9600 - specificity_at_sensitivity: 0.9362 - recall: 0.6400 - precision: 0.7111 - auc: 0.8552\n",
            "Epoch 440: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4554 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9292 - specificity_at_sensitivity: 0.9420 - recall: 0.6372 - precision: 0.7273 - auc: 0.8492 - val_loss: 0.4796 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.8732 - val_specificity_at_sensitivity: 0.9775 - val_recall: 0.6479 - val_precision: 0.7931 - val_auc: 0.8529\n",
            "Epoch 441/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4419 - accuracy: 0.7847 - sensitivity_at_specificity: 0.9633 - specificity_at_sensitivity: 0.9274 - recall: 0.6697 - precision: 0.7374 - auc: 0.8690\n",
            "Epoch 441: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4412 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9658 - specificity_at_sensitivity: 0.9212 - recall: 0.6667 - precision: 0.7222 - auc: 0.8658 - val_loss: 0.4611 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.9231 - val_specificity_at_sensitivity: 0.9512 - val_recall: 0.6667 - val_precision: 0.7761 - val_auc: 0.8633\n",
            "Epoch 442/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4074 - accuracy: 0.8403 - sensitivity_at_specificity: 0.9524 - specificity_at_sensitivity: 0.9399 - recall: 0.6952 - precision: 0.8391 - auc: 0.8918\n",
            "Epoch 442: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4397 - accuracy: 0.8125 - sensitivity_at_specificity: 0.9412 - specificity_at_sensitivity: 0.9303 - recall: 0.6471 - precision: 0.8105 - auc: 0.8696 - val_loss: 0.4662 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.9706 - val_specificity_at_sensitivity: 0.9022 - val_recall: 0.6471 - val_precision: 0.7857 - val_auc: 0.8599\n",
            "Epoch 443/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4641 - accuracy: 0.7674 - sensitivity_at_specificity: 0.9189 - specificity_at_sensitivity: 0.9435 - recall: 0.6036 - precision: 0.7444 - auc: 0.8483\n",
            "Epoch 443: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4534 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9180 - specificity_at_sensitivity: 0.9495 - recall: 0.6148 - precision: 0.7500 - auc: 0.8565 - val_loss: 0.5346 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.8889 - val_specificity_at_sensitivity: 0.9432 - val_recall: 0.5972 - val_precision: 0.7963 - val_auc: 0.8163\n",
            "Epoch 444/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4341 - accuracy: 0.8160 - sensitivity_at_specificity: 0.9550 - specificity_at_sensitivity: 0.9322 - recall: 0.7207 - precision: 0.7843 - auc: 0.8789\n",
            "Epoch 444: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4193 - accuracy: 0.8219 - sensitivity_at_specificity: 0.9744 - specificity_at_sensitivity: 0.9360 - recall: 0.7179 - precision: 0.7778 - auc: 0.8870 - val_loss: 0.4912 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.9143 - val_specificity_at_sensitivity: 0.9222 - val_recall: 0.6429 - val_precision: 0.8036 - val_auc: 0.8483\n",
            "Epoch 445/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4770 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9035 - specificity_at_sensitivity: 0.9655 - recall: 0.6140 - precision: 0.7865 - auc: 0.8445\n",
            "Epoch 445: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4746 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9070 - specificity_at_sensitivity: 0.9634 - recall: 0.6279 - precision: 0.7864 - auc: 0.8472 - val_loss: 0.5693 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.8548 - val_specificity_at_sensitivity: 0.8673 - val_recall: 0.7097 - val_precision: 0.5641 - val_auc: 0.7837\n",
            "Epoch 446/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4457 - accuracy: 0.7778 - sensitivity_at_specificity: 0.9565 - specificity_at_sensitivity: 0.9306 - recall: 0.7304 - precision: 0.7179 - auc: 0.8711\n",
            "Epoch 446: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4362 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9597 - specificity_at_sensitivity: 0.9286 - recall: 0.7419 - precision: 0.7132 - auc: 0.8766 - val_loss: 0.4781 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9342 - val_specificity_at_sensitivity: 0.9405 - val_recall: 0.5921 - val_precision: 0.8824 - val_auc: 0.8744\n",
            "Epoch 447/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4603 - accuracy: 0.7535 - sensitivity_at_specificity: 0.9397 - specificity_at_sensitivity: 0.9302 - recall: 0.5517 - precision: 0.7711 - auc: 0.8642\n",
            "Epoch 447: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4580 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9365 - specificity_at_sensitivity: 0.9588 - recall: 0.5714 - precision: 0.7660 - auc: 0.8602 - val_loss: 0.4599 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.8947 - val_specificity_at_sensitivity: 0.9524 - val_recall: 0.7895 - val_precision: 0.7692 - val_auc: 0.8616\n",
            "Epoch 448/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4750 - accuracy: 0.7569 - sensitivity_at_specificity: 0.9062 - specificity_at_sensitivity: 0.9312 - recall: 0.7266 - precision: 0.7266 - auc: 0.8533\n",
            "Epoch 448: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4724 - accuracy: 0.7656 - sensitivity_at_specificity: 0.8971 - specificity_at_sensitivity: 0.9293 - recall: 0.7279 - precision: 0.7226 - auc: 0.8538 - val_loss: 0.4465 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 0.9722 - val_specificity_at_sensitivity: 0.9318 - val_recall: 0.6944 - val_precision: 0.8197 - val_auc: 0.8754\n",
            "Epoch 449/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4374 - accuracy: 0.8264 - sensitivity_at_specificity: 0.9029 - specificity_at_sensitivity: 0.9676 - recall: 0.5922 - precision: 0.8841 - auc: 0.8649\n",
            "Epoch 449: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4221 - accuracy: 0.8344 - sensitivity_at_specificity: 0.9130 - specificity_at_sensitivity: 0.9659 - recall: 0.6174 - precision: 0.8875 - auc: 0.8762 - val_loss: 0.5652 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8904 - val_specificity_at_sensitivity: 0.8506 - val_recall: 0.5753 - val_precision: 0.7119 - val_auc: 0.7902\n",
            "Epoch 450/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4829 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9455 - specificity_at_sensitivity: 0.8764 - recall: 0.7455 - precision: 0.7009 - auc: 0.8456\n",
            "Epoch 450: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4767 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9350 - specificity_at_sensitivity: 0.8832 - recall: 0.7398 - precision: 0.7109 - auc: 0.8494 - val_loss: 0.4358 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9737 - val_specificity_at_sensitivity: 0.9524 - val_recall: 0.7763 - val_precision: 0.7662 - val_auc: 0.8789\n",
            "Epoch 451/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4470 - accuracy: 0.7917 - sensitivity_at_specificity: 0.9255 - specificity_at_sensitivity: 0.9330 - recall: 0.5638 - precision: 0.7361 - auc: 0.8517\n",
            "Epoch 451: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.4438 - accuracy: 0.7969 - sensitivity_at_specificity: 0.9245 - specificity_at_sensitivity: 0.9346 - recall: 0.5755 - precision: 0.7531 - auc: 0.8551 - val_loss: 0.5247 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9178 - val_specificity_at_sensitivity: 0.9425 - val_recall: 0.5616 - val_precision: 0.8723 - val_auc: 0.8381\n",
            "Epoch 452/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4530 - accuracy: 0.7882 - sensitivity_at_specificity: 0.9255 - specificity_at_sensitivity: 0.9381 - recall: 0.5319 - precision: 0.7463 - auc: 0.8443\n",
            "Epoch 452: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4443 - accuracy: 0.7937 - sensitivity_at_specificity: 0.9216 - specificity_at_sensitivity: 0.9358 - recall: 0.5490 - precision: 0.7368 - auc: 0.8483 - val_loss: 0.4110 - val_accuracy: 0.8500 - val_sensitivity_at_specificity: 0.9552 - val_specificity_at_sensitivity: 0.9677 - val_recall: 0.7313 - val_precision: 0.8909 - val_auc: 0.8946\n",
            "Epoch 453/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4544 - accuracy: 0.7674 - sensitivity_at_specificity: 0.9515 - specificity_at_sensitivity: 0.8973 - recall: 0.6408 - precision: 0.6875 - auc: 0.8526\n",
            "Epoch 453: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4571 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9561 - specificity_at_sensitivity: 0.8932 - recall: 0.6316 - precision: 0.6857 - auc: 0.8508 - val_loss: 0.5444 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.8209 - val_specificity_at_sensitivity: 0.9462 - val_recall: 0.5970 - val_precision: 0.7143 - val_auc: 0.7838\n",
            "Epoch 454/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4822 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9029 - specificity_at_sensitivity: 0.9297 - recall: 0.6505 - precision: 0.7128 - auc: 0.8298\n",
            "Epoch 454: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4790 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9043 - specificity_at_sensitivity: 0.9317 - recall: 0.6348 - precision: 0.7300 - auc: 0.8319 - val_loss: 0.5397 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.9306 - val_specificity_at_sensitivity: 0.8977 - val_recall: 0.5278 - val_precision: 0.7917 - val_auc: 0.8373\n",
            "Epoch 455/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4725 - accuracy: 0.7604 - sensitivity_at_specificity: 0.9429 - specificity_at_sensitivity: 0.9290 - recall: 0.5429 - precision: 0.7308 - auc: 0.8393\n",
            "Epoch 455: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4712 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9478 - specificity_at_sensitivity: 0.9268 - recall: 0.5565 - precision: 0.7191 - auc: 0.8404 - val_loss: 0.5253 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8451 - val_specificity_at_sensitivity: 0.9213 - val_recall: 0.6620 - val_precision: 0.7231 - val_auc: 0.8160\n",
            "Epoch 456/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4920 - accuracy: 0.7639 - sensitivity_at_specificity: 0.9478 - specificity_at_sensitivity: 0.9017 - recall: 0.6696 - precision: 0.7196 - auc: 0.8347\n",
            "Epoch 456: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4832 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9520 - specificity_at_sensitivity: 0.9077 - recall: 0.6800 - precision: 0.7265 - auc: 0.8412 - val_loss: 0.4639 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.8923 - val_specificity_at_sensitivity: 0.9474 - val_recall: 0.6462 - val_precision: 0.7925 - val_auc: 0.8509\n",
            "Epoch 457/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4367 - accuracy: 0.8229 - sensitivity_at_specificity: 0.9483 - specificity_at_sensitivity: 0.9709 - recall: 0.6724 - precision: 0.8571 - auc: 0.8838\n",
            "Epoch 457: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4284 - accuracy: 0.8250 - sensitivity_at_specificity: 0.9462 - specificity_at_sensitivity: 0.9737 - recall: 0.6846 - precision: 0.8558 - auc: 0.8888 - val_loss: 0.4993 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.8551 - val_specificity_at_sensitivity: 0.9670 - val_recall: 0.7246 - val_precision: 0.6667 - val_auc: 0.8350\n",
            "Epoch 458/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4903 - accuracy: 0.7674 - sensitivity_at_specificity: 0.9091 - specificity_at_sensitivity: 0.8876 - recall: 0.6909 - precision: 0.6972 - auc: 0.8356\n",
            "Epoch 458: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4918 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9127 - specificity_at_sensitivity: 0.8814 - recall: 0.6905 - precision: 0.7016 - auc: 0.8362 - val_loss: 0.4922 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.9155 - val_specificity_at_sensitivity: 0.9551 - val_recall: 0.6338 - val_precision: 0.8491 - val_auc: 0.8365\n",
            "Epoch 459/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4472 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9407 - specificity_at_sensitivity: 0.9529 - recall: 0.6441 - precision: 0.7677 - auc: 0.8663\n",
            "Epoch 459: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4624 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9470 - specificity_at_sensitivity: 0.9255 - recall: 0.6515 - precision: 0.7350 - auc: 0.8558 - val_loss: 0.4619 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9683 - val_specificity_at_sensitivity: 0.8969 - val_recall: 0.7937 - val_precision: 0.6667 - val_auc: 0.8638\n",
            "Epoch 460/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5153 - accuracy: 0.7604 - sensitivity_at_specificity: 0.9143 - specificity_at_sensitivity: 0.8743 - recall: 0.6381 - precision: 0.6837 - auc: 0.8113\n",
            "Epoch 460: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.5043 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9153 - specificity_at_sensitivity: 0.8861 - recall: 0.6186 - precision: 0.7019 - auc: 0.8205 - val_loss: 0.4818 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9296 - val_specificity_at_sensitivity: 0.9438 - val_recall: 0.5352 - val_precision: 0.8636 - val_auc: 0.8667\n",
            "Epoch 461/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4298 - accuracy: 0.8229 - sensitivity_at_specificity: 0.9263 - specificity_at_sensitivity: 0.9482 - recall: 0.5895 - precision: 0.8235 - auc: 0.8610\n",
            "Epoch 461: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4455 - accuracy: 0.8031 - sensitivity_at_specificity: 0.9352 - specificity_at_sensitivity: 0.9387 - recall: 0.5648 - precision: 0.7922 - auc: 0.8538 - val_loss: 0.4998 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.8769 - val_specificity_at_sensitivity: 0.9368 - val_recall: 0.5846 - val_precision: 0.8444 - val_auc: 0.8200\n",
            "Epoch 462/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4341 - accuracy: 0.8056 - sensitivity_at_specificity: 0.9100 - specificity_at_sensitivity: 0.9574 - recall: 0.6800 - precision: 0.7391 - auc: 0.8632\n",
            "Epoch 462: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4201 - accuracy: 0.8156 - sensitivity_at_specificity: 0.9196 - specificity_at_sensitivity: 0.9663 - recall: 0.6964 - precision: 0.7573 - auc: 0.8760 - val_loss: 0.4386 - val_accuracy: 0.8062 - val_sensitivity_at_specificity: 0.9600 - val_specificity_at_sensitivity: 0.9882 - val_recall: 0.6533 - val_precision: 0.9074 - val_auc: 0.9069\n",
            "Epoch 463/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4643 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9459 - specificity_at_sensitivity: 0.9266 - recall: 0.6126 - precision: 0.7556 - auc: 0.8555\n",
            "Epoch 463: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4801 - accuracy: 0.7563 - sensitivity_at_specificity: 0.9457 - specificity_at_sensitivity: 0.9162 - recall: 0.5969 - precision: 0.7476 - auc: 0.8472 - val_loss: 0.5093 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.8974 - val_specificity_at_sensitivity: 0.9634 - val_recall: 0.7179 - val_precision: 0.7778 - val_auc: 0.8312\n",
            "Epoch 464/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4269 - accuracy: 0.8160 - sensitivity_at_specificity: 0.9439 - specificity_at_sensitivity: 0.9503 - recall: 0.7570 - precision: 0.7500 - auc: 0.8796\n",
            "Epoch 464: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4362 - accuracy: 0.8094 - sensitivity_at_specificity: 0.9417 - specificity_at_sensitivity: 0.9550 - recall: 0.7417 - precision: 0.7479 - auc: 0.8720 - val_loss: 0.4577 - val_accuracy: 0.8000 - val_sensitivity_at_specificity: 0.8727 - val_specificity_at_sensitivity: 0.9429 - val_recall: 0.6545 - val_precision: 0.7347 - val_auc: 0.8442\n",
            "Epoch 465/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5020 - accuracy: 0.7708 - sensitivity_at_specificity: 0.8404 - specificity_at_sensitivity: 0.9330 - recall: 0.5213 - precision: 0.7000 - auc: 0.7954\n",
            "Epoch 465: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4892 - accuracy: 0.7812 - sensitivity_at_specificity: 0.8544 - specificity_at_sensitivity: 0.9355 - recall: 0.5340 - precision: 0.7143 - auc: 0.8053 - val_loss: 0.4966 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9167 - val_specificity_at_sensitivity: 0.9432 - val_recall: 0.5833 - val_precision: 0.8571 - val_auc: 0.8470\n",
            "Epoch 466/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4659 - accuracy: 0.7708 - sensitivity_at_specificity: 0.9245 - specificity_at_sensitivity: 0.9231 - recall: 0.5566 - precision: 0.7564 - auc: 0.8483\n",
            "Epoch 466: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4632 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9138 - specificity_at_sensitivity: 0.9265 - recall: 0.5690 - precision: 0.7674 - auc: 0.8477 - val_loss: 0.4959 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.9167 - val_specificity_at_sensitivity: 0.9205 - val_recall: 0.6944 - val_precision: 0.6579 - val_auc: 0.8281\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4759 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9444 - specificity_at_sensitivity: 0.9227 - recall: 0.6667 - precision: 0.6942 - auc: 0.8423\n",
            "Epoch 467: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.4759 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9444 - specificity_at_sensitivity: 0.9227 - recall: 0.6667 - precision: 0.6942 - auc: 0.8423 - val_loss: 0.4987 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9740 - val_specificity_at_sensitivity: 0.9880 - val_recall: 0.5325 - val_precision: 0.9535 - val_auc: 0.8887\n",
            "Epoch 468/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4428 - accuracy: 0.7778 - sensitivity_at_specificity: 0.9515 - specificity_at_sensitivity: 0.9297 - recall: 0.6117 - precision: 0.7241 - auc: 0.8625\n",
            "Epoch 468: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4354 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9565 - specificity_at_sensitivity: 0.9317 - recall: 0.6261 - precision: 0.7347 - auc: 0.8698 - val_loss: 0.4918 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9643 - val_specificity_at_sensitivity: 0.9211 - val_recall: 0.6667 - val_precision: 0.8485 - val_auc: 0.8657\n",
            "Epoch 469/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4586 - accuracy: 0.7951 - sensitivity_at_specificity: 0.9504 - specificity_at_sensitivity: 0.9341 - recall: 0.6446 - precision: 0.8298 - auc: 0.8681\n",
            "Epoch 469: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4664 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9389 - specificity_at_sensitivity: 0.9101 - recall: 0.6336 - precision: 0.8058 - auc: 0.8581 - val_loss: 0.5210 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8857 - val_specificity_at_sensitivity: 0.9111 - val_recall: 0.7857 - val_precision: 0.6250 - val_auc: 0.8154\n",
            "Epoch 470/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4476 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9231 - specificity_at_sensitivity: 0.9293 - recall: 0.7308 - precision: 0.6847 - auc: 0.8612\n",
            "Epoch 470: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4437 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9561 - specificity_at_sensitivity: 0.9320 - recall: 0.7105 - precision: 0.6923 - auc: 0.8616 - val_loss: 0.4706 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9589 - val_specificity_at_sensitivity: 0.9425 - val_recall: 0.6301 - val_precision: 0.7931 - val_auc: 0.8649\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.7937 - sensitivity_at_specificity: 0.9100 - specificity_at_sensitivity: 0.9409 - recall: 0.5700 - precision: 0.7125 - auc: 0.8416\n",
            "Epoch 471: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4501 - accuracy: 0.7937 - sensitivity_at_specificity: 0.9100 - specificity_at_sensitivity: 0.9409 - recall: 0.5700 - precision: 0.7125 - auc: 0.8416 - val_loss: 0.6151 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8904 - val_specificity_at_sensitivity: 0.8621 - val_recall: 0.5205 - val_precision: 0.7451 - val_auc: 0.7829\n",
            "Epoch 472/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4814 - accuracy: 0.7569 - sensitivity_at_specificity: 0.9407 - specificity_at_sensitivity: 0.9235 - recall: 0.5593 - precision: 0.7857 - auc: 0.8471\n",
            "Epoch 472: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4629 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9449 - specificity_at_sensitivity: 0.9326 - recall: 0.5906 - precision: 0.7895 - auc: 0.8560 - val_loss: 0.5105 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.8814 - val_specificity_at_sensitivity: 0.9010 - val_recall: 0.7288 - val_precision: 0.6825 - val_auc: 0.8126\n",
            "Epoch 473/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4594 - accuracy: 0.7986 - sensitivity_at_specificity: 0.9245 - specificity_at_sensitivity: 0.9286 - recall: 0.7264 - precision: 0.7264 - auc: 0.8511\n",
            "Epoch 473: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4629 - accuracy: 0.8031 - sensitivity_at_specificity: 0.9160 - specificity_at_sensitivity: 0.9254 - recall: 0.7311 - precision: 0.7373 - auc: 0.8489 - val_loss: 0.4804 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9853 - val_specificity_at_sensitivity: 0.9130 - val_recall: 0.5588 - val_precision: 0.7451 - val_auc: 0.8504\n",
            "Epoch 474/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4388 - accuracy: 0.7951 - sensitivity_at_specificity: 0.9429 - specificity_at_sensitivity: 0.9344 - recall: 0.5619 - precision: 0.8194 - auc: 0.8716\n",
            "Epoch 474: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4337 - accuracy: 0.8062 - sensitivity_at_specificity: 0.9310 - specificity_at_sensitivity: 0.9559 - recall: 0.5948 - precision: 0.8214 - auc: 0.8730 - val_loss: 0.5128 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.8919 - val_specificity_at_sensitivity: 0.9419 - val_recall: 0.7297 - val_precision: 0.7606 - val_auc: 0.8282\n",
            "Epoch 475/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4559 - accuracy: 0.7674 - sensitivity_at_specificity: 0.9417 - specificity_at_sensitivity: 0.9524 - recall: 0.7167 - precision: 0.7227 - auc: 0.8650\n",
            "Epoch 475: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.4536 - accuracy: 0.7688 - sensitivity_at_specificity: 0.9478 - specificity_at_sensitivity: 0.9516 - recall: 0.7015 - precision: 0.7344 - auc: 0.8659 - val_loss: 0.5899 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.8060 - val_specificity_at_sensitivity: 0.8817 - val_recall: 0.5224 - val_precision: 0.7143 - val_auc: 0.7565\n",
            "Epoch 476/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4372 - accuracy: 0.8021 - sensitivity_at_specificity: 0.9320 - specificity_at_sensitivity: 0.9568 - recall: 0.6602 - precision: 0.7556 - auc: 0.8617\n",
            "Epoch 476: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4467 - accuracy: 0.7937 - sensitivity_at_specificity: 0.9217 - specificity_at_sensitivity: 0.9463 - recall: 0.6522 - precision: 0.7426 - auc: 0.8528 - val_loss: 0.5244 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.8906 - val_specificity_at_sensitivity: 0.9167 - val_recall: 0.5781 - val_precision: 0.7115 - val_auc: 0.8045\n",
            "Epoch 477/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5134 - accuracy: 0.7292 - sensitivity_at_specificity: 0.9364 - specificity_at_sensitivity: 0.8708 - recall: 0.5455 - precision: 0.6818 - auc: 0.8187\n",
            "Epoch 477: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5253 - accuracy: 0.7312 - sensitivity_at_specificity: 0.9213 - specificity_at_sensitivity: 0.8808 - recall: 0.5591 - precision: 0.7030 - auc: 0.8140 - val_loss: 0.5036 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.9118 - val_specificity_at_sensitivity: 0.8913 - val_recall: 0.6765 - val_precision: 0.7797 - val_auc: 0.8298\n",
            "Epoch 478/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4178 - accuracy: 0.8229 - sensitivity_at_specificity: 0.9406 - specificity_at_sensitivity: 0.9465 - recall: 0.7030 - precision: 0.7717 - auc: 0.8795\n",
            "Epoch 478: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4215 - accuracy: 0.8156 - sensitivity_at_specificity: 0.9391 - specificity_at_sensitivity: 0.9512 - recall: 0.6957 - precision: 0.7692 - auc: 0.8788 - val_loss: 0.4180 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 0.9420 - val_specificity_at_sensitivity: 0.9780 - val_recall: 0.7391 - val_precision: 0.8644 - val_auc: 0.8966\n",
            "Epoch 479/500\n",
            " 6/10 [=================>............] - ETA: 0s - loss: 0.4396 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9589 - specificity_at_sensitivity: 0.9496 - recall: 0.5616 - precision: 0.8039 - auc: 0.8692\n",
            "Epoch 479: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.4565 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9344 - specificity_at_sensitivity: 0.9242 - recall: 0.6148 - precision: 0.7500 - auc: 0.8548 - val_loss: 0.5064 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.9194 - val_specificity_at_sensitivity: 0.8776 - val_recall: 0.6452 - val_precision: 0.6154 - val_auc: 0.8110\n",
            "Epoch 480/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4565 - accuracy: 0.7951 - sensitivity_at_specificity: 0.9048 - specificity_at_sensitivity: 0.9363 - recall: 0.5238 - precision: 0.6984 - auc: 0.8238\n",
            "Epoch 480: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4442 - accuracy: 0.8031 - sensitivity_at_specificity: 0.9255 - specificity_at_sensitivity: 0.9336 - recall: 0.5532 - precision: 0.7123 - auc: 0.8376 - val_loss: 0.5691 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.9028 - val_specificity_at_sensitivity: 0.9318 - val_recall: 0.4306 - val_precision: 0.8611 - val_auc: 0.8438\n",
            "Epoch 481/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5072 - accuracy: 0.7535 - sensitivity_at_specificity: 0.9297 - specificity_at_sensitivity: 0.9000 - recall: 0.6562 - precision: 0.7568 - auc: 0.8353\n",
            "Epoch 481: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5261 - accuracy: 0.7406 - sensitivity_at_specificity: 0.9296 - specificity_at_sensitivity: 0.8989 - recall: 0.6620 - precision: 0.7287 - auc: 0.8204 - val_loss: 0.5099 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.9634 - val_recall: 0.7949 - val_precision: 0.6667 - val_auc: 0.8336\n",
            "Epoch 482/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5172 - accuracy: 0.7292 - sensitivity_at_specificity: 0.8983 - specificity_at_sensitivity: 0.8941 - recall: 0.6441 - precision: 0.6786 - auc: 0.8141\n",
            "Epoch 482: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5162 - accuracy: 0.7344 - sensitivity_at_specificity: 0.9154 - specificity_at_sensitivity: 0.9000 - recall: 0.6385 - precision: 0.6860 - auc: 0.8141 - val_loss: 0.4867 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.9538 - val_specificity_at_sensitivity: 0.9263 - val_recall: 0.5846 - val_precision: 0.8444 - val_auc: 0.8614\n",
            "Epoch 483/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4788 - accuracy: 0.7569 - sensitivity_at_specificity: 0.9167 - specificity_at_sensitivity: 0.9222 - recall: 0.5833 - precision: 0.7159 - auc: 0.8436\n",
            "Epoch 483: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4651 - accuracy: 0.7688 - sensitivity_at_specificity: 0.9180 - specificity_at_sensitivity: 0.9394 - recall: 0.6066 - precision: 0.7400 - auc: 0.8554 - val_loss: 0.4930 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 0.9000 - val_specificity_at_sensitivity: 0.9556 - val_recall: 0.7000 - val_precision: 0.8033 - val_auc: 0.8394\n",
            "Epoch 484/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4695 - accuracy: 0.7951 - sensitivity_at_specificity: 0.9211 - specificity_at_sensitivity: 0.9540 - recall: 0.6754 - precision: 0.7778 - auc: 0.8532\n",
            "Epoch 484: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4717 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9280 - specificity_at_sensitivity: 0.9487 - recall: 0.6560 - precision: 0.7523 - auc: 0.8494 - val_loss: 0.4963 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.9275 - val_specificity_at_sensitivity: 0.8901 - val_recall: 0.6087 - val_precision: 0.7000 - val_auc: 0.8325\n",
            "Epoch 485/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4463 - accuracy: 0.8090 - sensitivity_at_specificity: 0.9189 - specificity_at_sensitivity: 0.9661 - recall: 0.6937 - precision: 0.7857 - auc: 0.8684\n",
            "Epoch 485: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4420 - accuracy: 0.8094 - sensitivity_at_specificity: 0.8992 - specificity_at_sensitivity: 0.9602 - recall: 0.7143 - precision: 0.7589 - auc: 0.8701 - val_loss: 0.4819 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.9286 - val_specificity_at_sensitivity: 0.9444 - val_recall: 0.5857 - val_precision: 0.7736 - val_auc: 0.8390\n",
            "Epoch 486/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4469 - accuracy: 0.7847 - sensitivity_at_specificity: 0.9434 - specificity_at_sensitivity: 0.9286 - recall: 0.6415 - precision: 0.7391 - auc: 0.8639\n",
            "Epoch 486: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4634 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9322 - specificity_at_sensitivity: 0.9208 - recall: 0.6441 - precision: 0.7379 - auc: 0.8531 - val_loss: 0.5302 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.8947 - val_specificity_at_sensitivity: 0.9405 - val_recall: 0.5658 - val_precision: 0.8431 - val_auc: 0.8295\n",
            "Epoch 487/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4614 - accuracy: 0.7917 - sensitivity_at_specificity: 0.9630 - specificity_at_sensitivity: 0.9222 - recall: 0.6667 - precision: 0.7500 - auc: 0.8535\n",
            "Epoch 487: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4637 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9680 - specificity_at_sensitivity: 0.9179 - recall: 0.6640 - precision: 0.7615 - auc: 0.8549 - val_loss: 0.4970 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.9412 - val_specificity_at_sensitivity: 0.9348 - val_recall: 0.6912 - val_precision: 0.6714 - val_auc: 0.8348\n",
            "Epoch 488/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4777 - accuracy: 0.8056 - sensitivity_at_specificity: 0.9244 - specificity_at_sensitivity: 0.9172 - recall: 0.7647 - precision: 0.7647 - auc: 0.8538\n",
            "Epoch 488: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4819 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9225 - specificity_at_sensitivity: 0.9162 - recall: 0.7597 - precision: 0.7481 - auc: 0.8494 - val_loss: 0.4535 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9296 - val_specificity_at_sensitivity: 0.9438 - val_recall: 0.6056 - val_precision: 0.8113 - val_auc: 0.8731\n",
            "Epoch 489/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4213 - accuracy: 0.8056 - sensitivity_at_specificity: 0.9569 - specificity_at_sensitivity: 0.9419 - recall: 0.6552 - precision: 0.8261 - auc: 0.8915\n",
            "Epoch 489: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4317 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9606 - specificity_at_sensitivity: 0.9275 - recall: 0.6772 - precision: 0.7890 - auc: 0.8793 - val_loss: 0.5077 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.9062 - val_specificity_at_sensitivity: 0.8958 - val_recall: 0.7344 - val_precision: 0.6620 - val_auc: 0.8250\n",
            "Epoch 490/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4494 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9474 - specificity_at_sensitivity: 0.9425 - recall: 0.6579 - precision: 0.7426 - auc: 0.8600\n",
            "Epoch 490: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4490 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9538 - specificity_at_sensitivity: 0.9263 - recall: 0.6615 - precision: 0.7544 - auc: 0.8631 - val_loss: 0.5353 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.8429 - val_specificity_at_sensitivity: 0.9667 - val_recall: 0.5571 - val_precision: 0.7358 - val_auc: 0.7971\n",
            "Epoch 491/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4297 - accuracy: 0.7986 - sensitivity_at_specificity: 0.9804 - specificity_at_sensitivity: 0.9301 - recall: 0.6961 - precision: 0.7245 - auc: 0.8745\n",
            "Epoch 491: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4375 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9352 - specificity_at_sensitivity: 0.9245 - recall: 0.6944 - precision: 0.7075 - auc: 0.8652 - val_loss: 0.4958 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.8219 - val_specificity_at_sensitivity: 0.9655 - val_recall: 0.6575 - val_precision: 0.7742 - val_auc: 0.8284\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 0.7969 - sensitivity_at_specificity: 0.9573 - specificity_at_sensitivity: 0.9507 - recall: 0.6325 - precision: 0.7708 - auc: 0.8759\n",
            "Epoch 492: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4285 - accuracy: 0.7969 - sensitivity_at_specificity: 0.9573 - specificity_at_sensitivity: 0.9507 - recall: 0.6325 - precision: 0.7708 - auc: 0.8759 - val_loss: 0.5044 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9178 - val_specificity_at_sensitivity: 0.9080 - val_recall: 0.6164 - val_precision: 0.7627 - val_auc: 0.8418\n",
            "Epoch 493/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4485 - accuracy: 0.7986 - sensitivity_at_specificity: 0.9320 - specificity_at_sensitivity: 0.9351 - recall: 0.5825 - precision: 0.8000 - auc: 0.8602\n",
            "Epoch 493: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4738 - accuracy: 0.7937 - sensitivity_at_specificity: 0.9107 - specificity_at_sensitivity: 0.9279 - recall: 0.5893 - precision: 0.7674 - auc: 0.8322 - val_loss: 0.4957 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9355 - val_specificity_at_sensitivity: 0.9082 - val_recall: 0.7097 - val_precision: 0.6769 - val_auc: 0.8367\n",
            "Epoch 494/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4875 - accuracy: 0.7396 - sensitivity_at_specificity: 0.9099 - specificity_at_sensitivity: 0.8927 - recall: 0.6937 - precision: 0.6525 - auc: 0.8280\n",
            "Epoch 494: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4878 - accuracy: 0.7406 - sensitivity_at_specificity: 0.9091 - specificity_at_sensitivity: 0.8794 - recall: 0.6694 - precision: 0.6532 - auc: 0.8265 - val_loss: 0.5037 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.8525 - val_specificity_at_sensitivity: 0.9091 - val_recall: 0.5082 - val_precision: 0.7381 - val_auc: 0.8052\n",
            "Epoch 495/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5036 - accuracy: 0.7674 - sensitivity_at_specificity: 0.8411 - specificity_at_sensitivity: 0.9006 - recall: 0.5607 - precision: 0.7500 - auc: 0.8145\n",
            "Epoch 495: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4942 - accuracy: 0.7688 - sensitivity_at_specificity: 0.8595 - specificity_at_sensitivity: 0.9246 - recall: 0.5785 - precision: 0.7527 - auc: 0.8237 - val_loss: 0.4243 - val_accuracy: 0.8188 - val_sensitivity_at_specificity: 0.9846 - val_specificity_at_sensitivity: 0.9474 - val_recall: 0.7538 - val_precision: 0.7903 - val_auc: 0.8863\n",
            "Epoch 496/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4764 - accuracy: 0.7569 - sensitivity_at_specificity: 0.9464 - specificity_at_sensitivity: 0.9205 - recall: 0.6518 - precision: 0.7019 - auc: 0.8426\n",
            "Epoch 496: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4760 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9268 - specificity_at_sensitivity: 0.9188 - recall: 0.6504 - precision: 0.7143 - auc: 0.8419 - val_loss: 0.5231 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9315 - val_specificity_at_sensitivity: 0.8966 - val_recall: 0.5753 - val_precision: 0.7925 - val_auc: 0.8280\n",
            "Epoch 497/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4870 - accuracy: 0.7674 - sensitivity_at_specificity: 0.8878 - specificity_at_sensitivity: 0.9053 - recall: 0.5102 - precision: 0.7246 - auc: 0.8207\n",
            "Epoch 497: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.4905 - accuracy: 0.7656 - sensitivity_at_specificity: 0.8947 - specificity_at_sensitivity: 0.9175 - recall: 0.5263 - precision: 0.7407 - auc: 0.8268 - val_loss: 0.4847 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 0.8750 - val_specificity_at_sensitivity: 0.9375 - val_recall: 0.6406 - val_precision: 0.7736 - val_auc: 0.8329\n",
            "Epoch 498/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4230 - accuracy: 0.8021 - sensitivity_at_specificity: 0.9588 - specificity_at_sensitivity: 0.9529 - recall: 0.7320 - precision: 0.6961 - auc: 0.8781\n",
            "Epoch 498: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4219 - accuracy: 0.8031 - sensitivity_at_specificity: 0.9630 - specificity_at_sensitivity: 0.9528 - recall: 0.7222 - precision: 0.7027 - auc: 0.8798 - val_loss: 0.4571 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 0.9265 - val_specificity_at_sensitivity: 0.9674 - val_recall: 0.6765 - val_precision: 0.8070 - val_auc: 0.8650\n",
            "Epoch 499/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4529 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9429 - specificity_at_sensitivity: 0.9235 - recall: 0.5905 - precision: 0.7381 - auc: 0.8556\n",
            "Epoch 499: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.4554 - accuracy: 0.7781 - sensitivity_at_specificity: 0.9397 - specificity_at_sensitivity: 0.9314 - recall: 0.5862 - precision: 0.7473 - auc: 0.8535 - val_loss: 0.4808 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.9403 - val_specificity_at_sensitivity: 0.9032 - val_recall: 0.6716 - val_precision: 0.7627 - val_auc: 0.8491\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.7437 - sensitivity_at_specificity: 0.9516 - specificity_at_sensitivity: 0.9082 - recall: 0.6532 - precision: 0.6750 - auc: 0.8317\n",
            "Epoch 500: val_accuracy did not improve from 0.85625\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.4925 - accuracy: 0.7437 - sensitivity_at_specificity: 0.9516 - specificity_at_sensitivity: 0.9082 - recall: 0.6532 - precision: 0.6750 - auc: 0.8317 - val_loss: 0.4892 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 0.8846 - val_specificity_at_sensitivity: 0.9167 - val_recall: 0.5385 - val_precision: 0.7000 - val_auc: 0.7978\n"
          ]
        }
      ],
      "source": [
        "#Model Execution\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Initializing Device Specification\n",
        "device_spec = tf.DeviceSpec(job =\"localhost\", replica = 0, device_type = \"GPU\")\n",
        "\n",
        "# Printing the DeviceSpec\n",
        "print('Device Spec: ', device_spec.to_string())\n",
        "\n",
        "# Enabling device logging\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "# Specifying the device\n",
        "with tf.device(device_spec):\n",
        "\n",
        "#with tf.device('/gpu:10'):\n",
        "\n",
        "    checkpoint = ModelCheckpoint(\"ECG_Model_Lead_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "    mycallback=tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=150, mode=\"auto\")\n",
        "\n",
        "    history = model.fit(\n",
        "          train_data,\n",
        "          steps_per_epoch=10,\n",
        "          epochs=500,\n",
        "          verbose=1,\n",
        "          validation_data = val_data,\n",
        "          validation_steps=5,\n",
        "          callbacks = [mycallback,checkpoint]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "WA6R1uo2NMSt",
        "outputId": "5a4cceee-e437-4184-aed2-4552dff8f752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy:  0.8343750238418579\n",
            "Validation Accuracy:  0.856249988079071\n",
            "Validation Specificity:  0.9886363744735718\n",
            "Validation Sensitivity:  0.9866666793823242\n",
            "Validation Recall:  0.890625\n",
            "Validation Precision:  1.0\n",
            "Validation Loss:  0.3926168978214264\n",
            "Validation AUC:  0.9162721037864685\n"
          ]
        }
      ],
      "source": [
        "Training_Accuracy=history.history['accuracy']\n",
        "Validation_Accuracy=history.history['val_accuracy']\n",
        "Validation_Specificity=history.history['val_specificity_at_sensitivity']\n",
        "Validation_Sensitivity=history.history['val_sensitivity_at_specificity']\n",
        "Validation_Recall=history.history['val_recall']\n",
        "Validation_Precision=history.history['val_precision']\n",
        "Validation_Loss=history.history['val_loss']\n",
        "Validation_auc=history.history['val_auc']\n",
        "\n",
        "print(\"Training Accuracy: \",np.max(Training_Accuracy))\n",
        "print(\"Validation Accuracy: \",np.max(Validation_Accuracy))\n",
        "print(\"Validation Specificity: \",np.max(Validation_Specificity))\n",
        "print(\"Validation Sensitivity: \",np.max(Validation_Sensitivity))\n",
        "print(\"Validation Recall: \",np.max(Validation_Recall))\n",
        "print(\"Validation Precision: \",np.max(Validation_Precision))\n",
        "print(\"Validation Loss: \",np.min(Validation_Loss))\n",
        "print(\"Validation AUC: \",np.max(Validation_auc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "KARYMF-bNMSv",
        "outputId": "8e876910-9c40-4fef-e8e7-face82ae61e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "predicted_class 1, _ 0.8315315246582031\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.40205317735671997\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.589867115020752\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.823451817035675, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00473.npy, Actual Label: 0, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.01574993133544922\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.014288642443716526\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.015751274302601814\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.04578984808176756\n",
            "Overall Label: 0\n",
            "File: A00520.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.04556883126497269\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.051097940653562546\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.04624514281749725\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.14291191473603249\n",
            "Overall Label: 0\n",
            "File: A00231.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.026708342134952545\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.01019399892538786\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.011025028303265572\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.047927369363605976\n",
            "Overall Label: 0\n",
            "File: A00456.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.04437582194805145\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.038683585822582245\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.12468717247247696\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.20774658024311066\n",
            "Overall Label: 0\n",
            "File: A00132.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.029211370274424553\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.059074755758047104\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.06086700037121773\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.14915312640368938\n",
            "Overall Label: 0\n",
            "File: A00005.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.20296451449394226\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.02024966850876808\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.03589881211519241\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.25911299511790276\n",
            "Overall Label: 0\n",
            "File: A00519.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.05188046023249626\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.06039900332689285\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.05333895981311798\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.1656184233725071\n",
            "Overall Label: 0\n",
            "File: A00216.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.2941875457763672\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.27612999081611633\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5494070053100586\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 1]\n",
            "sum_confidence_1 0.8435945510864258, sum_confidence_0 0.27612999081611633\n",
            "Overall Label: 1\n",
            "File: A00102.npy, Actual Label: 0, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6620649099349976\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.8600295782089233\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6107783317565918\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 2.1328728199005127, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00004.npy, Actual Label: 0, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.22750574350357056\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.04059755057096481\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.013161237351596355\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.2812645314261317\n",
            "Overall Label: 0\n",
            "File: A00465.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.3203287422657013\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.4539183974266052\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.2965998351573944\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.070846974849701, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00054.npy, Actual Label: 0, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.02319485694169998\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 0, _ 0.024503078311681747\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.012882518582046032\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.06058045383542776\n",
            "Overall Label: 0\n",
            "File: A00432.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.05914197117090225\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.03010367788374424\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.06330699473619461\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.1525526437908411\n",
            "Overall Label: 0\n",
            "File: A00027.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  2342\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.2477843165397644\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.504094123840332\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.265828937292099\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.504094123840332, sum_confidence_0 0.5136132538318634\n",
            "Overall Label: 0\n",
            "File: A00128.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.32237014174461365\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.20825251936912537\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5588023662567139\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 1]\n",
            "sum_confidence_1 0.8811725080013275, sum_confidence_0 0.20825251936912537\n",
            "Overall Label: 1\n",
            "File: A00551.npy, Actual Label: 0, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 0, _ 0.02935865707695484\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.008199535310268402\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.009891112335026264\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.04744930472224951\n",
            "Overall Label: 0\n",
            "File: A00225.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.3115098774433136\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.13576391339302063\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.1257474571466446\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 0]\n",
            "sum_confidence_1 0.3115098774433136, sum_confidence_0 0.2615113705396652\n",
            "Overall Label: 1\n",
            "File: A00090.npy, Actual Label: 0, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.08971883356571198\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "predicted_class 0, _ 0.20945613086223602\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.017574667930603027\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.316749632358551\n",
            "Overall Label: 0\n",
            "File: A00137.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  2034\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.04985332116484642\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.1198040097951889\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.26070067286491394\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.43035800382494926\n",
            "Overall Label: 0\n",
            "File: A00015.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.01910986937582493\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.06463238596916199\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 0, _ 0.03864222764968872\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.12238448299467564\n",
            "Overall Label: 0\n",
            "File: A00267.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.06154104694724083\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.12983180582523346\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.22301216423511505\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.41438501700758934\n",
            "Overall Label: 0\n",
            "File: A00107.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.10573703795671463\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.09750372916460037\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.1203969195485115\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.3236376866698265\n",
            "Overall Label: 0\n",
            "File: A00071.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.772061288356781\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.2034837305545807\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.3866516649723053\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 1]\n",
            "sum_confidence_1 1.1587129533290863, sum_confidence_0 0.2034837305545807\n",
            "Overall Label: 1\n",
            "File: A00542.npy, Actual Label: 0, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.19429172575473785\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.46590468287467957\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.4863883852958679\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 0.9522930681705475, sum_confidence_0 0.19429172575473785\n",
            "Overall Label: 1\n",
            "File: A00217.npy, Actual Label: 0, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.04801657050848007\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.05102869123220444\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.02022506110370159\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.1192703228443861\n",
            "Overall Label: 0\n",
            "File: A00486.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6342523097991943\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6088746190071106\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.499066025018692\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.742192953824997, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00247.npy, Actual Label: 0, Predicted Label: 1\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.21347631514072418\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.19124622642993927\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.05070904642343521\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.45543158799409866\n",
            "Overall Label: 0\n",
            "File: A00439.npy, Actual Label: 0, Predicted Label: 0\n",
            "Skipping file: /home/ubuntu/From_Laptop/12 leads vs 1 lead/test-data-CinC-2017_numpy-files - denoised - altered label/disease/A00438.npy due to insufficient length.\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.21347631514072418\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.19124622642993927\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.05070904642343521\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.45543158799409866\n",
            "Overall Label: 0\n",
            "File: A00438.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.03337143734097481\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.025326931849122047\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.12210642546415329\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.18080479465425014\n",
            "Overall Label: 0\n",
            "File: A00156.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3258397579193115\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.21262764930725098\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.18493077158927917\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 0]\n",
            "sum_confidence_1 0.3258397579193115, sum_confidence_0 0.39755842089653015\n",
            "Overall Label: 0\n",
            "File: A00422.npy, Actual Label: 0, Predicted Label: 0\n",
            "Skipping file: /home/ubuntu/From_Laptop/12 leads vs 1 lead/test-data-CinC-2017_numpy-files - denoised - altered label/disease/A00405.npy due to insufficient length.\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3258397579193115\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.21262764930725098\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.18493077158927917\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 0]\n",
            "sum_confidence_1 0.3258397579193115, sum_confidence_0 0.39755842089653015\n",
            "Overall Label: 0\n",
            "File: A00405.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2862131595611572\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.08982488512992859\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.060858674347400665\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.4368967190384865\n",
            "Overall Label: 0\n",
            "File: A00395.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.10991697758436203\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.048487354069948196\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.020997576415538788\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.17940190806984901\n",
            "Overall Label: 0\n",
            "File: A00009.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.21857741475105286\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.17839588224887848\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.04522423818707466\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.442197535187006\n",
            "Overall Label: 0\n",
            "File: A00271.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5476906299591064\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.7691529393196106\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.626578688621521\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.943422257900238, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00509.npy, Actual Label: 0, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.05828710272908211\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 0, _ 0.11625099927186966\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.07419176399707794\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.2487298659980297\n",
            "Overall Label: 0\n",
            "File: A00253.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.028138481080532074\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.13360843062400818\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 0, _ 0.13757407665252686\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.2993209883570671\n",
            "Overall Label: 0\n",
            "File: A00375.npy, Actual Label: 0, Predicted Label: 0\n",
            "Skipping file: /home/ubuntu/From_Laptop/12 leads vs 1 lead/test-data-CinC-2017_numpy-files - denoised - altered label/disease/A00441.npy due to insufficient length.\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.028138481080532074\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.13360843062400818\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.13757407665252686\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.2993209883570671\n",
            "Overall Label: 0\n",
            "File: A00441.npy, Actual Label: 0, Predicted Label: 0\n",
            "Skipping file: /home/ubuntu/From_Laptop/12 leads vs 1 lead/test-data-CinC-2017_numpy-files - denoised - altered label/disease/A00397.npy due to insufficient length.\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.028138481080532074\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.13360843062400818\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.13757407665252686\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.2993209883570671\n",
            "Overall Label: 0\n",
            "File: A00397.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.0034932750277221203\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.025245152413845062\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 0, _ 0.011661646887660027\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.04040007432922721\n",
            "Overall Label: 0\n",
            "File: A00301.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.048190221190452576\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.3606269359588623\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.09230481088161469\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.3606269359588623, sum_confidence_0 0.14049503207206726\n",
            "Overall Label: 1\n",
            "File: A00208.npy, Actual Label: 0, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.014105619862675667\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.1259491890668869\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.060115352272987366\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.20017016120254993\n",
            "Overall Label: 0\n",
            "File: A00101.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.06995933502912521\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.0538799986243248\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.06911706924438477\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.19295640289783478\n",
            "Overall Label: 0\n",
            "File: A00067.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.029962383210659027\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.02778717689216137\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.06898576021194458\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.12673532031476498\n",
            "Overall Label: 0\n",
            "File: A00087.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.012838909402489662\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.04030824452638626\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.05251545459032059\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.10566260851919651\n",
            "Overall Label: 0\n",
            "File: A00321.npy, Actual Label: 0, Predicted Label: 0\n",
            "Skipping file: /home/ubuntu/From_Laptop/12 leads vs 1 lead/test-data-CinC-2017_numpy-files - denoised - altered label/disease/A00141.npy due to insufficient length.\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.012838909402489662\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.04030824452638626\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.05251545459032059\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.10566260851919651\n",
            "Overall Label: 0\n",
            "File: A00141.npy, Actual Label: 0, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.6738351583480835\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.7857270836830139\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.6843359470367432\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 2.1438981890678406, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00062.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.3177102208137512\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5536723732948303\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.785646915435791\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.6570295095443726, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00230.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.4305356442928314\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.29011300206184387\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.09177661687135696\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 0]\n",
            "sum_confidence_1 0.7206486463546753, sum_confidence_0 0.09177661687135696\n",
            "Overall Label: 1\n",
            "File: A00134.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 1, _ 0.48736533522605896\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.18193911015987396\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.13019190728664398\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 0]\n",
            "sum_confidence_1 0.48736533522605896, sum_confidence_0 0.31213101744651794\n",
            "Overall Label: 1\n",
            "File: A00237.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.64609295129776\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.7329499125480652\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.6988095045089722\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 2.0778523683547974, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00168.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.3097880780696869\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.7406404614448547\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.4483972191810608\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.4988257586956024, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00180.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.6079920530319214\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.2435951977968216\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.5328790545463562\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 1]\n",
            "sum_confidence_1 1.1408711075782776, sum_confidence_0 0.2435951977968216\n",
            "Overall Label: 1\n",
            "File: A00207.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  5933\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.2144102305173874\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.4227108955383301\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3271496891975403\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 0.7498605847358704, sum_confidence_0 0.2144102305173874\n",
            "Overall Label: 1\n",
            "File: A00051.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.2802252173423767\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.19427673518657684\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.35888874530792236\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 1]\n",
            "sum_confidence_1 0.35888874530792236, sum_confidence_0 0.47450195252895355\n",
            "Overall Label: 0\n",
            "File: A00011.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.6976411938667297\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.6504563689231873\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.8482639789581299\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 2.196361541748047, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00232.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.677936315536499\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.7540798187255859\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.44769006967544556\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.8797062039375305, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00109.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.29628056287765503\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.2751613259315491\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.2455730140209198\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 0]\n",
            "sum_confidence_1 0.29628056287765503, sum_confidence_0 0.5207343399524689\n",
            "Overall Label: 0\n",
            "File: A00117.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  4684\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 0, _ 0.22574198246002197\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.35035228729248047\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.36272937059402466\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 0.7130816578865051, sum_confidence_0 0.22574198246002197\n",
            "Overall Label: 1\n",
            "File: A00060.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  2898\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.19873380661010742\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 0, _ 0.18311730027198792\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.38925161957740784\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 1]\n",
            "sum_confidence_1 0.38925161957740784, sum_confidence_0 0.38185110688209534\n",
            "Overall Label: 1\n",
            "File: A00032.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.32462215423583984\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "predicted_class 1, _ 0.3625444769859314\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.1197197288274765\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 0]\n",
            "sum_confidence_1 0.6871666312217712, sum_confidence_0 0.1197197288274765\n",
            "Overall Label: 1\n",
            "File: A00084.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.17207951843738556\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.513060450553894\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.455904483795166\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 0.9689649343490601, sum_confidence_0 0.17207951843738556\n",
            "Overall Label: 1\n",
            "File: A00010.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.038174282759428024\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.03623392432928085\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.11704019457101822\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.1914484016597271\n",
            "Overall Label: 0\n",
            "File: A00035.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.11077258735895157\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.35156047344207764\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.43549978733062744\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 0.7870602607727051, sum_confidence_0 0.11077258735895157\n",
            "Overall Label: 1\n",
            "File: A00152.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.20601071417331696\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2611011564731598\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.13980206847190857\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.6069139391183853\n",
            "Overall Label: 0\n",
            "File: A00194.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  2327\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2820466160774231\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.6372469663619995\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3359456956386566\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 0.9731926620006561, sum_confidence_0 0.2820466160774231\n",
            "Overall Label: 1\n",
            "File: A00057.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.15816085040569305\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5563611388206482\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5544911026954651\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 1.1108522415161133, sum_confidence_0 0.15816085040569305\n",
            "Overall Label: 1\n",
            "File: A00039.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.30310696363449097\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3199630081653595\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.3109091520309448\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 0.9339791238307953, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00163.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.6187680959701538\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.318911612033844\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.45285987854003906\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.3905395865440369, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00113.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.10515746474266052\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.05058081075549126\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.1902826428413391\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.3460209183394909\n",
            "Overall Label: 0\n",
            "File: A00191.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  2180\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.4161512851715088\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.24146555364131927\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.16025029122829437\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 0]\n",
            "sum_confidence_1 0.4161512851715088, sum_confidence_0 0.40171584486961365\n",
            "Overall Label: 1\n",
            "File: A00052.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.31025442481040955\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.026107056066393852\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.09675171226263046\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 0]\n",
            "sum_confidence_1 0.31025442481040955, sum_confidence_0 0.12285876832902431\n",
            "Overall Label: 1\n",
            "File: A00219.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.1668994426727295\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.24856036901474\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.08013194799423218\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.49559175968170166\n",
            "Overall Label: 0\n",
            "File: A00046.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7301621437072754\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7130902409553528\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.253268301486969\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 0]\n",
            "sum_confidence_1 1.4432523846626282, sum_confidence_0 0.253268301486969\n",
            "Overall Label: 1\n",
            "File: A00171.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.6053102612495422\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.322650283575058\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7345992922782898\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.66255983710289, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00002.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.6659005880355835\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.574109673500061\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.6566528081893921\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.8966630697250366, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00206.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 0, _ 0.18428461253643036\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.17811691761016846\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.47056013345718384\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 1]\n",
            "sum_confidence_1 0.47056013345718384, sum_confidence_0 0.3624015301465988\n",
            "Overall Label: 1\n",
            "File: A00124.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.43109825253486633\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2605587840080261\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7814393639564514\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 1]\n",
            "sum_confidence_1 1.2125376164913177, sum_confidence_0 0.2605587840080261\n",
            "Overall Label: 1\n",
            "File: A00104.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  2055\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.42262816429138184\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6554591655731201\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.2509773373603821\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 0]\n",
            "sum_confidence_1 1.078087329864502, sum_confidence_0 0.2509773373603821\n",
            "Overall Label: 1\n",
            "File: A00173.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.45881447196006775\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.11918395012617111\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.15345121920108795\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 0]\n",
            "sum_confidence_1 0.45881447196006775, sum_confidence_0 0.27263516932725906\n",
            "Overall Label: 1\n",
            "File: A00053.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.33945462107658386\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.2614249587059021\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.5144451856613159\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 1]\n",
            "sum_confidence_1 0.8538998067378998, sum_confidence_0 0.2614249587059021\n",
            "Overall Label: 1\n",
            "File: A00144.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.42237716913223267\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.6163628101348877\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.6696222424507141\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.7083622217178345, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00233.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.1750527173280716\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.27181175351142883\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.22643718123435974\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.6733016520738602\n",
            "Overall Label: 0\n",
            "File: A00227.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "predicted_class 0, _ 0.0757952556014061\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.18219093978405\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.15947678685188293\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.417462982237339\n",
            "Overall Label: 0\n",
            "File: A00249.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.4985055923461914\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.48214924335479736\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.37686440348625183\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.3575192391872406, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00048.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.14906667172908783\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.08597903698682785\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.1292237788438797\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.3642694875597954\n",
            "Overall Label: 0\n",
            "File: A00200.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5075183510780334\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7244631052017212\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.030969474464654922\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 0]\n",
            "sum_confidence_1 1.2319814562797546, sum_confidence_0 0.030969474464654922\n",
            "Overall Label: 1\n",
            "File: A00127.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.4755859076976776\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.5192762613296509\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.49678993225097656\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.491652101278305, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00150.npy, Actual Label: 1, Predicted Label: 1\n",
            "Skipping file: /home/ubuntu/From_Laptop/12 leads vs 1 lead/test-data-CinC-2017_numpy-files - denoised - altered label/normal/A00221.npy due to insufficient length.\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.4755859076976776\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5192762613296509\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.49678993225097656\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.491652101278305, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00221.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5946568846702576\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.44056713581085205\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.1095043271780014\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 0]\n",
            "sum_confidence_1 1.0352240204811096, sum_confidence_0 0.1095043271780014\n",
            "Overall Label: 1\n",
            "File: A00064.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.27006396651268005\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.14316371083259583\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.045146144926548004\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.4583738222718239\n",
            "Overall Label: 0\n",
            "File: A00037.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.10589256137609482\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.29804733395576477\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.4098467230796814\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 0.7078940570354462, sum_confidence_0 0.10589256137609482\n",
            "Overall Label: 1\n",
            "File: A00130.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.4911746084690094\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6390864849090576\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7268220782279968\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.8570831716060638, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00079.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.34362414479255676\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5910970568656921\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7060024738311768\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.6407236754894257, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00116.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.22026124596595764\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.4784737825393677\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5131760835647583\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 0.991649866104126, sum_confidence_0 0.22026124596595764\n",
            "Overall Label: 1\n",
            "File: A00050.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.13754615187644958\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.11508169025182724\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.15179918706417084\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.40442702919244766\n",
            "Overall Label: 0\n",
            "File: A00210.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5043796300888062\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.765532910823822\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.6429488062858582\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.9128613471984863, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00112.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "predicted_class 1, _ 0.6715806126594543\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.4077207148075104\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.3832824230194092\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.462583750486374, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00006.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.35949552059173584\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.5952295660972595\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6275543570518494\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.5822794437408447, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00151.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.19729478657245636\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.36235737800598145\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.2537725865840912\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.36235737800598145, sum_confidence_0 0.45106737315654755\n",
            "Overall Label: 0\n",
            "File: A00244.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.16990961134433746\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.8718609809875488\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.47010910511016846\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 1.3419700860977173, sum_confidence_0 0.16990961134433746\n",
            "Overall Label: 1\n",
            "File: A00059.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.3826904296875\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.4796200394630432\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.24858522415161133\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 0]\n",
            "sum_confidence_1 0.8623104691505432, sum_confidence_0 0.24858522415161133\n",
            "Overall Label: 1\n",
            "File: A00036.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6898866295814514\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.7005435824394226\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.28407254815101624\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 0]\n",
            "sum_confidence_1 1.390430212020874, sum_confidence_0 0.28407254815101624\n",
            "Overall Label: 1\n",
            "File: A00193.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.17740556597709656\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.027523621916770935\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.11524957418441772\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.3201787620782852\n",
            "Overall Label: 0\n",
            "File: A00153.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.601834774017334\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.7263593673706055\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.8626161217689514\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 2.190810263156891, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00026.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.1798766553401947\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.14118993282318115\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.1014779582619667\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.42254454642534256\n",
            "Overall Label: 0\n",
            "File: A00222.npy, Actual Label: 1, Predicted Label: 0\n",
            "Skipping file: /home/ubuntu/From_Laptop/12 leads vs 1 lead/test-data-CinC-2017_numpy-files - denoised - altered label/normal/A00093.npy due to insufficient length.\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.1798766553401947\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.14118993282318115\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.1014779582619667\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.42254454642534256\n",
            "Overall Label: 0\n",
            "File: A00093.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.2549450099468231\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.46749672293663025\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2723264694213867\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.46749672293663025, sum_confidence_0 0.5272714793682098\n",
            "Overall Label: 0\n",
            "File: A00033.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.45844388008117676\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5032584071159363\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5261368751525879\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.487839162349701, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00143.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.21653810143470764\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.327080637216568\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.15652437508106232\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.327080637216568, sum_confidence_0 0.37306247651576996\n",
            "Overall Label: 0\n",
            "File: A00086.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.09613221138715744\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.2132890522480011\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.04229022189974785\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.3517114855349064\n",
            "Overall Label: 0\n",
            "File: A00157.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.759971559047699\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6508229374885559\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2607609033584595\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 0]\n",
            "sum_confidence_1 1.4107944965362549, sum_confidence_0 0.2607609033584595\n",
            "Overall Label: 1\n",
            "File: A00197.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  4370\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.2698805034160614\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.4522853195667267\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 0, _ 0.26027610898017883\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.4522853195667267, sum_confidence_0 0.5301566123962402\n",
            "Overall Label: 0\n",
            "File: A00245.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.2933025360107422\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.11982676386833191\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.1540609747171402\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 0]\n",
            "sum_confidence_1 0.2933025360107422, sum_confidence_0 0.2738877385854721\n",
            "Overall Label: 1\n",
            "File: A00018.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.520215630531311\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.41886910796165466\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.3474825918674469\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.2865673303604126, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00007.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.28011661767959595\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.5014432072639465\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.13220517337322235\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.5014432072639465, sum_confidence_0 0.4123217910528183\n",
            "Overall Label: 1\n",
            "File: A00063.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.531948447227478\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.7976329326629639\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.42429253458976746\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.7538739144802094, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00202.npy, Actual Label: 1, Predicted Label: 1\n",
            "Skipping file: /home/ubuntu/From_Laptop/12 leads vs 1 lead/test-data-CinC-2017_numpy-files - denoised - altered label/normal/A00014.npy due to insufficient length.\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.531948447227478\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7976329326629639\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.42429253458976746\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.7538739144802094, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00014.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  2934\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5664258599281311\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.39172303676605225\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.36232149600982666\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.32047039270401, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00224.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6560598015785217\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.49838149547576904\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.42650195956230164\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.5809432566165924, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00025.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.2204289734363556\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.18448814749717712\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.23996159434318542\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.6448787152767181\n",
            "Overall Label: 0\n",
            "File: A00044.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.22305521368980408\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.37398338317871094\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.12289606034755707\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.37398338317871094, sum_confidence_0 0.34595127403736115\n",
            "Overall Label: 1\n",
            "File: A00248.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5280728340148926\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6981859803199768\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7440252304077148\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.9702840447425842, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00122.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5015431046485901\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6609993577003479\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.1394609808921814\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 0]\n",
            "sum_confidence_1 1.162542462348938, sum_confidence_0 0.1394609808921814\n",
            "Overall Label: 1\n",
            "File: A00183.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.09229215979576111\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.3503686785697937\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.20937299728393555\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.3503686785697937, sum_confidence_0 0.30166515707969666\n",
            "Overall Label: 1\n",
            "File: A00179.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5934571623802185\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.30768129229545593\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5245598554611206\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.425698310136795, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00184.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.11712466180324554\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.05752341449260712\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.4908924698829651\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 1]\n",
            "sum_confidence_1 0.4908924698829651, sum_confidence_0 0.17464807629585266\n",
            "Overall Label: 1\n",
            "File: A00118.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.07658681273460388\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.21147219836711884\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.10973606258630753\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.39779507368803024\n",
            "Overall Label: 0\n",
            "File: A00072.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.7195789813995361\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "predicted_class 1, _ 0.8587685227394104\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.4528515338897705\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 2.031199038028717, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00140.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.13182534277439117\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.8771650195121765\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.4854987859725952\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 1.3626638054847717, sum_confidence_0 0.13182534277439117\n",
            "Overall Label: 1\n",
            "File: A00049.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3840\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.3928416073322296\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5215050578117371\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.46929043531417847\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.3836371004581451, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00019.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.20949393510818481\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.1487583965063095\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.34059077501296997\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 1]\n",
            "sum_confidence_1 0.34059077501296997, sum_confidence_0 0.3582523316144943\n",
            "Overall Label: 0\n",
            "File: A00085.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.2303619235754013\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.15754610300064087\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3721843361854553\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 1]\n",
            "sum_confidence_1 0.3721843361854553, sum_confidence_0 0.3879080265760422\n",
            "Overall Label: 0\n",
            "File: A00068.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 1, _ 0.42565301060676575\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.3330908417701721\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.3836148977279663\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.1423587501049042, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00095.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.08801921457052231\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.046710751950740814\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.29085835814476013\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 1]\n",
            "sum_confidence_1 0.29085835814476013, sum_confidence_0 0.13472996652126312\n",
            "Overall Label: 1\n",
            "File: A00129.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.3446410298347473\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.08907458186149597\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.12419778853654861\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 0]\n",
            "sum_confidence_1 0.3446410298347473, sum_confidence_0 0.2132723703980446\n",
            "Overall Label: 1\n",
            "File: A00177.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.37277984619140625\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.07115118205547333\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.05239531770348549\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 0]\n",
            "sum_confidence_1 0.37277984619140625, sum_confidence_0 0.12354649975895882\n",
            "Overall Label: 1\n",
            "File: A00172.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5363796949386597\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.47254678606987\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.5344175100326538\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.5433439910411835, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00098.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.06410656124353409\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5549339652061462\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.03549965098500252\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.5549339652061462, sum_confidence_0 0.0996062122285366\n",
            "Overall Label: 1\n",
            "File: A00089.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.5175136923789978\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.34165313839912415\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5441209077835083\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.4032877385616302, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00040.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.4202903211116791\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.7047038078308105\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.619343638420105\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.7443377673625946, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00238.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.4483479857444763\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.4003012180328369\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.668684720993042\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.5173339247703552, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00228.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.37814027070999146\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2270117998123169\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3650152385234833\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 1]\n",
            "sum_confidence_1 0.7431555092334747, sum_confidence_0 0.2270117998123169\n",
            "Overall Label: 1\n",
            "File: A00182.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.39994484186172485\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.09592199325561523\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.07243429124355316\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 0]\n",
            "sum_confidence_1 0.39994484186172485, sum_confidence_0 0.1683562844991684\n",
            "Overall Label: 1\n",
            "File: A00185.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.25912800431251526\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7765683531761169\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.525404691696167\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 1.301973044872284, sum_confidence_0 0.25912800431251526\n",
            "Overall Label: 1\n",
            "File: A00028.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.7070835828781128\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.6200364232063293\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7603838443756104\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 2.0875038504600525, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00226.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.20044854283332825\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.2688601016998291\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.0360468253493309\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.5053554698824883\n",
            "Overall Label: 0\n",
            "File: A00190.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6062452793121338\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6041057705879211\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5317739248275757\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.7421249747276306, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00146.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.18848136067390442\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.09906764328479767\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.12332198768854141\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.4108709916472435\n",
            "Overall Label: 0\n",
            "File: A00240.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6025602221488953\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7643725872039795\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.8313614130020142\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 2.198294222354889, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00135.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.7658374309539795\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7299516201019287\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.6279838681221008\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 2.123772919178009, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00165.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  2058\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.4413756728172302\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3448125123977661\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.19016851484775543\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 0]\n",
            "sum_confidence_1 0.7861881852149963, sum_confidence_0 0.19016851484775543\n",
            "Overall Label: 1\n",
            "File: A00214.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 1, _ 0.4144800901412964\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5729334354400635\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2743089497089386\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 0]\n",
            "sum_confidence_1 0.9874135255813599, sum_confidence_0 0.2743089497089386\n",
            "Overall Label: 1\n",
            "File: A00012.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.1112973541021347\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 0, _ 0.19593866169452667\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.05622101575136185\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.3634570315480232\n",
            "Overall Label: 0\n",
            "File: A00031.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.2675093114376068\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.25605711340904236\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.08437911421060562\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.6079455390572548\n",
            "Overall Label: 0\n",
            "File: A00097.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.2749353051185608\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5967655777931213\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5141450762748718\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 1.1109106540679932, sum_confidence_0 0.2749353051185608\n",
            "Overall Label: 1\n",
            "File: A00148.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.4112975299358368\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7440354228019714\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.5017736554145813\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.6571066081523895, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00091.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2152261584997177\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2734559178352356\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.6827272772789001\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 1]\n",
            "sum_confidence_1 0.6827272772789001, sum_confidence_0 0.4886820763349533\n",
            "Overall Label: 1\n",
            "File: A00147.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 1, _ 0.4518662691116333\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3409411609172821\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3326340317726135\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.125441461801529, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00175.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5422028303146362\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.7217571139335632\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.5063214898109436\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.770281434059143, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00199.npy, Actual Label: 1, Predicted Label: 1\n",
            "Skipping file: /home/ubuntu/From_Laptop/12 leads vs 1 lead/test-data-CinC-2017_numpy-files - denoised - altered label/normal/A00167.npy due to insufficient length.\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.5422028303146362\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7217571139335632\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.5063214898109436\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.770281434059143, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00167.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.21009400486946106\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.14886151254177094\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.10937324166297913\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.4683287590742111\n",
            "Overall Label: 0\n",
            "File: A00223.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "predicted_class 0, _ 0.07650844752788544\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.11126788705587387\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.25578567385673523\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.44356200844049454\n",
            "Overall Label: 0\n",
            "File: A00142.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2135985940694809\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "predicted_class 1, _ 0.3156866431236267\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.08189061284065247\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.3156866431236267, sum_confidence_0 0.29548920691013336\n",
            "Overall Label: 1\n",
            "File: A00073.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5855942368507385\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3196268379688263\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.38662582635879517\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.29184690117836, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00021.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  6056\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.31263118982315063\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2691746652126312\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.31858956813812256\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 1]\n",
            "sum_confidence_1 0.6312207579612732, sum_confidence_0 0.2691746652126312\n",
            "Overall Label: 1\n",
            "File: A00105.npy, Actual Label: 1, Predicted Label: 1\n",
            "Skipping file: /home/ubuntu/From_Laptop/12 leads vs 1 lead/test-data-CinC-2017_numpy-files - denoised - altered label/normal/A00178.npy due to insufficient length.\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.31263118982315063\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.2691746652126312\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.31858956813812256\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 1]\n",
            "sum_confidence_1 0.6312207579612732, sum_confidence_0 0.2691746652126312\n",
            "Overall Label: 1\n",
            "File: A00178.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.4508325159549713\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "predicted_class 1, _ 0.5348258018493652\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.1530708223581314\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 0]\n",
            "sum_confidence_1 0.9856583178043365, sum_confidence_0 0.1530708223581314\n",
            "Overall Label: 1\n",
            "File: A00094.npy, Actual Label: 1, Predicted Label: 1\n",
            "Skipping file: /home/ubuntu/From_Laptop/12 leads vs 1 lead/test-data-CinC-2017_numpy-files - denoised - altered label/normal/A00239.npy due to insufficient length.\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.4508325159549713\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.5348258018493652\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.1530708223581314\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 0]\n",
            "sum_confidence_1 0.9856583178043365, sum_confidence_0 0.1530708223581314\n",
            "Overall Label: 1\n",
            "File: A00239.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.15261699259281158\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.24000728130340576\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.34965479373931885\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 1]\n",
            "sum_confidence_1 0.34965479373931885, sum_confidence_0 0.39262427389621735\n",
            "Overall Label: 0\n",
            "File: A00045.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.4398166835308075\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.3627895712852478\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.4956037998199463\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.2982100546360016, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00016.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.2499849796295166\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.6655950546264648\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.5596827268600464\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 1.2252777814865112, sum_confidence_0 0.2499849796295166\n",
            "Overall Label: 1\n",
            "File: A00099.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.016797157004475594\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.48160746693611145\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.2616429030895233\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.48160746693611145, sum_confidence_0 0.2784400600939989\n",
            "Overall Label: 1\n",
            "File: A00169.npy, Actual Label: 1, Predicted Label: 1\n",
            "Skipping file: /home/ubuntu/From_Laptop/12 leads vs 1 lead/test-data-CinC-2017_numpy-files - denoised - altered label/normal/A00235.npy due to insufficient length.\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.016797157004475594\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.48160746693611145\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.2616429030895233\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.48160746693611145, sum_confidence_0 0.2784400600939989\n",
            "Overall Label: 1\n",
            "File: A00235.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.36531931161880493\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.47316959500312805\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.4761216342449188\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.3146105408668518, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00241.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 0, _ 0.15902411937713623\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.17662928998470306\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.19926071166992188\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.5349141210317612\n",
            "Overall Label: 0\n",
            "File: A00111.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.4173222482204437\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.361826092004776\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.5396937727928162\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.3188421130180359, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00003.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3113430142402649\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.22320465743541718\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.43836119771003723\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 1]\n",
            "sum_confidence_1 0.7497042119503021, sum_confidence_0 0.22320465743541718\n",
            "Overall Label: 1\n",
            "File: A00042.npy, Actual Label: 1, Predicted Label: 1\n",
            "Skipping file: /home/ubuntu/From_Laptop/12 leads vs 1 lead/test-data-CinC-2017_numpy-files - denoised - altered label/normal/A00236.npy due to insufficient length.\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.3113430142402649\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.22320465743541718\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.43836119771003723\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 1]\n",
            "sum_confidence_1 0.7497042119503021, sum_confidence_0 0.22320465743541718\n",
            "Overall Label: 1\n",
            "File: A00236.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.38785433769226074\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3664880394935608\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 1, _ 0.39982497692108154\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.154167354106903, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00188.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.06896479427814484\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.45181214809417725\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.09119074046611786\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.45181214809417725, sum_confidence_0 0.1601555347442627\n",
            "Overall Label: 1\n",
            "File: A00149.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3760886490345001\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.17307902872562408\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.21717755496501923\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 0]\n",
            "sum_confidence_1 0.3760886490345001, sum_confidence_0 0.3902565836906433\n",
            "Overall Label: 0\n",
            "File: A00174.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.1971520483493805\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.10074319690465927\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "predicted_class 0, _ 0.09551265835762024\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 0, 0]\n",
            "sum_confidence_1 0, sum_confidence_0 0.39340790361166\n",
            "Overall Label: 0\n",
            "File: A00076.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.21731455624103546\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted_class 1, _ 0.33434101939201355\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.20227448642253876\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 0]\n",
            "sum_confidence_1 0.33434101939201355, sum_confidence_0 0.4195890426635742\n",
            "Overall Label: 0\n",
            "File: A00234.npy, Actual Label: 1, Predicted Label: 0\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 0, _ 0.23473259806632996\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7795215845108032\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7923440337181091\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 1.5718656182289124, sum_confidence_0 0.23473259806632996\n",
            "Overall Label: 1\n",
            "File: A00001.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.6815380454063416\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.5417073965072632\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7760137915611267\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 1.9992592334747314, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00166.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.5129753947257996\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.2052314728498459\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.41908180713653564\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 1]\n",
            "sum_confidence_1 0.9320572018623352, sum_confidence_0 0.2052314728498459\n",
            "Overall Label: 1\n",
            "File: A00154.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  6000\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.6376606225967407\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.22227610647678375\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.34608227014541626\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 1]\n",
            "sum_confidence_1 0.983742892742157, sum_confidence_0 0.22227610647678375\n",
            "Overall Label: 1\n",
            "File: A00081.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7690300345420837\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.7753362655639648\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.8182482123374939\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 1, 1]\n",
            "sum_confidence_1 2.3626145124435425, sum_confidence_0 0\n",
            "Overall Label: 1\n",
            "File: A00242.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "predicted_class 0, _ 0.09675178676843643\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 1, _ 0.34967344999313354\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3066621422767639\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [0, 1, 1]\n",
            "sum_confidence_1 0.6563355922698975, sum_confidence_0 0.09675178676843643\n",
            "Overall Label: 1\n",
            "File: A00080.npy, Actual Label: 1, Predicted Label: 1\n",
            "Signal Length:  3000\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "predicted_class 1, _ 0.3364785313606262\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.10480652004480362\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "predicted_class 0, _ 0.08171499520540237\n",
            "votes for  /home/ubuntu/From_Laptop/12 leads vs 1 lead/temp_images/3.png  is:  [1, 0, 0]\n",
            "sum_confidence_1 0.3364785313606262, sum_confidence_0 0.186521515250206\n",
            "Overall Label: 1\n",
            "File: A00160.npy, Actual Label: 1, Predicted Label: 1\n",
            "True labels:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "pred labels:  [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
            "\n",
            "Overall Accuracy: 76.56%\n",
            "AUC: 0.7657373440939105\n",
            "Misclassifications:\n",
            "Class 0: 11 misclassifications\n",
            "Class 1: 34 misclassifications\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# FINAL CODE#\n",
        "\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "import shutil\n",
        "from scipy.signal import butter, filtfilt\n",
        "#from scipy import signal\n",
        "import scipy\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Normalization layer\n",
        "nrmzln_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "def create_image(file_path, save_dir):\n",
        "    # Load file\n",
        "    x = np.load(file_path)\n",
        "\n",
        "    x_size=np.array(x).flatten()\n",
        "    if len(x_size) <= 6000:\n",
        "        print(f\"Skipping file: {file_path} due to insufficient length.\")\n",
        "        return\n",
        "\n",
        "    # Resample the signals from 300 Hz to 100 Hz\n",
        "    original_frequency = 300  # Sampling frequency of original signals (in Hz)\n",
        "    target_frequency = 100  # Target sampling frequency (in Hz)\n",
        "    # Calculate the resampling ratio\n",
        "    resampling_ratio = target_frequency / original_frequency\n",
        "    # Initialize an empty array to store resampled signals\n",
        "    resampled_signals = []\n",
        "    # Resample each signal in the dataset\n",
        "    for signal_data in x:\n",
        "        # Perform resampling\n",
        "        resampled_signal = scipy.signal.resample(signal_data, int(len(signal_data) * resampling_ratio))\n",
        "        resampled_signals.append(resampled_signal)\n",
        "    # Convert the list of resampled signals back to a NumPy array\n",
        "    resampled_signals = np.array(resampled_signals)\n",
        "\n",
        "\n",
        "    signal = resampled_signals[:]\n",
        "    signal = np.array(signal).flatten()\n",
        "\n",
        "    b, a = butter(4, 0.02, btype='high', analog=False)\n",
        "    filtered_ecg = filtfilt(b, a, signal)\n",
        "    max_index = np.argmax(np.abs(filtered_ecg[600:len(filtered_ecg)-50]))\n",
        "    y = filtered_ecg[600:len(filtered_ecg)-50]\n",
        "    max_amplitude = y[max_index]\n",
        "\n",
        "    if max_amplitude >= 0:\n",
        "        signal = signal\n",
        "    else:\n",
        "        signal = -(signal)\n",
        "\n",
        "\n",
        "    # Divide the signal into three parts\n",
        "    sub_image_length = 1000\n",
        "    print(\"Signal Length: \",len(signal))\n",
        "    for i in range(3):\n",
        "        start_idx = i * sub_image_length\n",
        "        end_idx = (i + 1) * sub_image_length\n",
        "\n",
        "        sub_signal = signal[start_idx:end_idx]\n",
        "        normalized_array = (sub_signal / max(sub_signal)).clip(-1, 1)\n",
        "\n",
        "        plt.figure(figsize=(1.25, 1.25))\n",
        "        plt.plot(normalized_array, 'gray')\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        sub_image_path = os.path.join(save_dir, f\"{i + 1}.png\")\n",
        "        plt.savefig(sub_image_path, bbox_inches='tight', pad_inches=0)\n",
        "        plt.close()\n",
        "\n",
        "def load_image(img_path, target_size=(96, 96)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "\n",
        "    img_tensor = image.img_to_array(img)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "    nrmzln_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
        "    img_tensor = nrmzln_layer(img_tensor)\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "def predict_class(model, img_path, threshold=0.29):\n",
        "\n",
        "    img_tensor = load_image(img_path)\n",
        "    pred = model.predict(img_tensor)\n",
        "    return 1 if pred >= threshold else 0, pred[0][0]\n",
        "\n",
        "def evaluate_test_folder(model, test_folder):\n",
        "    class_labels = sorted(os.listdir(test_folder))\n",
        "    total_samples = 0\n",
        "    correct_predictions = 0\n",
        "    misclassifications = {0: 0, 1: 0}\n",
        "    skipped_files = []\n",
        "    true_labels = []\n",
        "    predicted_probabilities = []\n",
        "\n",
        "    for class_label in class_labels:\n",
        "        class_path = os.path.join(test_folder, class_label)\n",
        "        for npy_file in os.listdir(class_path):\n",
        "            npy_path = os.path.join(class_path, npy_file)\n",
        "\n",
        "            # Create three sub-images using create_image function\n",
        "            save_dir = \"directory/temp_images/\"\n",
        "            create_image(npy_path, save_dir)\n",
        "\n",
        "            # Predict class label for each sub-image\n",
        "            votes = []\n",
        "            votes_avg = []\n",
        "            for i in range(1, 4):\n",
        "                sub_image_path = os.path.join(save_dir, f\"{i}.png\")\n",
        "                predicted_class, _ = predict_class(model, sub_image_path)\n",
        "                print(f\"predicted_class {predicted_class}, _ {_}\")\n",
        "                votes.append(predicted_class)\n",
        "                votes_avg.append(_)\n",
        "\n",
        "            print(\"votes for \",sub_image_path,\" is: \",votes)\n",
        "\n",
        "            # Sum up the confidence values for each class\n",
        "            sum_confidence_1 = sum([conf for vote, conf in zip(votes, votes_avg) if vote == 1])\n",
        "            sum_confidence_0 = sum([conf for vote, conf in zip(votes, votes_avg) if vote == 0])\n",
        "            print(f\"sum_confidence_1 {sum_confidence_1}, sum_confidence_0 {sum_confidence_0}\")\n",
        "            # Determine the overall label based on voting\n",
        "            overall_label = 1 if sum_confidence_1 > sum_confidence_0 else 0\n",
        "            print(\"Overall Label:\", overall_label)\n",
        "\n",
        "\n",
        "            # Get true class label based on folder name\n",
        "            true_class = 0 if class_label == 'disease' else 1\n",
        "\n",
        "            # Print details for each file\n",
        "            print(f\"File: {npy_file}, Actual Label: {true_class}, Predicted Label: {overall_label}\")\n",
        "\n",
        "            # Update metrics\n",
        "            total_samples += 1\n",
        "            correct_predictions += 1 if overall_label == true_class else 0\n",
        "            true_labels.append(true_class)\n",
        "            predicted_probabilities.append(overall_label)\n",
        "\n",
        "            # Track misclassifications\n",
        "            if overall_label != true_class:\n",
        "                misclassifications[true_class] += 1\n",
        "\n",
        "\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    auc = roc_auc_score(true_labels, predicted_probabilities)\n",
        "\n",
        "    print(\"True labels: \",true_labels)\n",
        "    print(\"pred labels: \",predicted_probabilities)\n",
        "    print(f\"\\nOverall Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(f\"AUC: {auc}\")\n",
        "    print(\"Misclassifications:\")\n",
        "    for class_label, count in misclassifications.items():\n",
        "        print(f\"Class {class_label}: {count} misclassifications\")\n",
        "\n",
        "    if skipped_files:\n",
        "        print(\"\\nSkipped Files:\")\n",
        "        for skipped_file in skipped_files:\n",
        "            print(skipped_file)\n",
        "\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(true_labels, predicted_probabilities)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Disease', 'Normal'])\n",
        "    disp.plot(cmap='OrRd', values_format='d', ax=plt.gca(), colorbar=False)\n",
        "    #plt.title(\"Confusion Matrix\", fontsize=16)\n",
        "    plt.xlabel(\"Predicted Labels\", fontsize=14)\n",
        "    plt.ylabel(\"True Labels\", fontsize=14)\n",
        "    plt.xticks(fontsize=13)\n",
        "    plt.yticks(fontsize=13)\n",
        "\n",
        "    # Increase font size for the sample counts inside the matrix\n",
        "    for text in disp.text_.ravel():\n",
        "        text.set_fontsize(14)\n",
        "\n",
        "    # Save the confusion matrix plot\n",
        "    plt.savefig(\"directory/confusion_matrix_lead_1.png\", dpi=800, bbox_inches='tight')\n",
        "\n",
        "\n",
        "    # Clean up temporary images\n",
        "    files = glob.glob(r'directory/temp_images/*')\n",
        "    for items in files:\n",
        "        os.remove(items)\n",
        "\n",
        "# Load the model\n",
        "model_path = \"directory/ECG_Model_Lead_1.h5\"\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Test folder path\n",
        "test_folder_path = 'directory/test_set/'\n",
        "\n",
        "# Evaluate the test folder\n",
        "evaluate_test_folder(model, test_folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "7p4-rcXVNMSw",
        "outputId": "0081fa60-3d3a-4550-c597-56d21ff5faf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "Image: A00004.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.019446417689323425\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00225.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.03401586413383484\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00216.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.03329721465706825\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00267.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.05553225427865982\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00009.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.0792173519730568\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00231.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.13144135475158691\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00027.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.06331541389226913\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00375.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.11231499165296555\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "Image: A00015.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.04732062295079231\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "Image: A00397.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.18170903623104095\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00208.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.026133965700864792\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00247.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.03010919690132141\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00542.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.01793757639825344\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00509.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.07556717842817307\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Image: A00405.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.14057613909244537\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Image: A00301.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.06929728388786316\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00005.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.06878777593374252\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00321.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.04929737001657486\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00253.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.024369968101382256\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00054.png, Actual Label: 0, Predicted Label: 1, Prediction Value: 0.2561286687850952\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00102.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.022926341742277145\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00439.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.10808054357767105\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00441.png, Actual Label: 0, Predicted Label: 1, Prediction Value: 0.3024872839450836\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00520.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.03614673763513565\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00132.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.02070770412683487\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00128.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.029962362721562386\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00486.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.009574539959430695\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00217.png, Actual Label: 0, Predicted Label: 1, Prediction Value: 0.2352636605501175\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00107.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.07785305380821228\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00465.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.16247443854808807\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00422.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.08206506073474884\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00137.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.13757996261119843\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00090.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.054279934614896774\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00456.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.05975133925676346\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00473.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.18203869462013245\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00395.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.16526304185390472\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00519.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.05244443193078041\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00438.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.08049623668193817\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00141.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.02208588644862175\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00156.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.10271387547254562\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00067.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.08302761614322662\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00271.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.043846387416124344\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00101.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.024415025487542152\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00551.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.07887522131204605\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00087.png, Actual Label: 0, Predicted Label: 1, Prediction Value: 0.2357538342475891\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00432.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.09832628071308136\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00071.png, Actual Label: 0, Predicted Label: 0, Prediction Value: 0.01345171220600605\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00068.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.15490269660949707\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00111.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.0327853262424469\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00135.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.055838000029325485\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00249.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.05295290797948837\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00245.png, Actual Label: 1, Predicted Label: 1, Prediction Value: 0.24454735219478607\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00118.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.10271774232387543\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00177.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.08443808555603027\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00099.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.13581497967243195\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00179.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.11782200634479523\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00210.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.0500665158033371\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00166.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.02772086299955845\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00183.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.09815149754285812\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00112.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.040391821414232254\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00098.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.026112038642168045\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00127.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.06887832283973694\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00239.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.0339227132499218\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00235.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.04112444072961807\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00199.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.02748861536383629\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00167.png, Actual Label: 1, Predicted Label: 1, Prediction Value: 0.2329888790845871\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00059.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.1721315234899521\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00171.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.0630653128027916\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00180.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.14549222588539124\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00142.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.03755210340023041\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00044.png, Actual Label: 1, Predicted Label: 1, Prediction Value: 0.2477603405714035\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00200.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.052273645997047424\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00064.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.1187775731086731\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Image: A00197.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.07215386629104614\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00221.png, Actual Label: 1, Predicted Label: 1, Prediction Value: 0.3457685708999634\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00042.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.06103690713644028\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00248.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.1418859213590622\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00105.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.1271112859249115\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00122.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.09170811623334885\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00174.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.12084826827049255\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00006.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.025259578600525856\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00190.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.05692688375711441\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00045.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.013756726868450642\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00026.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.064933180809021\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00163.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.12697075307369232\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00191.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.15402676165103912\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00051.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.15092869102954865\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00182.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.15763629972934723\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00165.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.0206735972315073\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00206.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.046778157353401184\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00194.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.19384726881980896\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00046.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.1358691304922104\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00242.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.04586944729089737\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00202.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.051877282559871674\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00037.png, Actual Label: 1, Predicted Label: 1, Prediction Value: 0.23907189071178436\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00152.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.1412069946527481\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00035.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.05463089048862457\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00095.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.021578475832939148\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00019.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.054330773651599884\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00028.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.09370432049036026\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00134.png, Actual Label: 1, Predicted Label: 1, Prediction Value: 0.22582168877124786\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00080.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.03669172525405884\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00002.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.063084177672863\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00232.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.024295886978507042\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00113.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.06165294349193573\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00057.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.183768168091774\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Image: A00169.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.024448076263070107\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Image: A00007.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.07766768336296082\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00236.png, Actual Label: 1, Predicted Label: 1, Prediction Value: 0.23662075400352478\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00081.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.06317021697759628\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00049.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.10098220407962799\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00001.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.05823444202542305\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00063.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.09879045933485031\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00214.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.09931448101997375\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00160.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.04121977463364601\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00117.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.04782707989215851\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00222.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.056002456694841385\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00173.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.10252892225980759\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00085.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.18539908528327942\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00234.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.04045495763421059\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00033.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.07956279069185257\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00003.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.059620484709739685\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00109.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.03897394612431526\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00036.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.14561235904693604\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00241.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.17895565927028656\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00228.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.01342167891561985\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00147.png, Actual Label: 1, Predicted Label: 1, Prediction Value: 0.24298955500125885\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00151.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.047159016132354736\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00130.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.08480101823806763\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00144.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.015124647878110409\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00014.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.12553513050079346\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00207.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.1507583111524582\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00172.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.07226885855197906\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00060.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.042002223432064056\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00089.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.04194684699177742\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00072.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.0343019925057888\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00084.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.048617251217365265\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00040.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.046829599887132645\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00148.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.06753820925951004\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00150.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.05768972262740135\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00146.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.028174158185720444\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00018.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.05557881295681\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00178.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.1245463639497757\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00091.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.03742847591638565\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00227.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.045306459069252014\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00149.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.038505326956510544\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00224.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.044995225965976715\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00097.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.036857761442661285\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00238.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.01623120903968811\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00140.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.05337272211909294\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00219.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.12618298828601837\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00230.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.18474595248699188\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00073.png, Actual Label: 1, Predicted Label: 1, Prediction Value: 0.20082072913646698\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00116.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.082856185734272\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00175.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.08234325796365738\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00039.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.16661876440048218\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00076.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.027100559324026108\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "Image: A00193.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.08554504811763763\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00226.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.1098007783293724\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00237.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.07831086963415146\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00012.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.04081925004720688\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00094.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.024523282423615456\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00157.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.050329312682151794\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00129.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.1053423136472702\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00010.png, Actual Label: 1, Predicted Label: 1, Prediction Value: 0.21860161423683167\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00086.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.06475730985403061\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "Image: A00104.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.11593107879161835\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00021.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.08239995688199997\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00244.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.06128353625535965\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00048.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.06852004677057266\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00184.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.03696507588028908\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00153.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.07515240460634232\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00185.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.13322441279888153\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00079.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.04395348206162453\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00025.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.04609281197190285\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00031.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.022861842066049576\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "Image: A00233.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.10522088408470154\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00016.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.0944909155368805\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00168.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.1318064033985138\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00093.png, Actual Label: 1, Predicted Label: 1, Prediction Value: 0.5664626955986023\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00011.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.06194779649376869\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00154.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.06645137816667557\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00188.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.06976202875375748\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00143.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.023310046643018723\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00032.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.04382793605327606\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00124.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.03863874822854996\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "Image: A00052.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.069902703166008\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00050.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.10760147124528885\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00062.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.028594980016350746\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00053.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.05558920279145241\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00240.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.08210743218660355\n",
            "(1, 96, 96, 3)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "Image: A00223.png, Actual Label: 1, Predicted Label: 0, Prediction Value: 0.030309686437249184\n",
            "\n",
            "Overall Accuracy: 28.12%\n",
            "misclassifications\n",
            "Class 0: 4 misclassifications\n",
            "Class 1: 134 misclassifications\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "\n",
        "# Normalization layer\n",
        "nrmzln_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "def load_image(img_path, target_size=(96, 96)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "\n",
        "    img_tensor = image.img_to_array(img)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "\n",
        "    # Replace normalization with Keras Rescaling layer\n",
        "    nrmzln_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
        "    img_tensor = nrmzln_layer(img_tensor)\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "def predict_class(model, img_path, threshold=0.20):\n",
        "    img_tensor = load_image(img_path)\n",
        "    print(img_tensor.shape)\n",
        "    pred = model.predict(img_tensor)\n",
        "    return 1 if pred >= threshold else 0, pred[0][0]\n",
        "\n",
        "def remove_simple_background(img_tensor, target_size=(96, 96)):\n",
        "    # Convert the image tensor to a NumPy array\n",
        "    img_array = np.squeeze(img_tensor, axis=0)\n",
        "\n",
        "    # Convert to uint8 and ensure 3 channels (assuming RGB image)\n",
        "    img_array = img_array.astype(np.uint8)\n",
        "    if img_array.shape[-1] == 1:\n",
        "        img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply a simple threshold to identify the background (assuming it's white)\n",
        "    _, thresholded = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Invert the thresholded image\n",
        "    mask = cv2.bitwise_not(thresholded)\n",
        "\n",
        "    # Apply the mask to the original image\n",
        "    result = cv2.bitwise_and(img_array, img_array, mask=mask)\n",
        "\n",
        "    # Resize the result if needed\n",
        "    result = cv2.resize(result, target_size)\n",
        "\n",
        "    # Expand dimensions for compatibility with the original code\n",
        "    result_tensor = np.expand_dims(result, axis=0)\n",
        "\n",
        "    return result_tensor\n",
        "\n",
        "def evaluate_test_folder(model, test_folder):\n",
        "    class_labels = sorted(os.listdir(test_folder))\n",
        "    total_samples = 0\n",
        "    correct_predictions = 0\n",
        "    misclassifications = {0: 0, 1: 0}\n",
        "\n",
        "    for class_label in class_labels:\n",
        "        class_path = os.path.join(test_folder, class_label)\n",
        "        for image_file in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_file)\n",
        "\n",
        "            # Predict class label using the model\n",
        "            predicted_class, prediction_value = predict_class(model, image_path)\n",
        "\n",
        "            # Get true class label based on folder name\n",
        "            true_class = 0 if class_label == 'disease' else 1\n",
        "\n",
        "            # Print details for each image\n",
        "            print(f\"Image: {image_file}, Actual Label: {true_class}, Predicted Label: {predicted_class}, Prediction Value: {prediction_value}\")\n",
        "\n",
        "            # Update metrics\n",
        "            total_samples += 1\n",
        "            correct_predictions += 1 if predicted_class == true_class else 0\n",
        "\n",
        "                        # Track misclassifications\n",
        "            if predicted_class != true_class:\n",
        "                misclassifications[true_class] += 1\n",
        "\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    print(f\"\\nOverall Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(\"misclassifications\")\n",
        "    for class_label, count in misclassifications.items():\n",
        "        print(f\"Class {class_label}: {count} misclassifications\")\n",
        "\n",
        "# Load the model\n",
        "model_path = \"directory/ECG_Model_Lead_1.h5\"\n",
        "\n",
        "test_folder_path = 'directory/test_set_without_proposed_architecture/'\n",
        "\n",
        "\n",
        "# Evaluate the test folder\n",
        "evaluate_test_folder(model, test_folder_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}